{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"How to DAO with DAOstack Introduction DAOstack provides everything you need to start managing your community without a centralized authority. Launch your DAO - Decentralized Autonomous Organization using Adaptive, Modular and Upgradable governance structures powered by, DAOstack , a software stack for building Dapps (decentralized apps), DAOs (Decentralized Autonomous Organizations), and DAO tools. The Stack A DApp build with DAOstack DAOs consists of public blockchain layer ( Infra, Arc, Arc-Hive) which is the source of data caching layers (Subgraph) which allows fast access to the blockchain layer javascript library (Client) for application layer integration.","title":"Home"},{"location":"#how-to-dao-with-daostack","text":"","title":"How to DAO with DAOstack"},{"location":"#introduction","text":"DAOstack provides everything you need to start managing your community without a centralized authority. Launch your DAO - Decentralized Autonomous Organization using Adaptive, Modular and Upgradable governance structures powered by, DAOstack , a software stack for building Dapps (decentralized apps), DAOs (Decentralized Autonomous Organizations), and DAO tools.","title":"Introduction"},{"location":"#the-stack","text":"A DApp build with DAOstack DAOs consists of public blockchain layer ( Infra, Arc, Arc-Hive) which is the source of data caching layers (Subgraph) which allows fast access to the blockchain layer javascript library (Client) for application layer integration.","title":"The Stack"},{"location":"FAQ/","text":"Frequently Asked Questions New DAO How do I deploy a new DAO? The easiest way to launch a DAO is using DAOcreator - an interactive tool created by dOrg to deploy your new DAO. Know about the project, get help from our team to customise your DAO and get started on Alchemy here Another alternative to deploy a DAO could be via command line, This give you access to advanced features like - adding custom schemes and global constraints. Refer to our starter-template example or the custom scheme tutorial for details. I have deployed a DAO, what next? Once you have deployed your DAO you would want to do one of the following Get it shown in Alchemy Create a new dApp interface Get it shown in Alchemy In order to get your app added to Alchemy, you will need to get it registered with DAOregistry and indexed by DAOstack subgraph . Since the process has not been automated yet, we would suggest you to submit PR to the DAOstack subgraph repo by adding the output of the deployment process ( json object ) in this folder. Alternatively, you can DM the output to Shiv (telegram: @shivgupt) , Open Source Developer Relations Coordinator , who can then submit PR on your behalf. Create a new dApp interface You can use starter-template example in DAOstack Hacker-kit as the starting point. The example provides a basic react-app and setup a dev environment will core layers of DAOstack. Developer Onboard Which layer of stack can I work/contribute? While contributions are welcome for all layers of the stack, we suggest the first time contributors to start at the dApp layer i.e. Alchemy. Checkout dev setup guide for Alchemy Please refer to our Stack guide on Developer's Portal for details on when to work on each layer. I want to contribute but don't know where to get started? Onboarding on any new project can be a daunting process. Please checkout the intro to the various layers of the DAOstack's Stack . For the first time contributors we suggest any of the following Add feature to Alchemy Interface Create new interface with Starter template Once you are more familiar with the stack you may want to play with and add to various layers of the stack and might find the following guides useful Add custom scheme to the DAO Alchemy starter template Can DAOstack fund me for my contribution? All external contributions to the DAOstack are funded by GenesisDAO and must be passed by the Genesis members. GenesisDAO is the DAO designed to be the inheritor of the DAOstack treasury, and the entity tasked on steering the GEN token economy and use. Please, checkout our Ecosystem repo and refer to the proposals for grants section for details. I still have questions Where do I post queries ? If you still have questions, please feel free to post queries on DAO Research and Dev channel and tag @shivgupt (our Open Source Developer Relations Coordinator) Whom do I contact for technical help or for discussing integrations? For more one-one technical help and queries DM Shiv on telegram: @shivgupt","title":"FAQ"},{"location":"FAQ/#frequently-asked-questions","text":"","title":"Frequently Asked Questions"},{"location":"FAQ/#new-dao","text":"","title":"New DAO"},{"location":"FAQ/#how-do-i-deploy-a-new-dao","text":"The easiest way to launch a DAO is using DAOcreator - an interactive tool created by dOrg to deploy your new DAO. Know about the project, get help from our team to customise your DAO and get started on Alchemy here Another alternative to deploy a DAO could be via command line, This give you access to advanced features like - adding custom schemes and global constraints. Refer to our starter-template example or the custom scheme tutorial for details.","title":"How do I deploy a new DAO?"},{"location":"FAQ/#i-have-deployed-a-dao-what-next","text":"Once you have deployed your DAO you would want to do one of the following Get it shown in Alchemy Create a new dApp interface","title":"I have deployed a DAO, what next?"},{"location":"FAQ/#get-it-shown-in-alchemy","text":"In order to get your app added to Alchemy, you will need to get it registered with DAOregistry and indexed by DAOstack subgraph . Since the process has not been automated yet, we would suggest you to submit PR to the DAOstack subgraph repo by adding the output of the deployment process ( json object ) in this folder. Alternatively, you can DM the output to Shiv (telegram: @shivgupt) , Open Source Developer Relations Coordinator , who can then submit PR on your behalf.","title":"Get it shown in Alchemy"},{"location":"FAQ/#create-a-new-dapp-interface","text":"You can use starter-template example in DAOstack Hacker-kit as the starting point. The example provides a basic react-app and setup a dev environment will core layers of DAOstack.","title":"Create a new dApp interface"},{"location":"FAQ/#developer-onboard","text":"","title":"Developer Onboard"},{"location":"FAQ/#which-layer-of-stack-can-i-workcontribute","text":"While contributions are welcome for all layers of the stack, we suggest the first time contributors to start at the dApp layer i.e. Alchemy. Checkout dev setup guide for Alchemy Please refer to our Stack guide on Developer's Portal for details on when to work on each layer.","title":"Which layer of stack can I work/contribute?"},{"location":"FAQ/#i-want-to-contribute-but-dont-know-where-to-get-started","text":"Onboarding on any new project can be a daunting process. Please checkout the intro to the various layers of the DAOstack's Stack . For the first time contributors we suggest any of the following Add feature to Alchemy Interface Create new interface with Starter template Once you are more familiar with the stack you may want to play with and add to various layers of the stack and might find the following guides useful Add custom scheme to the DAO Alchemy starter template","title":"I want to contribute but don't know where to get started?"},{"location":"FAQ/#can-daostack-fund-me-for-my-contribution","text":"All external contributions to the DAOstack are funded by GenesisDAO and must be passed by the Genesis members. GenesisDAO is the DAO designed to be the inheritor of the DAOstack treasury, and the entity tasked on steering the GEN token economy and use. Please, checkout our Ecosystem repo and refer to the proposals for grants section for details.","title":"Can DAOstack fund me for my contribution?"},{"location":"FAQ/#i-still-have-questions","text":"","title":"I still have questions"},{"location":"FAQ/#where-do-i-post-queries","text":"If you still have questions, please feel free to post queries on DAO Research and Dev channel and tag @shivgupt (our Open Source Developer Relations Coordinator)","title":"Where do I post queries ?"},{"location":"FAQ/#whom-do-i-contact-for-technical-help-or-for-discussing-integrations","text":"For more one-one technical help and queries DM Shiv on telegram: @shivgupt","title":"Whom do I contact for technical help or for discussing integrations?"},{"location":"feature-requests/","text":"If you want to contribute but don't know where to start, checkout our feature request list. Pick up a task that interests you and match your skills and submit a Proposal to Genesis DAO to get funded. Refer to How to propose guide guide before you submit the proposal Table Guide: \ud83d\udd25 We would like to see this feature implemented, lets discuss the specs \ud83c\udf4e We have prepared the specs but currently no dev team is working on it \u23f0 A Dev team has started working on it Feature Status Github Issue Stack Layer Description Dev Time DAO to DAO relations \ud83c\udf4e #27 Alchemy Allow DAOs to interact with other DAOs by submitting proposals for voting / staking (/ proposing) 2 w Buy GEN with ETH or any token \ud83c\udf4e #1 Alchemy Integrate uniswap / kyber widget to allow the user to directly stake with eth or any other token which will be converted to gen. 2 w Prediction bot \ud83c\udf4e #6 External A bot that will make predictions on daos. It can use public training data as past proposals by the proposer or voters who voted for or against the proposal etc 2-3 w Better representation of the protocol. Help Mode \ud83d\udd25 #15 Alchemy Added tooltips, tours, walkthroughs that explain the genesis protocol 2 w Notification Bot for Alchemy \ud83c\udf4e #7 Alchemy Allow users to subscribe for telegram/email/twitter etc. notification for activities in DAO 2 w Improved Scheme Registrar UX \ud83c\udf4e #11 Alchemy A more simplistic and abstracted interface in order to change the Genesis parameters without wanting to commit seppuku. 2 w DAO treasury management \ud83c\udf4e #3 , #2 , #4 , #5 Alchemy Enable DAO to manage its treasury by re-appropriating its funds via decentralized exchange or deFi Projects 2 w Hashtags \ud83d\udd25 - Caching Alchemy Proposers can freely tag their proposals (e.g. #idea, #norm, #bounty etc), and then anyone can search / filter proposals by tags. Hashtags are case-insensitive (appear only with lower case). At first stage no admin, which means anyone can create any hashtag they want, and likely similarities will appear (#idea, #ideas, #ideation). Currently search available only inside DAO, can have cross-DAO search later 2 w GSN Integration \ud83c\udf4e - External Allow users to participate without a cost, i.e. sponsor the gas fees - Allow another agent to pay for gas, technically - Who can pay for gas: the DAO? other agent? 4 w Twitter player integration \ud83d\udd25 - Alchemy Allow people to interact with dao widgets (voting / proposing etc) inside twitter (e.g. https://twitter.com/sassal0x/status/1109263205606387712) 3 w DAO setup wizard integrated in Alchemy \ud83d\udd25 - Alchemy Allow users to create a new DAO inside alchemy. This includes integrating with the DAO creator by dOrg, but also figuring out the indexing part 4 w Decentralized Social identity integration \ud83d\udd25 - Alchemy Like the existing social identity but decentralised (https://3box.io) 2 w Unseen proposals indicator (in all DAOs) \ud83d\udd25 - Alchemy When a user comes in to the platform again, there's an indication on the dashboard of the number of new proposals in each DAO since his last visited. 1 w Sorting reputation holders \ud83c\udf4e - Alchemy, Caching Client Sorting Reputation holders by: Reputation (top to bottom / bottom to top), Time joined (?), Most active (?), ... ? 2 w Mark proposal as \"read\" / Fade inactive proposal \ud83d\udd25 - Alchemy A user can mark a proposal as \"read\" and it will then be hidden from the interface. The user can toggle a \"view all\" switch to see all the proposals even those she chose to hide... A state change for the proposal (queued pre-boosted) should reset this flag 3 w Alchemy dashboard \ud83d\udd25 - Alchemy Caching This would show stats about the entire DAOstack ecosystem - no. daos, no. proposals, gen staked etc... Could be part of the DAO explorer 2 w Aggregated boosted proposals view \ud83d\udd25 - Alchemy Show the boosted proposals from all the DAOs. This will be useful for predictors 2 w","title":"Feature Requests"},{"location":"hackerkit/","text":"Table of contents DAOs Examples Contact and Help DAOs DAOs can be created for any conceivable collaborative purpose, from local political action to distributed manufacturing and sales. The goal of DAOstack is to make it as easy as possible to create and manage DAOs, and to use them to drive a new decentralized global economy (specifically, an economy that uses GEN, our collective attention token ). DAOstack Technologies has created an initial DAO called \"Genesis\" with the purpose of promoting the GEN/DAO ecosystem. Genesis is currently live on the Ethereum mainnet, has over 200 Reputation-holders who have executed over 170 proposals since August 2018, and can be accessed through \"Alchemy\" . Examples The hackers kit is equipped with several examples and sample projects, which we are working to maintain and expand. The goal for these examples is to help developers easily kickstart a new project, as well as to demonstrate some of the features included in each layer of the DAO stack. Starter Template This is a basic template you can use for kickstarting your project using the DAOstack platform. Here you can find the basic structure for using Arc, Client and Subgraph to build your project. Peep DAO This project is a Dapp for interacting with a DAO which has its own DAO social media account on Peepeth , a decentralized microblogging app. The Dapp allows a DAO post Peeps via a decentralized voting mechanism. DutchX DAO Bootstrap This project contains a minimal UI for participating in the bootstrap of the DutchX DAO. The bootstrapping process for a DAO is the process of distributing its initial reputation and tokens. The DutchX bootstrap process is a 3 months period during which users can do several actions, like locking tokens, in order to receive Reputation in the DutchX DAO. You can view the DutchX DAO bootstrapping contracts here . Firestarter DAO Example Firestarter is a community driven crowdsourcing platform, which utilizes DaoStack for governance of the projects. This is a striped down version of the project, which only showcases the DaoStack integration.","title":"Hacker-kit"},{"location":"hackerkit/#table-of-contents","text":"DAOs Examples Contact and Help","title":"Table of contents"},{"location":"hackerkit/#daos","text":"DAOs can be created for any conceivable collaborative purpose, from local political action to distributed manufacturing and sales. The goal of DAOstack is to make it as easy as possible to create and manage DAOs, and to use them to drive a new decentralized global economy (specifically, an economy that uses GEN, our collective attention token ). DAOstack Technologies has created an initial DAO called \"Genesis\" with the purpose of promoting the GEN/DAO ecosystem. Genesis is currently live on the Ethereum mainnet, has over 200 Reputation-holders who have executed over 170 proposals since August 2018, and can be accessed through \"Alchemy\" .","title":"DAOs"},{"location":"hackerkit/#examples","text":"The hackers kit is equipped with several examples and sample projects, which we are working to maintain and expand. The goal for these examples is to help developers easily kickstart a new project, as well as to demonstrate some of the features included in each layer of the DAO stack.","title":"Examples"},{"location":"hackerkit/#starter-template","text":"This is a basic template you can use for kickstarting your project using the DAOstack platform. Here you can find the basic structure for using Arc, Client and Subgraph to build your project.","title":"Starter Template"},{"location":"hackerkit/#peep-dao","text":"This project is a Dapp for interacting with a DAO which has its own DAO social media account on Peepeth , a decentralized microblogging app. The Dapp allows a DAO post Peeps via a decentralized voting mechanism.","title":"Peep DAO"},{"location":"hackerkit/#dutchx-dao-bootstrap","text":"This project contains a minimal UI for participating in the bootstrap of the DutchX DAO. The bootstrapping process for a DAO is the process of distributing its initial reputation and tokens. The DutchX bootstrap process is a 3 months period during which users can do several actions, like locking tokens, in order to receive Reputation in the DutchX DAO. You can view the DutchX DAO bootstrapping contracts here .","title":"DutchX DAO Bootstrap"},{"location":"hackerkit/#firestarter-dao-example","text":"Firestarter is a community driven crowdsourcing platform, which utilizes DaoStack for governance of the projects. This is a striped down version of the project, which only showcases the DaoStack integration.","title":"Firestarter DAO Example"},{"location":"how-to-propose/","text":"All grants proposals must be submitted directly to the Genesis DAO and must be passed by the Genesis members to get funded. We will use DAOstack-collab repo to coordinate and reduce information asymmetries for developers builders in the DAOstack ecosystem. Choose from the list of Open Issues or work on your idea if you think it aligns with the Community's goal Use the Proposal template to create your own proposal document. Create new PR to DAOstack-collab repo to add your proposal document Create a new Contribution proposal in Genesis DAO and add link to PR in the URL section of the proposal Fill in the details in proposal create form and submit the proposal (This will send tx to Blockchain). NOTE: The PR will be merged if Genesis passes the proposal","title":"Propose to Genesis DAO"},{"location":"migration/","text":"Migration package is useful for handling the migrations of DAOstack contracts and DAOs. You can use this tool to migrate DAOstack base contracts and DAOstack DAOs in production, test or developer mode","title":"Migration"},{"location":"gettingStarted/deployDAO/","text":"Introduction The core contracts required by a daostack DAO are already deployed by the DAOstack team on mainnet as well as testnet and the addresses are available in Migration.json . Though, you will need to deploy following contracts: Avatar : The DAO's account that holds its assets. Controller : Access Control of the DAO. Native Reputation : Voting in Arc is done mainly using Reputation. Native Token : ERC20 token Can be used in any way DAO would like. Custom schemes (if any): Any new universal or non-universal scheme. Refer Structure of DAOstack DAO . How to Deploy? There are 2 recommended ways to deploy DAOstack DAO using Migration package using dOrg DAOcreator dOrg DAOcreator DAOcreator is a tool with user friendly guided interface to launch a new DAO created by dOrg . Limitations of current version: - cannot deploy custom schemes - cannot add multiple generic actions using generic schemes - in alpha stage Process Follow the instructions through the app to deploy the DAO. Copy the output of deployment process, along with a brief description of your DAO and its purpose, and send it to @shivgupt on Telegram or to the dOrg contact as displayed on the output screen. We will submit a PR to github.com/daostack/subgraph on your behalf. Migration package Either from CLI or using javascript. Example and full reference guide can be found at Migration Readme You can also find some example deployment setup and script in the DAOstacker Hacker Kit examples - Starter Template and FireStarter Kit NOTE: Universal Controller and Universal Generic Scheme has been discontinued for arc Version 33. Please make sure of the following: - Set \"useUController\": false - If registering Generic Scheme to the DAO mention it in Custom Scheme section.","title":"Deploy a DAO"},{"location":"gettingStarted/deployDAO/#introduction","text":"The core contracts required by a daostack DAO are already deployed by the DAOstack team on mainnet as well as testnet and the addresses are available in Migration.json . Though, you will need to deploy following contracts: Avatar : The DAO's account that holds its assets. Controller : Access Control of the DAO. Native Reputation : Voting in Arc is done mainly using Reputation. Native Token : ERC20 token Can be used in any way DAO would like. Custom schemes (if any): Any new universal or non-universal scheme. Refer Structure of DAOstack DAO .","title":"Introduction"},{"location":"gettingStarted/deployDAO/#how-to-deploy","text":"There are 2 recommended ways to deploy DAOstack DAO using Migration package using dOrg DAOcreator","title":"How to Deploy?"},{"location":"gettingStarted/deployDAO/#dorg-daocreator","text":"DAOcreator is a tool with user friendly guided interface to launch a new DAO created by dOrg . Limitations of current version: - cannot deploy custom schemes - cannot add multiple generic actions using generic schemes - in alpha stage","title":"dOrg DAOcreator"},{"location":"gettingStarted/deployDAO/#process","text":"Follow the instructions through the app to deploy the DAO. Copy the output of deployment process, along with a brief description of your DAO and its purpose, and send it to @shivgupt on Telegram or to the dOrg contact as displayed on the output screen. We will submit a PR to github.com/daostack/subgraph on your behalf.","title":"Process"},{"location":"gettingStarted/deployDAO/#migration-package","text":"Either from CLI or using javascript. Example and full reference guide can be found at Migration Readme You can also find some example deployment setup and script in the DAOstacker Hacker Kit examples - Starter Template and FireStarter Kit NOTE: Universal Controller and Universal Generic Scheme has been discontinued for arc Version 33. Please make sure of the following: - Set \"useUController\": false - If registering Generic Scheme to the DAO mention it in Custom Scheme section.","title":"Migration package"},{"location":"gettingStarted/setupAlchemyDevMode/","text":"Following is the guide to start developing with Alchemy if you are using already supported schemes by client.js and subgraph . If you have created your own scheme contracts for your DAO, please refer to Add Custom Scheme support tutorial Prerequisites docker = 18.06.1-c docker-compose = 1.22.0 node = 10.16.0 npm = 6.9.0 Overview Alchemy uses Client.js for reading/inferencing blockchain data via DAOstack Subgraph writing/modifying state of Arc contracts Interaction of Alchemy with rest of the stack Boilerplate 1 2 3 git clone https : // github . com / daostack / alchemy . git cd alchemy npm ci Setup Alchemy with Ganache (mode: development) 1 2 3 docker - compose build docker - compose up - d graph - node alchemy - server npm run start The above commands will build docker images and start the following services locally: alchemy-server = for storing proposal information for quick access graph-node = for handling events from blockchain as described in subgraph ganache = dev blockchain with some test DAOs deployed and loaded with GEN and Eth subgraph-ipfs = subgraph mappings on ipfs node subgraph-postgres = db for caching events based on subgraph and later fetched via GraphQL redis = used by alchemy-server for sessions alchemy-postgres Import test accounts that are setup with GEN and ETH to your metamask. You can get the account details by: 1 docker logs alchemy_ganache_1 | head - 35 Now your playground is ready for developing. TODO: Currently webpack does not detect changes in all components and rebuilds only if top-level src/file is changed. For now you can touch the any file in top-level and this should trigger rebuild NOTE: If the feature integration requires you to interact with outside contracts (e.g. uniswap widget integration might require uniswap contracts), then you can simply deploy those contracts to same ganache container using truffle or your own deployment script. See Client.js documentation for more integration details Setup Alchemy with Testnet (mode: staging) Often Ganache does not behave same as production. If you want to setup Alchemy for interacting with testnet and check before you submit PR, then after the boilerplate steps - Choose from one of the following setup for testnet to start playing/integrating features to Alchemy: Use DAOstack rinkeby subgraph Run graph-node locally NOTE: Alchemy only shows daos that are registered via DAOregistry and tracked by DAOstack subgraph for the respective network. You can send the .json of your DAO details to us (contact Nave Rachman, telegram: @NaveRachman) and we will help you. Since above process of registering DAO takes up to 24hrs in following section we provide way to hack it during development and start your own graph-node Use DAOstack rinkeby subgraph Choose this when, using rinkeby testnet working with existing whitelisted DAOs on DAOstack subgraph Run alchemy-server 1 docker - compose up - d alchemy - server Start alchemy in staging mode 1 npm run start - staging Run graph-node locally Choose this when, working with any of the already supported Arc schemes by client Alchemy playing with the DAO that is not yet tracked by DAOstack subgraph Make following changes: Clone subgraph repo and start-graph node locally 1 2 3 git clone git @github . com : daostack / subgraph . git cd subgraph npm i Setup .env file and run rinkeby graph node 1 2 3 4 5 6 7 8 // Following are example values please change for customization network = rinkeby subgraph = daostack postgres_password = letmein ethereum_node = https://rinkeby.infura.io/v3/e0cdf3bfda9b468fa908aa6ab03d5ba2 npm run docker : run - rinkeby Update your DAO details in daos/rinkeby/ DAO-Name .json and deploy subgraph 1 npm run deploy { migrationFile : ../migration.json } Go back to alchemy and Update webpack.dev.config.js , add following process variables 1 2 3 ARC_GRAPHQLHTTPPROVIDER : http://127.0.0.1:8000/subgraphs/name/daostack , ARC_GRAPHQLWSPROVIDER : ws://127.0.0.1:8001/subgraphs/name/daostack , ARC_IPFSPROVIDER : localhost NOTE: If you changed name of subgraph while setting up .env in step 1 then change it in this step accordingly Run alchemy-server 1 docker - compose up - d alchemy - server Start alchemy in staging mode 1 npm run start - staging","title":"Add features to Alchemy interface"},{"location":"gettingStarted/setupAlchemyDevMode/#prerequisites","text":"docker = 18.06.1-c docker-compose = 1.22.0 node = 10.16.0 npm = 6.9.0","title":"Prerequisites"},{"location":"gettingStarted/setupAlchemyDevMode/#overview","text":"Alchemy uses Client.js for reading/inferencing blockchain data via DAOstack Subgraph writing/modifying state of Arc contracts Interaction of Alchemy with rest of the stack","title":"Overview"},{"location":"gettingStarted/setupAlchemyDevMode/#boilerplate","text":"1 2 3 git clone https : // github . com / daostack / alchemy . git cd alchemy npm ci","title":"Boilerplate"},{"location":"gettingStarted/setupAlchemyDevMode/#setup-alchemy-with-ganache-mode-development","text":"1 2 3 docker - compose build docker - compose up - d graph - node alchemy - server npm run start The above commands will build docker images and start the following services locally: alchemy-server = for storing proposal information for quick access graph-node = for handling events from blockchain as described in subgraph ganache = dev blockchain with some test DAOs deployed and loaded with GEN and Eth subgraph-ipfs = subgraph mappings on ipfs node subgraph-postgres = db for caching events based on subgraph and later fetched via GraphQL redis = used by alchemy-server for sessions alchemy-postgres Import test accounts that are setup with GEN and ETH to your metamask. You can get the account details by: 1 docker logs alchemy_ganache_1 | head - 35 Now your playground is ready for developing. TODO: Currently webpack does not detect changes in all components and rebuilds only if top-level src/file is changed. For now you can touch the any file in top-level and this should trigger rebuild NOTE: If the feature integration requires you to interact with outside contracts (e.g. uniswap widget integration might require uniswap contracts), then you can simply deploy those contracts to same ganache container using truffle or your own deployment script. See Client.js documentation for more integration details","title":"Setup Alchemy with Ganache (mode: development)"},{"location":"gettingStarted/setupAlchemyDevMode/#setup-alchemy-with-testnet-mode-staging","text":"Often Ganache does not behave same as production. If you want to setup Alchemy for interacting with testnet and check before you submit PR, then after the boilerplate steps - Choose from one of the following setup for testnet to start playing/integrating features to Alchemy: Use DAOstack rinkeby subgraph Run graph-node locally NOTE: Alchemy only shows daos that are registered via DAOregistry and tracked by DAOstack subgraph for the respective network. You can send the .json of your DAO details to us (contact Nave Rachman, telegram: @NaveRachman) and we will help you. Since above process of registering DAO takes up to 24hrs in following section we provide way to hack it during development and start your own graph-node","title":"Setup Alchemy with Testnet (mode: staging)"},{"location":"gettingStarted/setupAlchemyDevMode/#use-daostack-rinkeby-subgraph","text":"Choose this when, using rinkeby testnet working with existing whitelisted DAOs on DAOstack subgraph Run alchemy-server 1 docker - compose up - d alchemy - server Start alchemy in staging mode 1 npm run start - staging","title":"Use DAOstack rinkeby subgraph"},{"location":"gettingStarted/setupAlchemyDevMode/#run-graph-node-locally","text":"Choose this when, working with any of the already supported Arc schemes by client Alchemy playing with the DAO that is not yet tracked by DAOstack subgraph Make following changes: Clone subgraph repo and start-graph node locally 1 2 3 git clone git @github . com : daostack / subgraph . git cd subgraph npm i Setup .env file and run rinkeby graph node 1 2 3 4 5 6 7 8 // Following are example values please change for customization network = rinkeby subgraph = daostack postgres_password = letmein ethereum_node = https://rinkeby.infura.io/v3/e0cdf3bfda9b468fa908aa6ab03d5ba2 npm run docker : run - rinkeby Update your DAO details in daos/rinkeby/ DAO-Name .json and deploy subgraph 1 npm run deploy { migrationFile : ../migration.json } Go back to alchemy and Update webpack.dev.config.js , add following process variables 1 2 3 ARC_GRAPHQLHTTPPROVIDER : http://127.0.0.1:8000/subgraphs/name/daostack , ARC_GRAPHQLWSPROVIDER : ws://127.0.0.1:8001/subgraphs/name/daostack , ARC_IPFSPROVIDER : localhost NOTE: If you changed name of subgraph while setting up .env in step 1 then change it in this step accordingly Run alchemy-server 1 docker - compose up - d alchemy - server Start alchemy in staging mode 1 npm run start - staging","title":"Run graph-node locally"},{"location":"gettingStarted/setupGenericScheme/","text":"Generic Schemes In DAOstack, \"schemes\" are smart contracts that enable various DAO actions, and \"generic schemes\" are schemes that enable nearly any kind of action possible for an Ethereum address. DAOs can use GenericScheme : to enable truly generic DAO actions (letting proposers choose which contracts to interact with and how), to create specific, custom integrations (actions that make particular calls to particular smart contracts that serve a particular purpose for the DAO). NOTE : If a DAO wants to make multiple smart contracts available, with different labels and proposal types in the UI, then each contract should use its own GenericScheme instance, customized if required for the DAO's purpose. While at the contract level, generic schemes only need encoded call data to function, asking users to provide this data is not good UX. If you're using a generic scheme for anything except a truly generic action, which is only accessible to Ethereum experts, we ask that you add Alchemy support for the specific actions you intend. Please do not register your scheme on mainnet without adding alchemy support for it. Here is an example of a customized generic scheme on mainnet. UGenericScheme i.e. the universal version of the generic scheme has been deprecated and removed from arc ( version 33). Subgraph and Alchemy will be backward compatible and support old DAOs already deployed and using it. How to register a Generic Scheme to a DAO A DAO can only use schemes that are registered with its controller. There are two ways to register a scheme to a DAO's controller: During the DAO's creation, while deploying the DAO's contracts Through a proposal that uses a scheme with permission to register schemes to the DAO. NOTE: In case of the Genesis DAO, you can propose new schemes to be registered using the aptly named Scheme Registrar scheme. Register a Generic Scheme while deploying a DAO While deploying DAO you can register multiple \"GenericScheme\" instances and mention each in the customSchemes section of your migration-dao-params.json . Example 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 CustomSchemes : [ { name : GenericScheme , schemeName : GenericScheme , params :[ GenesisProtocolAddress , { voteParams : 1 }, ENS_PUBLIC_RESOLVER ], permissions : 0x00000010 , alias : GenericSchemeENSPublicProvider , fromArc : true } ] , Refer to the instructions for how to deploy DAO . Register Generic Scheme to an already deployed DAO If the DAO has a Scheme Registrar scheme, then you can register new schemes to DAO via a proposal. Registering a new scheme via registrar requires: - Set voting Machine Parameters (if other than already saved) - Submit proposal to Scheme Registrar Set Voting Machine Parameters If your Generic Scheme use vote parameters other than the ones already registered with Genesis Protocol (voting machine), then use setParameter to register new vote parameters. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 const genesisProtocolJson = require ( @daostack/arc/build/contracts/GenesisProtocol.json ) const genesisProtocolContract = new web3 . eth . Contract ( genesisProtocolJson . abi , GenesisProtocolAddress , // Get this from migration.json file { from , gas , gasPrice } ) // Following are example values, Please change appropriately // Refer https://daostack.zendesk.com/hc/en-us/sections/360000535638-Genesis-Protocol const voteParams = { boostedVotePeriodLimit : 345600 , daoBountyConst : 10 , minimumDaoBountyGWei : 150000000000 , queuedVotePeriodLimit : 2592000 , queuedVoteRequiredPercentage : 50 , preBoostedVotePeriodLimit : 86400 , proposingRepRewardGwei : 50000000000 , quietEndingPeriod : 172800 , thresholdConst : 1200 , voteOnBehalf : 0x0000000000000000000000000000000000000000 , votersReputationLossRatio : 4 , activationTime : 0 } const parameters = [ [ voteParams . queuedVoteRequiredPercentage . toString (), voteOnBehalf . queuedVotePeriodLimit . toString (), votersReputationLossRatio . boostedVotePeriodLimit . toString (), voteParams . preBoostedVotePeriodLimit . toString (), voteOnBehalf . thresholdConst . toString (), votersReputationLossRatio . quietEndingPeriod . toString (), voteParams . proposingRepRewardGwei . toString (), voteOnBehalf . votersReputationLossRatio . toString (), voteParams . minimumDaoBountyGWei . toString (), voteOnBehalf . daoBountyConst . toString (), votersReputationLossRatio . activationTime . toString (), ], voteParams . voteOnBehalf , ] const genesisProtocolSetParams = genesisProtocolContract . methods . setParameters (... parameters ) genesisProtocolSetParams . send () Set Generic Scheme to interact with your contract Now, you will have to deploy a new instance of GenericScheme and use its initialize method to setup its params: the DAO Avatar it connects to, the contractToCall , the votingMachine to use, the voteParameters for voting on proposals that use the scheme. The following is a short script that shows how to do this: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 const genericSchemeJson = require ( @daostack/arc/build/contracts/GenericScheme.json ) const genericSchemeContract = new web3 . eth . Contract ( genericSchemeJson . abi , undefined , { from , gas , gasPrice } ) // Deploy New GenericScheme Instance const genericSchemeDeployedContract = genericSchemeContract . deploy ({ data : genericSchemeJson . bytecode , arguments : null }). send () let genericScheme = await genericSchemeDeployedContract // Log Address of new instance to use in next step while registering the scheme to DAO console . log ( `Deployed new GenericScheme instance at ${ genericScheme . options . address } ` ) // Get address from https://github.com/daostack/migration/blob/master/migration.json const votingMachineAddress = 0xaddress-of-VotingMachine-of-DAO-on-given-network // For eg if you want this Generic Scheme to enable DAO to interact with Bounties Network // then targetContract would be the address of Bounties Network s respective contract const targetContractAddress = 0xaddress-of-contract-this-will-interact-with const avatar = 0xaddres-of-DAO const paramHash = 0xVote-Param-Hash-from-previous-step genericScheme . methods . initialize ( avatar , paramHash , votingMachineAddress , targetContractAddress ). send () Submit a new proposal to the Scheme Registrar via Alchemy UI On Alchemy's landing page, choose the DAO to which you wish to register the scheme. Visit the DAO's Home page and choose Scheme Registrar . Click New Proposal \u2013 this will open a popup. Select Add Scheme on the popup sidebar (on the left). Give the proposal an appropriate title, description, and url linking to a description of the proposal. For Scheme , put the address of your Generic Scheme contract. The paramHash can be null for non universal scheme. In the permissions section, check Call genericCall on behalf of (this will allow your scheme to make generic calls, which is the whole point here). Submit the proposal and sign the transaction as normal. If the DAO passes your proposal, then your Generic Scheme with the ability to interact with the targetContract will be registered to the DAO, and people will be able to submit proposals for the DAO to take your custom generic action. How to get Generic Scheme indexed by DAOstack subgraph The DAOstack subgraph enables Alchemy's quick loading of cached blockchain data and is a huge part of creating a positive user experience in Alchemy. You will have to submit a PR here 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 1 . Make sure to choose the correct Ethereum network for your DAO 2 . If the scheme is for a new DAO , then add ` YourDAO . json ` in that network folder . eg . { name : New DAO , Avatar : 0xaddress-of-avatar-on-this-network , DAOToken : 0xaddress-of-daotoken-on-this-network , Reputation : 0xaddress-of-nativereputation-on-this-network , Controller : 0xaddress-of-controller-on-this-network , Schemes : { GenesisScheme : 0xaddress-of-genericScheme-on-this-network }, arcVersion : 0.0.1-rc.22 # choose the correct arc version } 3 . If the scheme is for an already existing DAO , then edit ` existing - DAO . json ` for the correct network . Add to the schemes section , eg . Schemes : { GenesisScheme : 0xaddress-of-genericScheme-on-this-network }, arcVersion : 0.0.1-rc.22 # choose the correct arc version How to get your Generic Scheme showing up in Alchemy To help you get a user-friendly interface for your generic scheme, we have created a way to customize Alchemy's UI for specific generic schemes. The customization has a few pieces, and you will have to submit a PR to the Alchemy repo once you're finished with it. Proposal Creation Interface Customize the \"create proposal\" popup to present the different functions the scheme can call on the contract. This requires adding the contracts\u2019 ABI and customizing things like the titles of the labels and placeholders. If this was a generic scheme for interacting with the Bounties Network, you would create a file named something like Bounties.json and add it here . Use the following example or refer to an example using the DutchX integration. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 // Bounties.json { name : Bounties , address : { main : [ 0xtarget-contract-address-on-mainnet ], rinkeby : [], private : [] }, actions : [ { id : createBountyMethod-from-contract , label : Create Bounty , description : This method will create a bounty with the DAO as the issuer , notes : , fields : [ { label : bounty title , name : name-of-field-in-abi , placeholder : Osam Bin-Laden - dead or alive }, { // more feilds if any }, ], abi : {}, }, { // more methods of contract if any } ], } Update Known Schemes Once you have customised the proposal create interface update the genericSchemeRegistry For eg. In case of StandardBounty scheme we will add: 1 2 3 4 5 6 const standardBountiesInfo = require ( ./schemes/StandardBounties.json ) const KNOWNSCHEMES = [ ..., standardBountiesInfo ]; Proposal Display Interface You will also have to customise the description summary for your scheme to explain what it does. Refer to the ProposalSummaryDutchX and add your own proposal summary file, say ProposalSummaryBountiesNetwork.tsx , here . Update Proposal Summary render Once you have created the proposal summary make sure that it gets rendered by updating ProposalSummaryKnownGenericScheme.tsx For eg. In case of StandardBounty scheme we will add: 1 2 3 4 import ProposalSummaryStandardBounties from ./ProposalSummaryStandardBounties ; if ( genericSchemeInfo . specs . name === StandardBounties ) { return ProposalSummaryStandardBounties { ... this . props } / ; Integration tests Please add the relevant integration test for your scheme. You can refer to genericSchemeDutchx tests. (Optional) Change the Scheme UI Right now, Alchemy\u2019s UI is only focused on currently open proposals (it does not show past proposals). But based on the scheme you are adding, there might be some different UI features/tabs that are required. For a bounties scheme, for example, it would be helpful to have a new tab that shows open bounties (from proposals that have already been passed).","title":"Setup Generic Scheme for a DAO"},{"location":"gettingStarted/setupGenericScheme/#generic-schemes","text":"In DAOstack, \"schemes\" are smart contracts that enable various DAO actions, and \"generic schemes\" are schemes that enable nearly any kind of action possible for an Ethereum address. DAOs can use GenericScheme : to enable truly generic DAO actions (letting proposers choose which contracts to interact with and how), to create specific, custom integrations (actions that make particular calls to particular smart contracts that serve a particular purpose for the DAO). NOTE : If a DAO wants to make multiple smart contracts available, with different labels and proposal types in the UI, then each contract should use its own GenericScheme instance, customized if required for the DAO's purpose. While at the contract level, generic schemes only need encoded call data to function, asking users to provide this data is not good UX. If you're using a generic scheme for anything except a truly generic action, which is only accessible to Ethereum experts, we ask that you add Alchemy support for the specific actions you intend. Please do not register your scheme on mainnet without adding alchemy support for it. Here is an example of a customized generic scheme on mainnet. UGenericScheme i.e. the universal version of the generic scheme has been deprecated and removed from arc ( version 33). Subgraph and Alchemy will be backward compatible and support old DAOs already deployed and using it.","title":"Generic Schemes"},{"location":"gettingStarted/setupGenericScheme/#how-to-register-a-generic-scheme-to-a-dao","text":"A DAO can only use schemes that are registered with its controller. There are two ways to register a scheme to a DAO's controller: During the DAO's creation, while deploying the DAO's contracts Through a proposal that uses a scheme with permission to register schemes to the DAO. NOTE: In case of the Genesis DAO, you can propose new schemes to be registered using the aptly named Scheme Registrar scheme.","title":"How to register a Generic Scheme to a DAO"},{"location":"gettingStarted/setupGenericScheme/#register-a-generic-scheme-while-deploying-a-dao","text":"While deploying DAO you can register multiple \"GenericScheme\" instances and mention each in the customSchemes section of your migration-dao-params.json . Example 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 CustomSchemes : [ { name : GenericScheme , schemeName : GenericScheme , params :[ GenesisProtocolAddress , { voteParams : 1 }, ENS_PUBLIC_RESOLVER ], permissions : 0x00000010 , alias : GenericSchemeENSPublicProvider , fromArc : true } ] , Refer to the instructions for how to deploy DAO .","title":"Register a Generic Scheme while deploying a DAO"},{"location":"gettingStarted/setupGenericScheme/#register-generic-scheme-to-an-already-deployed-dao","text":"If the DAO has a Scheme Registrar scheme, then you can register new schemes to DAO via a proposal. Registering a new scheme via registrar requires: - Set voting Machine Parameters (if other than already saved) - Submit proposal to Scheme Registrar","title":"Register Generic Scheme to an already deployed DAO"},{"location":"gettingStarted/setupGenericScheme/#set-voting-machine-parameters","text":"If your Generic Scheme use vote parameters other than the ones already registered with Genesis Protocol (voting machine), then use setParameter to register new vote parameters. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 const genesisProtocolJson = require ( @daostack/arc/build/contracts/GenesisProtocol.json ) const genesisProtocolContract = new web3 . eth . Contract ( genesisProtocolJson . abi , GenesisProtocolAddress , // Get this from migration.json file { from , gas , gasPrice } ) // Following are example values, Please change appropriately // Refer https://daostack.zendesk.com/hc/en-us/sections/360000535638-Genesis-Protocol const voteParams = { boostedVotePeriodLimit : 345600 , daoBountyConst : 10 , minimumDaoBountyGWei : 150000000000 , queuedVotePeriodLimit : 2592000 , queuedVoteRequiredPercentage : 50 , preBoostedVotePeriodLimit : 86400 , proposingRepRewardGwei : 50000000000 , quietEndingPeriod : 172800 , thresholdConst : 1200 , voteOnBehalf : 0x0000000000000000000000000000000000000000 , votersReputationLossRatio : 4 , activationTime : 0 } const parameters = [ [ voteParams . queuedVoteRequiredPercentage . toString (), voteOnBehalf . queuedVotePeriodLimit . toString (), votersReputationLossRatio . boostedVotePeriodLimit . toString (), voteParams . preBoostedVotePeriodLimit . toString (), voteOnBehalf . thresholdConst . toString (), votersReputationLossRatio . quietEndingPeriod . toString (), voteParams . proposingRepRewardGwei . toString (), voteOnBehalf . votersReputationLossRatio . toString (), voteParams . minimumDaoBountyGWei . toString (), voteOnBehalf . daoBountyConst . toString (), votersReputationLossRatio . activationTime . toString (), ], voteParams . voteOnBehalf , ] const genesisProtocolSetParams = genesisProtocolContract . methods . setParameters (... parameters ) genesisProtocolSetParams . send ()","title":"Set Voting Machine Parameters"},{"location":"gettingStarted/setupGenericScheme/#set-generic-scheme-to-interact-with-your-contract","text":"Now, you will have to deploy a new instance of GenericScheme and use its initialize method to setup its params: the DAO Avatar it connects to, the contractToCall , the votingMachine to use, the voteParameters for voting on proposals that use the scheme. The following is a short script that shows how to do this: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 const genericSchemeJson = require ( @daostack/arc/build/contracts/GenericScheme.json ) const genericSchemeContract = new web3 . eth . Contract ( genericSchemeJson . abi , undefined , { from , gas , gasPrice } ) // Deploy New GenericScheme Instance const genericSchemeDeployedContract = genericSchemeContract . deploy ({ data : genericSchemeJson . bytecode , arguments : null }). send () let genericScheme = await genericSchemeDeployedContract // Log Address of new instance to use in next step while registering the scheme to DAO console . log ( `Deployed new GenericScheme instance at ${ genericScheme . options . address } ` ) // Get address from https://github.com/daostack/migration/blob/master/migration.json const votingMachineAddress = 0xaddress-of-VotingMachine-of-DAO-on-given-network // For eg if you want this Generic Scheme to enable DAO to interact with Bounties Network // then targetContract would be the address of Bounties Network s respective contract const targetContractAddress = 0xaddress-of-contract-this-will-interact-with const avatar = 0xaddres-of-DAO const paramHash = 0xVote-Param-Hash-from-previous-step genericScheme . methods . initialize ( avatar , paramHash , votingMachineAddress , targetContractAddress ). send ()","title":"Set Generic Scheme to interact with your contract"},{"location":"gettingStarted/setupGenericScheme/#submit-a-new-proposal-to-the-scheme-registrar-via-alchemy-ui","text":"On Alchemy's landing page, choose the DAO to which you wish to register the scheme. Visit the DAO's Home page and choose Scheme Registrar . Click New Proposal \u2013 this will open a popup. Select Add Scheme on the popup sidebar (on the left). Give the proposal an appropriate title, description, and url linking to a description of the proposal. For Scheme , put the address of your Generic Scheme contract. The paramHash can be null for non universal scheme. In the permissions section, check Call genericCall on behalf of (this will allow your scheme to make generic calls, which is the whole point here). Submit the proposal and sign the transaction as normal. If the DAO passes your proposal, then your Generic Scheme with the ability to interact with the targetContract will be registered to the DAO, and people will be able to submit proposals for the DAO to take your custom generic action.","title":"Submit a new proposal to the Scheme Registrar via Alchemy UI"},{"location":"gettingStarted/setupGenericScheme/#how-to-get-generic-scheme-indexed-by-daostack-subgraph","text":"The DAOstack subgraph enables Alchemy's quick loading of cached blockchain data and is a huge part of creating a positive user experience in Alchemy. You will have to submit a PR here 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 1 . Make sure to choose the correct Ethereum network for your DAO 2 . If the scheme is for a new DAO , then add ` YourDAO . json ` in that network folder . eg . { name : New DAO , Avatar : 0xaddress-of-avatar-on-this-network , DAOToken : 0xaddress-of-daotoken-on-this-network , Reputation : 0xaddress-of-nativereputation-on-this-network , Controller : 0xaddress-of-controller-on-this-network , Schemes : { GenesisScheme : 0xaddress-of-genericScheme-on-this-network }, arcVersion : 0.0.1-rc.22 # choose the correct arc version } 3 . If the scheme is for an already existing DAO , then edit ` existing - DAO . json ` for the correct network . Add to the schemes section , eg . Schemes : { GenesisScheme : 0xaddress-of-genericScheme-on-this-network }, arcVersion : 0.0.1-rc.22 # choose the correct arc version","title":"How to get Generic Scheme indexed by DAOstack subgraph"},{"location":"gettingStarted/setupGenericScheme/#how-to-get-your-generic-scheme-showing-up-in-alchemy","text":"To help you get a user-friendly interface for your generic scheme, we have created a way to customize Alchemy's UI for specific generic schemes. The customization has a few pieces, and you will have to submit a PR to the Alchemy repo once you're finished with it.","title":"How to get your Generic Scheme showing up in Alchemy"},{"location":"gettingStarted/setupGenericScheme/#proposal-creation-interface","text":"Customize the \"create proposal\" popup to present the different functions the scheme can call on the contract. This requires adding the contracts\u2019 ABI and customizing things like the titles of the labels and placeholders. If this was a generic scheme for interacting with the Bounties Network, you would create a file named something like Bounties.json and add it here . Use the following example or refer to an example using the DutchX integration. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 // Bounties.json { name : Bounties , address : { main : [ 0xtarget-contract-address-on-mainnet ], rinkeby : [], private : [] }, actions : [ { id : createBountyMethod-from-contract , label : Create Bounty , description : This method will create a bounty with the DAO as the issuer , notes : , fields : [ { label : bounty title , name : name-of-field-in-abi , placeholder : Osam Bin-Laden - dead or alive }, { // more feilds if any }, ], abi : {}, }, { // more methods of contract if any } ], }","title":"Proposal Creation Interface"},{"location":"gettingStarted/setupGenericScheme/#update-known-schemes","text":"Once you have customised the proposal create interface update the genericSchemeRegistry For eg. In case of StandardBounty scheme we will add: 1 2 3 4 5 6 const standardBountiesInfo = require ( ./schemes/StandardBounties.json ) const KNOWNSCHEMES = [ ..., standardBountiesInfo ];","title":"Update Known Schemes"},{"location":"gettingStarted/setupGenericScheme/#proposal-display-interface","text":"You will also have to customise the description summary for your scheme to explain what it does. Refer to the ProposalSummaryDutchX and add your own proposal summary file, say ProposalSummaryBountiesNetwork.tsx , here .","title":"Proposal Display Interface"},{"location":"gettingStarted/setupGenericScheme/#update-proposal-summary-render","text":"Once you have created the proposal summary make sure that it gets rendered by updating ProposalSummaryKnownGenericScheme.tsx For eg. In case of StandardBounty scheme we will add: 1 2 3 4 import ProposalSummaryStandardBounties from ./ProposalSummaryStandardBounties ; if ( genericSchemeInfo . specs . name === StandardBounties ) { return ProposalSummaryStandardBounties { ... this . props } / ;","title":"Update Proposal Summary render"},{"location":"gettingStarted/setupGenericScheme/#integration-tests","text":"Please add the relevant integration test for your scheme. You can refer to genericSchemeDutchx tests.","title":"Integration tests"},{"location":"gettingStarted/setupGenericScheme/#optional-change-the-scheme-ui","text":"Right now, Alchemy\u2019s UI is only focused on currently open proposals (it does not show past proposals). But based on the scheme you are adding, there might be some different UI features/tabs that are required. For a bounties scheme, for example, it would be helpful to have a new tab that shows open bounties (from proposals that have already been passed).","title":"(Optional) Change the Scheme UI"},{"location":"gettingStarted/customScheme/clientForNewScheme/","text":"You might want to update client library while working on Alchemy integration if you added new contract or updated subgraph In this client tutorial we will extend client library to interact with the previous non-universal example scheme BuyInWithRageQuitOpt Pre Work Make sure you have cloned DAOstack client repo , if you have not already Update Client In order to extend client support for the new scheme you will have to add the following: New Scheme Class New Entity Class Integration Test ( Merging code without testing is a risky business \ud83d\ude01) Some case dependent updates Add new scheme class Create file client/src/schemes/BuyInWithRageQuitOpt.ts that exports the new scheme class to enable client to interact with the scheme contract Please refer to Example Scheme Class NOTE: You will need to add abi of the contract in client/src , if it does not exist in @daostack/arc Client library use toIOperationObservable to create observables to get 3rd confirmation update Example Scheme class 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 import BN = require ( bn.js ) import { from } from rxjs import { concatMap } from rxjs/operators import buyInWithRageQuitOptScheme = require ( ./BuyInWithRageQuitOpt.json ) import { Operation , toIOperationObservable } from ../operation import { Scheme } from ../scheme import { Deposit } from ../deposit export class BuyInWithRageQuitOptScheme { constructor ( public scheme : Scheme ) { } err = ( error : Error ): Error = { return error } public deposit ( amount : BN ): Operation Deposit | null { const observable = from ( this . getContract ()) . pipe ( concatMap (( buyInWithRageQuitOpt ) = { const transaction = { value : amount , tx : buyInWithRageQuitOpt . methods . deposit () } const map = ( receipt : any ) = { const event = receipt . events . buyIn if ( ! event ) { return null } return new Deposit ({ amount : event . returnValues . _amount , member : event . returnValues . _member . toLowerCase (), dao : event . returnValues . _avatar . toLowerCase (), rep : event . returnValues . _rep }, this . scheme . context ) } return this . scheme . context . sendTransaction ( transaction , map , this . err ) }) ) return toIOperationObservable ( observable ) } public quit (): Operation Quit | null { const observable = from ( this . getContract ()) . pipe ( concatMap (( buyInWithRageQuitOpt ) = { const transaction = buyInWithRageQuitOpt . methods . quit () const map = ( receipt : any ) = { const event = receipt . events . buyIn if ( ! event ) { return null } return new Quit ({ amount : event . returnValues . _amount , memberAddress : event . returnValues . _memberAddress , dao : event . returnValues . _avatar , rep : event . returnValues . _rep }, this . scheme . context ) } return this . scheme . context . sendTransaction ( transaction , map , this . err ) }) ) return toIOperationObservable ( observable ) } private async getContract () { const state = await this . scheme . fetchStaticState () return this . scheme . context . getContract ( state . address , buyInWithRageQuitOptScheme . abi ) } } Add new Entity class Enable client library to interact with the Entities added to subgraph during previous step (Upgrade subgraph) Add relevant IEntityStaticState, IEntityState and IEntityQueryOptions interface Each Entity class must have following methods: state : that takes IEntityQueryOptions and returns Entity Observable from graphQL query setStaticState : that sets IEntityStaticState fetchStaticState : that returns IEntityStaticState observable state : that returns IEntityState observable Please refer to example Deposit Entity class Example Entity Class 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 import gql from graphql-tag import { Observable } from rxjs import { first } from rxjs/operators import { Arc , IApolloQueryOptions } from ./arc import { Address , ICommonQueryOptions , IStateful } from ./types import { BN , createGraphQlQuery , isAddress } from ./utils export interface IDepositStaticState { id ? : string member : Address amount : typeof BN rep : typeof BN dao : Address } export interface IDepositState extends IDepositStaticState { id : string } export interface IDepositQueryOptions extends ICommonQueryOptions { where ? : { id ? : string member ? : Address dao ? : Address [ key : string ]: any } } export class Deposit implements IStateful IDepositState { /** * Deposit . search ( context , options ) searches for deposit entities * @param context an Arc instance that provides connection information * @param options the query options , cf . IDepositQueryOptions * @return an observable of Deposit objects */ public static search ( context : Arc , options : IDepositQueryOptions = {}, apolloQueryOptions : IApolloQueryOptions = {} ): Observable Deposit [] { if ( ! options . where ) { options . where = {}} let where = let daoFilter : ( r : any ) = boolean daoFilter = () = true for ( const key of Object . keys ( options . where )) { if ( options . where [ key ] === undefined ) { continue } if ( key === member || key === dao ) { const option = options . where [ key ] as string isAddress ( option ) options . where [ key ] = option . toLowerCase () } else { where += `${key}: ${options.where[key] as string} \\n` } } const query = gql ` query DepositSearch { deposits $ { createGraphQlQuery ( options , where )} { id member amount avatar rep } } ` return context . getObservableListWithFilter ( query , ( r : any ) = { return new Deposit ({ id : r . id , member : r . member , amount : new BN ( r . amount || 0 ), dao : r . avatar , rep : new BN ( r . rep || 0 ) }, context ) }, daoFilter , apolloQueryOptions ) as Observable Deposit [] } public id : string | undefined public staticState : IDepositStaticState | undefined constructor ( idOrOpts : string | IDepositStaticState , public context : Arc ) { if ( typeof idOrOpts === string ) { this . id = idOrOpts } else { const opts = idOrOpts as IDepositStaticState this . id = opts . id this . setStaticState ( opts ) } } public setStaticState ( opts : IDepositStaticState ) { this . staticState = opts } public async fetchStaticState (): Promise IDepositStaticState { if ( !! this . staticState ) { return this . staticState } else { return await this . state () . pipe ( first ()) . toPromise () } } public state ( apolloQueryOptions : IApolloQueryOptions = {}): Observable IDepositState { const query = gql ` query DepositById { deposit ( id : ${this.id} ) { id memberAddress amount avatar rep } } ` const itemMap = ( item : any ): IDepositState = { if ( item === null ) { throw Error ( `Could not find a Vote with id ${this.id}` ) } return { amount : item . amount , dao : item . dao , id : item . id , member : item . member , rep : item . rep } } return this . context . getObservableObject ( query , itemMap , apolloQueryOptions ) } } Integration Tests Add relevant integration test for the new scheme, client/test/scheme-buyInWithRageQuitOpt.spec.ts Start test watcher while you test and update the client 1 npm run test : watch : client -- test/scheme-buyInWithRageQuitOpt.spec.ts Refer to example Test BuyInWithRageQuitOpt Scheme Example Test BuyInWithRageQuitOpt Scheme Following is an example integration test file to test the sample non-universal scheme we developed in this tutorial 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 import { Scheme } from ../src/scheme import { Arc } from ../src/arc import { DAO } from ../src/dao import { first } from rxjs/operators import { Reputation } from ../src/reputation import { Deposit } from ../src/deposit import { BN , getTestDAO , getTestAddresses , newArc , toWei , waitUntilTrue } from ./utils jest . setTimeout ( 60000 ) /** * Scheme test */ describe ( Deposit to buy reputaion , () = { let addresses : any let arc : Arc let dao : DAO let scheme : Scheme let daoBalanceBefore : undefined let reputationBefore : undefined let eventLengthBefore : number let reputation : any let amount = toWei ( 0.1 ) let response : any const getEventLength = async () = { let deposits = await Deposit . search ( arc , { where : { member : arc . web3 . eth . defaultAccount }}, { fetchPolicy : no-cache } ) . pipe ( first ()) . toPromise () return deposits . length } beforeAll ( async () = { arc = await newArc () addresses = getTestAddresses ( arc ) dao = await getTestDAO () scheme = new Scheme ({ address : 0x6d065a54f0a14cb03b949a146dbb58c14a0afc48 , dao : dao . id , id : 0x992c72e5e965d11a318839b554b0330dcb3ac81dc2ac0e4e57ba2c15660a3564 , name : BuyInWithRageQuitOpt , paramsHash : 0x0000000000000000000000000000000000000000000000000000000000000000 }, arc ) reputation = new Reputation ( addresses . dao . Reputation , arc ) daoBalanceBefore = await dao . ethBalance () . pipe ( first ()) . toPromise () reputationBefore = await reputation . reputationOf ( arc . web3 . eth . defaultAccount ) . pipe ( first ()) . toPromise () eventLengthBefore = await getEventLength () expect ( scheme . BuyInWithRageQuitOpt ) . not . toBeFalsy () if ( scheme . BuyInWithRageQuitOpt ) { response = await scheme . BuyInWithRageQuitOpt . deposit ( amount ) . send () expect ( response ) } }) it ( Should increase DAO balance by amount deposited , async () = { let daoBalanceAfter = await dao . ethBalance () . pipe ( first ()) . toPromise () expect ( Number ( daoBalanceAfter ) - Number ( daoBalanceBefore )) . toEqual ( Number ( amount )) }) it ( Should increase reputation of Member by amount deposited , async () = { let reputationAfter = new BN ( await reputation . contract () . methods . balanceOf ( arc . web3 . eth . defaultAccount ) . call ()) expect ( Number ( reputationAfter ) - Number ( reputationBefore )) . toEqual ( Number ( amount )) }) it ( Should index the deposit event , async () = { const state0 = await response . result . fetchStaticState () expect ( state0 ) . toMatchObject ({ amount : amount . toString (), member : arc . web3 . eth . defaultAccount . toLowerCase (), dao : dao . id . toLowerCase (), rep : amount . toString () }) let eventLengthAfter = eventLengthBefore const depositIsIndexed = async () = { eventLengthAfter = await getEventLength () return eventLengthAfter - eventLengthBefore 0 } await waitUntilTrue ( depositIsIndexed ) expect ( eventLengthAfter - 1 ) . toEqual ( eventLengthBefore ) }) }) describe ( Quit to refund funds , () = { // add more tests }) Extra Interoperability updates (may differ per use case) Apart from the above standard updates you might need to update some other files depending on the scheme you are adding. For eg. In case of BuyInWithRageQuitOpt Scheme , we added to following files: src/scheme.ts : To add BuyInWithRageQuitOpt to ISchemeState src/operation.ts : To enable passing custom value to this.scheme.context.sendTransaction test/utils.ts : To update LATEST_ARC_VERSION and to getTestAddresses of our newly created DAO instead of test DAO test/migration.json : To use the migration file we got in the migration step (which has details of our DAO and new scheme`","title":"Client: interact with new Scheme"},{"location":"gettingStarted/customScheme/clientForNewScheme/#pre-work","text":"Make sure you have cloned DAOstack client repo , if you have not already","title":"Pre Work"},{"location":"gettingStarted/customScheme/clientForNewScheme/#update-client","text":"In order to extend client support for the new scheme you will have to add the following: New Scheme Class New Entity Class Integration Test ( Merging code without testing is a risky business \ud83d\ude01) Some case dependent updates","title":"Update Client"},{"location":"gettingStarted/customScheme/clientForNewScheme/#add-new-scheme-class","text":"Create file client/src/schemes/BuyInWithRageQuitOpt.ts that exports the new scheme class to enable client to interact with the scheme contract Please refer to Example Scheme Class NOTE: You will need to add abi of the contract in client/src , if it does not exist in @daostack/arc Client library use toIOperationObservable to create observables to get 3rd confirmation update","title":"Add new scheme class"},{"location":"gettingStarted/customScheme/clientForNewScheme/#example-scheme-class","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 import BN = require ( bn.js ) import { from } from rxjs import { concatMap } from rxjs/operators import buyInWithRageQuitOptScheme = require ( ./BuyInWithRageQuitOpt.json ) import { Operation , toIOperationObservable } from ../operation import { Scheme } from ../scheme import { Deposit } from ../deposit export class BuyInWithRageQuitOptScheme { constructor ( public scheme : Scheme ) { } err = ( error : Error ): Error = { return error } public deposit ( amount : BN ): Operation Deposit | null { const observable = from ( this . getContract ()) . pipe ( concatMap (( buyInWithRageQuitOpt ) = { const transaction = { value : amount , tx : buyInWithRageQuitOpt . methods . deposit () } const map = ( receipt : any ) = { const event = receipt . events . buyIn if ( ! event ) { return null } return new Deposit ({ amount : event . returnValues . _amount , member : event . returnValues . _member . toLowerCase (), dao : event . returnValues . _avatar . toLowerCase (), rep : event . returnValues . _rep }, this . scheme . context ) } return this . scheme . context . sendTransaction ( transaction , map , this . err ) }) ) return toIOperationObservable ( observable ) } public quit (): Operation Quit | null { const observable = from ( this . getContract ()) . pipe ( concatMap (( buyInWithRageQuitOpt ) = { const transaction = buyInWithRageQuitOpt . methods . quit () const map = ( receipt : any ) = { const event = receipt . events . buyIn if ( ! event ) { return null } return new Quit ({ amount : event . returnValues . _amount , memberAddress : event . returnValues . _memberAddress , dao : event . returnValues . _avatar , rep : event . returnValues . _rep }, this . scheme . context ) } return this . scheme . context . sendTransaction ( transaction , map , this . err ) }) ) return toIOperationObservable ( observable ) } private async getContract () { const state = await this . scheme . fetchStaticState () return this . scheme . context . getContract ( state . address , buyInWithRageQuitOptScheme . abi ) } }","title":"Example Scheme class"},{"location":"gettingStarted/customScheme/clientForNewScheme/#add-new-entity-class","text":"Enable client library to interact with the Entities added to subgraph during previous step (Upgrade subgraph) Add relevant IEntityStaticState, IEntityState and IEntityQueryOptions interface Each Entity class must have following methods: state : that takes IEntityQueryOptions and returns Entity Observable from graphQL query setStaticState : that sets IEntityStaticState fetchStaticState : that returns IEntityStaticState observable state : that returns IEntityState observable Please refer to example Deposit Entity class","title":"Add new Entity class"},{"location":"gettingStarted/customScheme/clientForNewScheme/#example-entity-class","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 import gql from graphql-tag import { Observable } from rxjs import { first } from rxjs/operators import { Arc , IApolloQueryOptions } from ./arc import { Address , ICommonQueryOptions , IStateful } from ./types import { BN , createGraphQlQuery , isAddress } from ./utils export interface IDepositStaticState { id ? : string member : Address amount : typeof BN rep : typeof BN dao : Address } export interface IDepositState extends IDepositStaticState { id : string } export interface IDepositQueryOptions extends ICommonQueryOptions { where ? : { id ? : string member ? : Address dao ? : Address [ key : string ]: any } } export class Deposit implements IStateful IDepositState { /** * Deposit . search ( context , options ) searches for deposit entities * @param context an Arc instance that provides connection information * @param options the query options , cf . IDepositQueryOptions * @return an observable of Deposit objects */ public static search ( context : Arc , options : IDepositQueryOptions = {}, apolloQueryOptions : IApolloQueryOptions = {} ): Observable Deposit [] { if ( ! options . where ) { options . where = {}} let where = let daoFilter : ( r : any ) = boolean daoFilter = () = true for ( const key of Object . keys ( options . where )) { if ( options . where [ key ] === undefined ) { continue } if ( key === member || key === dao ) { const option = options . where [ key ] as string isAddress ( option ) options . where [ key ] = option . toLowerCase () } else { where += `${key}: ${options.where[key] as string} \\n` } } const query = gql ` query DepositSearch { deposits $ { createGraphQlQuery ( options , where )} { id member amount avatar rep } } ` return context . getObservableListWithFilter ( query , ( r : any ) = { return new Deposit ({ id : r . id , member : r . member , amount : new BN ( r . amount || 0 ), dao : r . avatar , rep : new BN ( r . rep || 0 ) }, context ) }, daoFilter , apolloQueryOptions ) as Observable Deposit [] } public id : string | undefined public staticState : IDepositStaticState | undefined constructor ( idOrOpts : string | IDepositStaticState , public context : Arc ) { if ( typeof idOrOpts === string ) { this . id = idOrOpts } else { const opts = idOrOpts as IDepositStaticState this . id = opts . id this . setStaticState ( opts ) } } public setStaticState ( opts : IDepositStaticState ) { this . staticState = opts } public async fetchStaticState (): Promise IDepositStaticState { if ( !! this . staticState ) { return this . staticState } else { return await this . state () . pipe ( first ()) . toPromise () } } public state ( apolloQueryOptions : IApolloQueryOptions = {}): Observable IDepositState { const query = gql ` query DepositById { deposit ( id : ${this.id} ) { id memberAddress amount avatar rep } } ` const itemMap = ( item : any ): IDepositState = { if ( item === null ) { throw Error ( `Could not find a Vote with id ${this.id}` ) } return { amount : item . amount , dao : item . dao , id : item . id , member : item . member , rep : item . rep } } return this . context . getObservableObject ( query , itemMap , apolloQueryOptions ) } }","title":"Example Entity Class"},{"location":"gettingStarted/customScheme/clientForNewScheme/#integration-tests","text":"Add relevant integration test for the new scheme, client/test/scheme-buyInWithRageQuitOpt.spec.ts Start test watcher while you test and update the client 1 npm run test : watch : client -- test/scheme-buyInWithRageQuitOpt.spec.ts Refer to example Test BuyInWithRageQuitOpt Scheme","title":"Integration Tests"},{"location":"gettingStarted/customScheme/clientForNewScheme/#example-test-buyinwithragequitopt-scheme","text":"Following is an example integration test file to test the sample non-universal scheme we developed in this tutorial 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 import { Scheme } from ../src/scheme import { Arc } from ../src/arc import { DAO } from ../src/dao import { first } from rxjs/operators import { Reputation } from ../src/reputation import { Deposit } from ../src/deposit import { BN , getTestDAO , getTestAddresses , newArc , toWei , waitUntilTrue } from ./utils jest . setTimeout ( 60000 ) /** * Scheme test */ describe ( Deposit to buy reputaion , () = { let addresses : any let arc : Arc let dao : DAO let scheme : Scheme let daoBalanceBefore : undefined let reputationBefore : undefined let eventLengthBefore : number let reputation : any let amount = toWei ( 0.1 ) let response : any const getEventLength = async () = { let deposits = await Deposit . search ( arc , { where : { member : arc . web3 . eth . defaultAccount }}, { fetchPolicy : no-cache } ) . pipe ( first ()) . toPromise () return deposits . length } beforeAll ( async () = { arc = await newArc () addresses = getTestAddresses ( arc ) dao = await getTestDAO () scheme = new Scheme ({ address : 0x6d065a54f0a14cb03b949a146dbb58c14a0afc48 , dao : dao . id , id : 0x992c72e5e965d11a318839b554b0330dcb3ac81dc2ac0e4e57ba2c15660a3564 , name : BuyInWithRageQuitOpt , paramsHash : 0x0000000000000000000000000000000000000000000000000000000000000000 }, arc ) reputation = new Reputation ( addresses . dao . Reputation , arc ) daoBalanceBefore = await dao . ethBalance () . pipe ( first ()) . toPromise () reputationBefore = await reputation . reputationOf ( arc . web3 . eth . defaultAccount ) . pipe ( first ()) . toPromise () eventLengthBefore = await getEventLength () expect ( scheme . BuyInWithRageQuitOpt ) . not . toBeFalsy () if ( scheme . BuyInWithRageQuitOpt ) { response = await scheme . BuyInWithRageQuitOpt . deposit ( amount ) . send () expect ( response ) } }) it ( Should increase DAO balance by amount deposited , async () = { let daoBalanceAfter = await dao . ethBalance () . pipe ( first ()) . toPromise () expect ( Number ( daoBalanceAfter ) - Number ( daoBalanceBefore )) . toEqual ( Number ( amount )) }) it ( Should increase reputation of Member by amount deposited , async () = { let reputationAfter = new BN ( await reputation . contract () . methods . balanceOf ( arc . web3 . eth . defaultAccount ) . call ()) expect ( Number ( reputationAfter ) - Number ( reputationBefore )) . toEqual ( Number ( amount )) }) it ( Should index the deposit event , async () = { const state0 = await response . result . fetchStaticState () expect ( state0 ) . toMatchObject ({ amount : amount . toString (), member : arc . web3 . eth . defaultAccount . toLowerCase (), dao : dao . id . toLowerCase (), rep : amount . toString () }) let eventLengthAfter = eventLengthBefore const depositIsIndexed = async () = { eventLengthAfter = await getEventLength () return eventLengthAfter - eventLengthBefore 0 } await waitUntilTrue ( depositIsIndexed ) expect ( eventLengthAfter - 1 ) . toEqual ( eventLengthBefore ) }) }) describe ( Quit to refund funds , () = { // add more tests })","title":"Example Test BuyInWithRageQuitOpt Scheme"},{"location":"gettingStarted/customScheme/clientForNewScheme/#extra-interoperability-updates-may-differ-per-use-case","text":"Apart from the above standard updates you might need to update some other files depending on the scheme you are adding. For eg. In case of BuyInWithRageQuitOpt Scheme , we added to following files: src/scheme.ts : To add BuyInWithRageQuitOpt to ISchemeState src/operation.ts : To enable passing custom value to this.scheme.context.sendTransaction test/utils.ts : To update LATEST_ARC_VERSION and to getTestAddresses of our newly created DAO instead of test DAO test/migration.json : To use the migration file we got in the migration step (which has details of our DAO and new scheme`","title":"Extra Interoperability updates (may differ per use case)"},{"location":"gettingStarted/customScheme/developCustomNonUniScheme/","text":"Tutorial for adding non-universal scheme skip Design Principle Non-Universal scheme is more simple than a universal one, since it serves a single DAO (avatar) It is possible to attach multiple instances of non-universal scheme to a single DAO (avatar), For eg. In case of GenericScheme we attach an instance per external contract that the DAO can interact to. Recommended design principle : should include a one time called public initialize function which gets the avatar as its first parameters (This will assist with the common migration process) Example You can refer to the non-universal schemes developed by the DAOstack team here Following is another non-universal scheme example that we will also use in subgraph and client part of this tutorial. BuyInWithRageQuitOpt : A non-universal scheme to allow people to buy reputation by donating money to the DAO and if their goals no more align with the DAO, have the ability to quit reputation at some later time and receive propotional funds back. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 import @daostack/arc/contracts/controller/ControllerInterface.sol ; /** * @title BuyIn * @dev A scheme for buying in reputation in the DAO with option to rage quit */ contract BuyInWithRageQuitOpt { using SafeMath for uint256 ; event buyIn ( address indexed _avatar , address indexed _member , uint256 _amount , uint256 _rep ); event rageQuit ( address indexed _avatar , address indexed _member , uint256 _amount , uint256 _rep ); Avatar public avatar ; Reputation public reputation ; function initialize ( Avatar _avatar ) external { require ( avatar == Avatar ( 0 ), can be called only one time ); require ( _avatar != Avatar ( 0 ), avatar cannot be zero ); avatar = _avatar ; reputation = avatar . nativeReputation (); } function deposit () payable external { // Transfer buy in amount to DAO require ( address ( avatar ) . send ( msg . value )); // Mint Equivalent Rep to the buyer require ( ControllerInterface ( avatar . owner ()) . mintReputation ( msg . value , msg . sender , address ( avatar )), mint reputation should succeed ); emit buyIn ( address ( avatar ), msg . sender , msg . value , msg . value ); } function quit () public returns ( uint256 ){ // Get current reputation of the quitter uint256 rep = reputation . balanceOfAt ( msg . sender , block . number ); require ( rep 0 , Only members can quit ); // Calculate proportionate amount to refund to the quitter uint256 totalSupply = reputation . totalSupplyAt ( block . number ); uint256 amount = ( address ( avatar ) . balance ) . mul ( rep ) . div ( totalSupply ); // burn reputation require ( ControllerInterface ( avatar . owner ()) . burnReputation ( rep , msg . sender , address ( avatar )) ); // transfer proportionate funds require ( ControllerInterface ( avatar . owner ()) . sendEther ( amount , msg . sender , avatar ) ); emit rageQuit ( address ( avatar ), msg . sender , amount , rep ); return rep ; } }","title":"Non-Universal Scheme"},{"location":"gettingStarted/customScheme/developCustomNonUniScheme/#design-principle","text":"Non-Universal scheme is more simple than a universal one, since it serves a single DAO (avatar) It is possible to attach multiple instances of non-universal scheme to a single DAO (avatar), For eg. In case of GenericScheme we attach an instance per external contract that the DAO can interact to. Recommended design principle : should include a one time called public initialize function which gets the avatar as its first parameters (This will assist with the common migration process)","title":"Design Principle"},{"location":"gettingStarted/customScheme/developCustomNonUniScheme/#example","text":"You can refer to the non-universal schemes developed by the DAOstack team here Following is another non-universal scheme example that we will also use in subgraph and client part of this tutorial. BuyInWithRageQuitOpt : A non-universal scheme to allow people to buy reputation by donating money to the DAO and if their goals no more align with the DAO, have the ability to quit reputation at some later time and receive propotional funds back. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 import @daostack/arc/contracts/controller/ControllerInterface.sol ; /** * @title BuyIn * @dev A scheme for buying in reputation in the DAO with option to rage quit */ contract BuyInWithRageQuitOpt { using SafeMath for uint256 ; event buyIn ( address indexed _avatar , address indexed _member , uint256 _amount , uint256 _rep ); event rageQuit ( address indexed _avatar , address indexed _member , uint256 _amount , uint256 _rep ); Avatar public avatar ; Reputation public reputation ; function initialize ( Avatar _avatar ) external { require ( avatar == Avatar ( 0 ), can be called only one time ); require ( _avatar != Avatar ( 0 ), avatar cannot be zero ); avatar = _avatar ; reputation = avatar . nativeReputation (); } function deposit () payable external { // Transfer buy in amount to DAO require ( address ( avatar ) . send ( msg . value )); // Mint Equivalent Rep to the buyer require ( ControllerInterface ( avatar . owner ()) . mintReputation ( msg . value , msg . sender , address ( avatar )), mint reputation should succeed ); emit buyIn ( address ( avatar ), msg . sender , msg . value , msg . value ); } function quit () public returns ( uint256 ){ // Get current reputation of the quitter uint256 rep = reputation . balanceOfAt ( msg . sender , block . number ); require ( rep 0 , Only members can quit ); // Calculate proportionate amount to refund to the quitter uint256 totalSupply = reputation . totalSupplyAt ( block . number ); uint256 amount = ( address ( avatar ) . balance ) . mul ( rep ) . div ( totalSupply ); // burn reputation require ( ControllerInterface ( avatar . owner ()) . burnReputation ( rep , msg . sender , address ( avatar )) ); // transfer proportionate funds require ( ControllerInterface ( avatar . owner ()) . sendEther ( amount , msg . sender , avatar ) ); emit rageQuit ( address ( avatar ), msg . sender , amount , rep ); return rep ; } }","title":"Example"},{"location":"gettingStarted/customScheme/developCustomUniScheme/","text":"Design Principle Universal scheme is more complex than a non-universal one, since it serves multiple DAO (avatar) Only single instance of universal scheme is deployed and it can be used by multiple DAOs with different parameters as registered with DAO's controller. Recommended design principle : should inherit the Universal Scheme Interface should maintain a bytes32 = Parameters mapping should emit Avatar address in the events. should take Avatar as the parameter for scheme's proposal. Example Refer to the universal schemes developed by the DAOstack team here","title":"Universal Scheme"},{"location":"gettingStarted/customScheme/developCustomUniScheme/#design-principle","text":"Universal scheme is more complex than a non-universal one, since it serves multiple DAO (avatar) Only single instance of universal scheme is deployed and it can be used by multiple DAOs with different parameters as registered with DAO's controller. Recommended design principle : should inherit the Universal Scheme Interface should maintain a bytes32 = Parameters mapping should emit Avatar address in the events. should take Avatar as the parameter for scheme's proposal.","title":"Design Principle"},{"location":"gettingStarted/customScheme/developCustomUniScheme/#example","text":"Refer to the universal schemes developed by the DAOstack team here","title":"Example"},{"location":"gettingStarted/customScheme/intro/","text":"Scheme is an action a DAO on DAOstack platform can be enabled to take. Schemes might be used to help a DAO: propose and make investments, give reputation to agents, upgrade the DAO's contracts, register new schemes and constraints, etc. Apart from the schemes already designed by DAOstack team - Arc , you can also deploy your own Custom Schemes and register them to the DAO. A scheme could be, Universal : inherit from UniversalSchemeInterface and are designed to be deployed once and any DAO can register to a universal scheme to enable the functionality offered by them. OR Non Universal : do not follow any standard and do not inherit from UniversalSchemeInterface. A non universal scheme has to be deployed for each DAO separately. Which layer to customize To Enable DAO with some custom actions, you might need to work on multiple layers of the stack Arc : Design and Deploy the scheme contract which has the action DAO will execute. Migration : deploy + register custom scheme to new DAO using migration script or deploy independently and register via another Scheme Subgraph : develop subgraph tracker for your scheme for faster/efficient read access Client : enable DAOstack client library to write to your scheme contract and read scheme data from subgraph using graphQL Alchemy : enable user friendly interface for your scheme in Alchemy Tutorial In following section we will see some sample code for adding a custom scheme to the DAO and enabling graph-node to cache the events from the scheme and client to interact with the scheme. Depending on your requirements all or some parts of the tutorial might be useful for you. Overview Choose the project setup from any of the Hacker-kit Examples Follow the tutorial for Universal Scheme or Non-Universal Scheme Add your custom scheme contract to contracts folder. Compile using truffle 1 npm run compile Deploy with New DAO npm run migrate OR Deploy and register to Existing DAO Update subgraph and deploy : Make changes to subgraph refer Update subgraph tutorial and deploy graph npm run deploy:graph Update client and build : Update client to interact with your scheme, refer Update client tutorial npm run build:client npm run link:client To develop on the client in tandem with alchemy, start watcher 1 npm run watch : client Work on your own front-end or update alchemy to support your scheme as you desire","title":"Intro"},{"location":"gettingStarted/customScheme/intro/#which-layer-to-customize","text":"To Enable DAO with some custom actions, you might need to work on multiple layers of the stack Arc : Design and Deploy the scheme contract which has the action DAO will execute. Migration : deploy + register custom scheme to new DAO using migration script or deploy independently and register via another Scheme Subgraph : develop subgraph tracker for your scheme for faster/efficient read access Client : enable DAOstack client library to write to your scheme contract and read scheme data from subgraph using graphQL Alchemy : enable user friendly interface for your scheme in Alchemy","title":"Which layer to customize"},{"location":"gettingStarted/customScheme/intro/#tutorial","text":"In following section we will see some sample code for adding a custom scheme to the DAO and enabling graph-node to cache the events from the scheme and client to interact with the scheme. Depending on your requirements all or some parts of the tutorial might be useful for you.","title":"Tutorial"},{"location":"gettingStarted/customScheme/intro/#overview","text":"Choose the project setup from any of the Hacker-kit Examples Follow the tutorial for Universal Scheme or Non-Universal Scheme Add your custom scheme contract to contracts folder. Compile using truffle 1 npm run compile Deploy with New DAO npm run migrate OR Deploy and register to Existing DAO Update subgraph and deploy : Make changes to subgraph refer Update subgraph tutorial and deploy graph npm run deploy:graph Update client and build : Update client to interact with your scheme, refer Update client tutorial npm run build:client npm run link:client To develop on the client in tandem with alchemy, start watcher 1 npm run watch : client Work on your own front-end or update alchemy to support your scheme as you desire","title":"Overview"},{"location":"gettingStarted/customScheme/registerToExistingDAO/","text":"To register the new Scheme to an existing DAOstack DAO you can submit a new proposal to the Scheme Registrar via Alchemy UI after the Scheme is deployed. Deploy the Scheme contract You may use truffle or your own script to deploy the new scheme contract and intitialize it. Propose to SchemeRegistrar On Alchemy's landing page, choose the DAO to which you wish to register the scheme. Visit the DAO's Home page and choose Scheme Registrar . Click New Proposal \u2013 this will open a popup. Select Add Scheme on the popup sidebar (on the left). Give the proposal an appropriate title, description, and url linking to a description of the proposal. For Scheme , put the address of the new scheme contract (universal or not). Enter the paramHash for your scheme. universal scheme : paramHash returned by setParameters method non-universal scheme : can be left null, since only one parameter set is registered to non-universal schemes at the time of deployment. In the permissions section, check the appropriate permissions required by the scheme. In case of BuyInWithRageQuitOpt example we only need mint and burn permissions. Submit the proposal and sign the transaction as normal. If the DAO passes your proposal, then your Scheme will be registered to the DAO.","title":"Register scheme to existing DAO"},{"location":"gettingStarted/customScheme/registerToExistingDAO/#deploy-the-scheme-contract","text":"You may use truffle or your own script to deploy the new scheme contract and intitialize it.","title":"Deploy the Scheme contract"},{"location":"gettingStarted/customScheme/registerToExistingDAO/#propose-to-schemeregistrar","text":"On Alchemy's landing page, choose the DAO to which you wish to register the scheme. Visit the DAO's Home page and choose Scheme Registrar . Click New Proposal \u2013 this will open a popup. Select Add Scheme on the popup sidebar (on the left). Give the proposal an appropriate title, description, and url linking to a description of the proposal. For Scheme , put the address of the new scheme contract (universal or not). Enter the paramHash for your scheme. universal scheme : paramHash returned by setParameters method non-universal scheme : can be left null, since only one parameter set is registered to non-universal schemes at the time of deployment. In the permissions section, check the appropriate permissions required by the scheme. In case of BuyInWithRageQuitOpt example we only need mint and burn permissions. Submit the proposal and sign the transaction as normal. If the DAO passes your proposal, then your Scheme will be registered to the DAO.","title":"Propose to SchemeRegistrar"},{"location":"gettingStarted/customScheme/registerToNewDAO/","text":"You can deploy your new custom scheme contract and register it to the New DAO as part of initial scheme set using @daostack/migration tool Create DAO-spec Add data/YourDaoSpec.json file that describes the specifics of the DAO such as Name of Organization, Token name and symbol, initial set of scheme registered and founder members etc. You can refer to Deploy a DAO section for base dao-spec file Add CustomSchemes section with the details of your scheme as follows. Refer Example DAO spec name : Name of the contract file schemeName : Name of the scheme isUniversal : true or false, depending on which scheme you are registering params : array of parameters to be passed to scheme contract's initialize (in-case of non-universal) or setParameters (in-case of universal) method. Please keep the order of parameters expected by the method in consideration Include { \"voteParams\": X } for voting machine parameters, where X is the index of param from VotingMachinesParams , that will be used to vote on proposals submitted to this scheme. \"GenesisProtocolAddress\" will be converted to actual GenesisProtocol address. Include this if scheme uses Genesis Protocol as the voting machine and expects its Address as one of the parameter Since each non-universal scheme is deployed per DAO and it is advisable to have the DAO address initialized the scheme, the migration tool expects first param to initialize method is DAO avatar address. permissions : Include a 4 byte hex describing the permissions required by your new scheme 2nd bit: Scheme can register other schemes 3rd bit: Scheme can add/remove global constraints 4th bit: Scheme can upgrade the controller 5th bit: Scheme can call genericCall on behalf of address (optional): If you have already deployed your scheme contract, then include its address here, else migration script will deploy this scheme alias (optional): include alias for what you will want your scheme to be referred as in subgraph Example DAO spec file Following is CommunityDaoSpec.json using custom scheme designed in previous step for new Community DAO where people can buy reputation by donating money 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 { orgName : CommunityDAO , tokenName : Commune , tokenSymbol : CDT , ContributionReward :[ { voteParams : 0 } ], SchemeRegistrar : [ { voteRegisterParams : 1 , voteRemoveParams : 1 } ], CustomSchemes : [ { name : BuyInWithRageQuitOpt , schemeName : BuyInWithRageQuitOpt , isUniversal : false , params : [ ], permissions : 0x00000000 alias : DonationScheme } ], VotingMachinesParams :[ { activationTime : 0 , boostedVotePeriodLimit : 345600 , daoBountyConst : 10 , minimumDaoBounty : 150 , preBoostedVotePeriodLimit : 86400 , proposingRepReward : 0 , queuedVotePeriodLimit : 2592000 , queuedVoteRequiredPercentage : 50 , quietEndingPeriod : 172800 , thresholdConst : 1200 , voteOnBehalf : 0x0000000000000000000000000000000000000000 , votersReputationLossRatio : 0 } , { activationTime : 0 , boostedVotePeriodLimit : 691200 , daoBountyConst : 10 , minimumDaoBounty : 500 , preBoostedVotePeriodLimit : 172800 , proposingRepReward : 0 , queuedVotePeriodLimit : 5184000 , queuedVoteRequiredPercentage : 50 , quietEndingPeriod : 345600 , thresholdConst : 1500 , voteOnBehalf : 0x0000000000000000000000000000000000000000 , votersReputationLossRatio : 0 } ], schemes : { ContributionReward : true , SchemeRegistrar : true } , unregisterOwner : true , useUController : false , useDaoCreator : true , founders :[ ] } Create DAO-deploy file Create migration file to deploy your DAO. You will need node = 10.16.0 dotenv =8.1.0 @daostack/migration latest Update .env file with following environment variables CUSTOM_ABI_LOCATION : location of all your compiled contracts, eg. contracts/build DAO_SPEC : path to yourDaoSpec.json file DEFAULT_GAS : gas price for tx, eg. 3.0 OUTPUT_FILE : full path of file where to store migration output, eg. data/migration.json PRIVATE_KEY : key of the account you are using to deploy the DAO PROVIDER : url of the ethprovider, this could be infura or ganache Example 1 2 3 4 5 6 CUSTOM_ABI_LOCATION = build/contracts DAO_SPEC = ../data/testDaoSpec.json DEFAULT_GAS = 3 . 0 OUTPUT_FILE = data/migration.json PRIVATE_KEY = 0x4f3edf983ac636a65a842ce7c78d9aa706d3b113bce9c46f30d7d21715b23b1d PROVIDER = http://localhost:8545 Add/Update the ops/deployDAO.js , Refer Example deploy script Example deploy script 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 require ( dotenv ). config (); const DAOstackMigration = require ( @daostack/migration ); const migrationSpec = require ( process . env . DAO_SPEC ) async function migrate () { const options = { provider : process . env . PROVIDER , gasPrice : process . env . DEFAULT_GAS , quiet : false , force : true , restart : true , output : process . env . OUTPUT_FILE , privateKey : process . env . PRIVATE_KEY , customabislocation : process . env . CUSTOM_ABI_LOCATION , params : { private : migrationSpec , rinkeby : migrationSpec } , } ; await DAOstackMigration . migrateDAO ( options ); } migrate ()","title":"Register scheme to new DAO"},{"location":"gettingStarted/customScheme/registerToNewDAO/#create-dao-spec","text":"Add data/YourDaoSpec.json file that describes the specifics of the DAO such as Name of Organization, Token name and symbol, initial set of scheme registered and founder members etc. You can refer to Deploy a DAO section for base dao-spec file Add CustomSchemes section with the details of your scheme as follows. Refer Example DAO spec name : Name of the contract file schemeName : Name of the scheme isUniversal : true or false, depending on which scheme you are registering params : array of parameters to be passed to scheme contract's initialize (in-case of non-universal) or setParameters (in-case of universal) method. Please keep the order of parameters expected by the method in consideration Include { \"voteParams\": X } for voting machine parameters, where X is the index of param from VotingMachinesParams , that will be used to vote on proposals submitted to this scheme. \"GenesisProtocolAddress\" will be converted to actual GenesisProtocol address. Include this if scheme uses Genesis Protocol as the voting machine and expects its Address as one of the parameter Since each non-universal scheme is deployed per DAO and it is advisable to have the DAO address initialized the scheme, the migration tool expects first param to initialize method is DAO avatar address. permissions : Include a 4 byte hex describing the permissions required by your new scheme 2nd bit: Scheme can register other schemes 3rd bit: Scheme can add/remove global constraints 4th bit: Scheme can upgrade the controller 5th bit: Scheme can call genericCall on behalf of address (optional): If you have already deployed your scheme contract, then include its address here, else migration script will deploy this scheme alias (optional): include alias for what you will want your scheme to be referred as in subgraph","title":"Create DAO-spec"},{"location":"gettingStarted/customScheme/registerToNewDAO/#example-dao-spec-file","text":"Following is CommunityDaoSpec.json using custom scheme designed in previous step for new Community DAO where people can buy reputation by donating money 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 { orgName : CommunityDAO , tokenName : Commune , tokenSymbol : CDT , ContributionReward :[ { voteParams : 0 } ], SchemeRegistrar : [ { voteRegisterParams : 1 , voteRemoveParams : 1 } ], CustomSchemes : [ { name : BuyInWithRageQuitOpt , schemeName : BuyInWithRageQuitOpt , isUniversal : false , params : [ ], permissions : 0x00000000 alias : DonationScheme } ], VotingMachinesParams :[ { activationTime : 0 , boostedVotePeriodLimit : 345600 , daoBountyConst : 10 , minimumDaoBounty : 150 , preBoostedVotePeriodLimit : 86400 , proposingRepReward : 0 , queuedVotePeriodLimit : 2592000 , queuedVoteRequiredPercentage : 50 , quietEndingPeriod : 172800 , thresholdConst : 1200 , voteOnBehalf : 0x0000000000000000000000000000000000000000 , votersReputationLossRatio : 0 } , { activationTime : 0 , boostedVotePeriodLimit : 691200 , daoBountyConst : 10 , minimumDaoBounty : 500 , preBoostedVotePeriodLimit : 172800 , proposingRepReward : 0 , queuedVotePeriodLimit : 5184000 , queuedVoteRequiredPercentage : 50 , quietEndingPeriod : 345600 , thresholdConst : 1500 , voteOnBehalf : 0x0000000000000000000000000000000000000000 , votersReputationLossRatio : 0 } ], schemes : { ContributionReward : true , SchemeRegistrar : true } , unregisterOwner : true , useUController : false , useDaoCreator : true , founders :[ ] }","title":"Example DAO spec file"},{"location":"gettingStarted/customScheme/registerToNewDAO/#create-dao-deploy-file","text":"Create migration file to deploy your DAO. You will need node = 10.16.0 dotenv =8.1.0 @daostack/migration latest Update .env file with following environment variables CUSTOM_ABI_LOCATION : location of all your compiled contracts, eg. contracts/build DAO_SPEC : path to yourDaoSpec.json file DEFAULT_GAS : gas price for tx, eg. 3.0 OUTPUT_FILE : full path of file where to store migration output, eg. data/migration.json PRIVATE_KEY : key of the account you are using to deploy the DAO PROVIDER : url of the ethprovider, this could be infura or ganache Example 1 2 3 4 5 6 CUSTOM_ABI_LOCATION = build/contracts DAO_SPEC = ../data/testDaoSpec.json DEFAULT_GAS = 3 . 0 OUTPUT_FILE = data/migration.json PRIVATE_KEY = 0x4f3edf983ac636a65a842ce7c78d9aa706d3b113bce9c46f30d7d21715b23b1d PROVIDER = http://localhost:8545 Add/Update the ops/deployDAO.js , Refer Example deploy script","title":"Create DAO-deploy file"},{"location":"gettingStarted/customScheme/registerToNewDAO/#example-deploy-script","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 require ( dotenv ). config (); const DAOstackMigration = require ( @daostack/migration ); const migrationSpec = require ( process . env . DAO_SPEC ) async function migrate () { const options = { provider : process . env . PROVIDER , gasPrice : process . env . DEFAULT_GAS , quiet : false , force : true , restart : true , output : process . env . OUTPUT_FILE , privateKey : process . env . PRIVATE_KEY , customabislocation : process . env . CUSTOM_ABI_LOCATION , params : { private : migrationSpec , rinkeby : migrationSpec } , } ; await DAOstackMigration . migrateDAO ( options ); } migrate ()","title":"Example deploy script"},{"location":"gettingStarted/customScheme/subgraphForNewScheme/","text":"If you created a custom scheme or used any of the new arc scheme that are not yet tracked by subgraph, then you will have to make changes to DAOstack caching layer. NOTE: You can skip this step if you do not wish to take advantage of caching layer for faster access and would rather read data directly from blockchain. But would recommend not to. Pre Work Make sure you have cloned DAOstack subgraph repo , if you have not already Create a new directory with your scheme-name in mappings 1 2 cd subgraph mkdir src / mappings / BuyInWithRageQuitOpt Add contract abi to abis/'version' folder e.g. abis/0.0.1-rc.27/BuyInWithRageQuitOpt.json If you have jq tool installed you can use this command to extract abi, make sure to use right version folder 1 cat .. / build / contracts / BuyInWithRageQuitOpt . json | jq . abi abis / 0 . 0 . 1 - rc . 27 / BuyInWithRageQuitOpt . json If you ran above command you should be able to see an Abi file for the non-universal scheme as follows 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 [ { constant : true , inputs : [], name : avatar , outputs : [ { internalType : contract Avatar , name : , type : address } ], payable : false , stateMutability : view , type : function } , { constant : true , inputs : [], name : reputation , outputs : [ { internalType : contract Reputation , name : , type : address } ], payable : false , stateMutability : view , type : function } , { anonymous : false , inputs : [ { indexed : true , internalType : address , name : _member , type : address } , { indexed : false , internalType : uint256 , name : _amount , type : uint256 } , { indexed : false , internalType : uint256 , name : _rep , type : uint256 } ], name : buyIn , type : event } , { anonymous : false , inputs : [ { indexed : true , internalType : address , name : _member , type : address } , { indexed : false , internalType : uint256 , name : _amount , type : uint256 } , { indexed : false , internalType : uint256 , name : _rep , type : uint256 } ], name : rageQuit , type : event } , { constant : false , inputs : [ { internalType : contract Avatar , name : _avatar , type : address } ], name : initialize , outputs : [], payable : false , stateMutability : nonpayable , type : function } , { constant : false , inputs : [], name : deposit , outputs : [], payable : true , stateMutability : payable , type : function } , { constant : false , inputs : [], name : quit , outputs : [ { internalType : uint256 , name : , type : uint256 } ], payable : false , stateMutability : nonpayable , type : function } ] Add contract mappings In order to cache the events from blockchain, we will create following files in src/mappings/BuyInWithRageQuitOpt : datasource.yaml File containing the subgraph manifest src/mappings/BuyInWithRageQuitOpt/datasource.yaml 1 2 3 4 5 6 7 8 9 10 abis : - BuyInWithRageQuitOpt entities : - Deposit - Quit eventHandlers : - event : buyIn ( indexed address , uint256 , uint256 ) handler : handleBuyIn - event : rageQuit ( indexed address , uint256 , uint256 ) handler : handleRageQuit schema.graphql Describe what data is stored for your subgraph and how to query it via GraphQL in src/mappings/BuyInWithRageQuitOpt/schema.graphql NOTE: These will be used for the generating types in src/types/ during build step and will need to be imported while writing handlers in mapping.ts 1 2 3 4 5 6 7 8 9 10 11 12 13 type Deposit @entity { id : ID ! memberAddress : Bytes ! amount : BigInt ! rep : BigInt ! } type Quit @entity { id : ID ! memberAddress : Bytes ! amount : BigInt ! rep : BigInt ! } mapping.ts Describe how blockchain events are processed and stored in entities defined in your schema src/mappings/BuyInWithRageQuitOpt/mapping.ts NOTE: src/types/BuyInWithRageQuitOpt/BuyInWithRageQuitOpt will be generated during the build step based on the entities described in schema.graphQL. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 import allocator/arena ; import { store , } from @graphprotocol/graph-ts ; import * as domain from ../../domain ; import { Deposit , Quit } from ../../types/schema ; import { concat , equalsBytes , eventId } from ../../utils ; import { buyIn , rageQuit , } from ../../types/BuyInWithRageQuitOpt/BuyInWithRageQuitOpt ; export function handleBuyIn ( event : buyIn ): void { let ent = new Deposit ( eventId ( event )); ent . memberAddress = event . params . _member ; ent . amount = event . params . _amount ; ent . rep = event . params . _rep ; store . set ( Deposit , ent . id , ent ); } export function handleRageQuit ( event : rageQuit ): void { let ent = new Quit ( eventId ( event )); ent . memberAddress = event . params . _member ; ent . amount = event . params . _amount ; ent . rep = event . params . _rep ; store . set ( Quit , ent . id , ent ); } Integration test (optional) Add integration test for the subgraph test/integration/MyContractName.spec.ts Update Ops Add tracker for your contract in ops/mappings.json . In the JSON object for the network your contract is located at, under the \"mappings\" JSON array, add the following. arcVersion : contract arc version dao : section label where contract is defined in migration.json file (base/ dao/ test/ organs) or address , mapping : contract name as in mappings, name : contract name as appears in abis/arcVersion folder, contractName : contract name as appears in migration.json file, If your contract information is in the migration.json file specified (default is the file under @daostack/migration folder, as defined in the ops/settings.js file) 1 2 3 4 5 6 7 { name : BuyInWithRageQuitOpt , contractName : BuyInWithRageQuitOpt , dao : dao , mapping : BuyInWithRageQuitOpt , arcVersion : 0.0.1-rc.27 } , OR address : the contract address on network If your contract does not appear in the migration file add following info: 1 2 3 4 5 6 7 { name : BuyInWithRageQuitOpt , address : 0x4a35d1434D34Ac7842381362924E6399ca63Da5A dao : address , mapping : BuyInWithRageQuitOpt , arcVersion : 0.0.1-rc.27 , } ,","title":"Subgraph: enable cache for new scheme"},{"location":"gettingStarted/customScheme/subgraphForNewScheme/#pre-work","text":"Make sure you have cloned DAOstack subgraph repo , if you have not already Create a new directory with your scheme-name in mappings 1 2 cd subgraph mkdir src / mappings / BuyInWithRageQuitOpt Add contract abi to abis/'version' folder e.g. abis/0.0.1-rc.27/BuyInWithRageQuitOpt.json If you have jq tool installed you can use this command to extract abi, make sure to use right version folder 1 cat .. / build / contracts / BuyInWithRageQuitOpt . json | jq . abi abis / 0 . 0 . 1 - rc . 27 / BuyInWithRageQuitOpt . json If you ran above command you should be able to see an Abi file for the non-universal scheme as follows 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 [ { constant : true , inputs : [], name : avatar , outputs : [ { internalType : contract Avatar , name : , type : address } ], payable : false , stateMutability : view , type : function } , { constant : true , inputs : [], name : reputation , outputs : [ { internalType : contract Reputation , name : , type : address } ], payable : false , stateMutability : view , type : function } , { anonymous : false , inputs : [ { indexed : true , internalType : address , name : _member , type : address } , { indexed : false , internalType : uint256 , name : _amount , type : uint256 } , { indexed : false , internalType : uint256 , name : _rep , type : uint256 } ], name : buyIn , type : event } , { anonymous : false , inputs : [ { indexed : true , internalType : address , name : _member , type : address } , { indexed : false , internalType : uint256 , name : _amount , type : uint256 } , { indexed : false , internalType : uint256 , name : _rep , type : uint256 } ], name : rageQuit , type : event } , { constant : false , inputs : [ { internalType : contract Avatar , name : _avatar , type : address } ], name : initialize , outputs : [], payable : false , stateMutability : nonpayable , type : function } , { constant : false , inputs : [], name : deposit , outputs : [], payable : true , stateMutability : payable , type : function } , { constant : false , inputs : [], name : quit , outputs : [ { internalType : uint256 , name : , type : uint256 } ], payable : false , stateMutability : nonpayable , type : function } ]","title":"Pre Work"},{"location":"gettingStarted/customScheme/subgraphForNewScheme/#add-contract-mappings","text":"In order to cache the events from blockchain, we will create following files in src/mappings/BuyInWithRageQuitOpt :","title":"Add contract mappings"},{"location":"gettingStarted/customScheme/subgraphForNewScheme/#datasourceyaml","text":"File containing the subgraph manifest src/mappings/BuyInWithRageQuitOpt/datasource.yaml 1 2 3 4 5 6 7 8 9 10 abis : - BuyInWithRageQuitOpt entities : - Deposit - Quit eventHandlers : - event : buyIn ( indexed address , uint256 , uint256 ) handler : handleBuyIn - event : rageQuit ( indexed address , uint256 , uint256 ) handler : handleRageQuit","title":"datasource.yaml"},{"location":"gettingStarted/customScheme/subgraphForNewScheme/#schemagraphql","text":"Describe what data is stored for your subgraph and how to query it via GraphQL in src/mappings/BuyInWithRageQuitOpt/schema.graphql NOTE: These will be used for the generating types in src/types/ during build step and will need to be imported while writing handlers in mapping.ts 1 2 3 4 5 6 7 8 9 10 11 12 13 type Deposit @entity { id : ID ! memberAddress : Bytes ! amount : BigInt ! rep : BigInt ! } type Quit @entity { id : ID ! memberAddress : Bytes ! amount : BigInt ! rep : BigInt ! }","title":"schema.graphql"},{"location":"gettingStarted/customScheme/subgraphForNewScheme/#mappingts","text":"Describe how blockchain events are processed and stored in entities defined in your schema src/mappings/BuyInWithRageQuitOpt/mapping.ts NOTE: src/types/BuyInWithRageQuitOpt/BuyInWithRageQuitOpt will be generated during the build step based on the entities described in schema.graphQL. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 import allocator/arena ; import { store , } from @graphprotocol/graph-ts ; import * as domain from ../../domain ; import { Deposit , Quit } from ../../types/schema ; import { concat , equalsBytes , eventId } from ../../utils ; import { buyIn , rageQuit , } from ../../types/BuyInWithRageQuitOpt/BuyInWithRageQuitOpt ; export function handleBuyIn ( event : buyIn ): void { let ent = new Deposit ( eventId ( event )); ent . memberAddress = event . params . _member ; ent . amount = event . params . _amount ; ent . rep = event . params . _rep ; store . set ( Deposit , ent . id , ent ); } export function handleRageQuit ( event : rageQuit ): void { let ent = new Quit ( eventId ( event )); ent . memberAddress = event . params . _member ; ent . amount = event . params . _amount ; ent . rep = event . params . _rep ; store . set ( Quit , ent . id , ent ); }","title":"mapping.ts"},{"location":"gettingStarted/customScheme/subgraphForNewScheme/#integration-test-optional","text":"Add integration test for the subgraph test/integration/MyContractName.spec.ts","title":"Integration test (optional)"},{"location":"gettingStarted/customScheme/subgraphForNewScheme/#update-ops","text":"Add tracker for your contract in ops/mappings.json . In the JSON object for the network your contract is located at, under the \"mappings\" JSON array, add the following. arcVersion : contract arc version dao : section label where contract is defined in migration.json file (base/ dao/ test/ organs) or address , mapping : contract name as in mappings, name : contract name as appears in abis/arcVersion folder, contractName : contract name as appears in migration.json file, If your contract information is in the migration.json file specified (default is the file under @daostack/migration folder, as defined in the ops/settings.js file) 1 2 3 4 5 6 7 { name : BuyInWithRageQuitOpt , contractName : BuyInWithRageQuitOpt , dao : dao , mapping : BuyInWithRageQuitOpt , arcVersion : 0.0.1-rc.27 } , OR address : the contract address on network If your contract does not appear in the migration file add following info: 1 2 3 4 5 6 7 { name : BuyInWithRageQuitOpt , address : 0x4a35d1434D34Ac7842381362924E6399ca63Da5A dao : address , mapping : BuyInWithRageQuitOpt , arcVersion : 0.0.1-rc.27 , } ,","title":"Update Ops"},{"location":"stack/alchemy/alchemyIntro/","text":"The Client library facilitates development of \"Dapps\" (Decentralized applications) for interacting with DAOs. DAOstack has built its own Dapp called Alchemy , a front-end interface for DAOs , or more specifically, for budget management in decentralized organizations. Alchemy allows end users to make collaborative budgeting decisions and allocations using the Holographic Consensus protocol . You can find the Alchemy repo at github.com/daostack/alchemy . A second Dapp built by DAOstack is Vanille (enable MetaMask). Vanille enables users to create and interact with DAOs before moving to a dedicated interface like Alchemy. You can find the Vanille repo here: https://github.com/daostack/vanille . Should I work at this level? Build at the Dapp level if you want to create new ways to interact with existing DAOs and DAOstack smart contracts, e.g. a multi-DAO explorer for GEN predictors or a new DAO creation app.","title":"DApps/Alchemy"},{"location":"stack/alchemy/alchemyIntro/#should-i-work-at-this-level","text":"Build at the Dapp level if you want to create new ways to interact with existing DAOs and DAOstack smart contracts, e.g. a multi-DAO explorer for GEN predictors or a new DAO creation app.","title":"Should I work at this level?"},{"location":"stack/arc/arcIntro/","text":"Arc is a Solidity smart contract library for building DAOs. To get a good understanding of how the Arc framework is built, you can go to this blog post . Arc uses Infra to provide decentralized organizations with voting machines and voting rights management systems. DAOs built with Arc have a few basic contract components: Avatar - The DAO's \"account.\" This contract represents the address of the DAO and holds its assets. Reputation - Voting in Arc is done mainly using Reputation. Reputation can be distributed and redistributed only by DAO decision, and it is generally given (via vote) to an agent according to their performance and contribution to a DAO. Token - Each DAO may have its own token, which can be used in any way the DAO would like. Controller - The controller is the \"Access Control\" of the DAO, managing who can interact with which DAO functions and enforcing the DAO's constraints. Schemes - Schemes are a DAO's \"actions\": anything a DAO should act upon needs to be written and authorized by the controller as a scheme. Schemes might be used to help a DAO: propose and make investments, give reputation to agents, upgrade the DAO's contracts, register new schemes and constraints, etc. Global Constraints - Global constraints are limitations on a DAO's actions. When executing a scheme, the controller checks the constraints to see if the action violates them, and blocks the execution if it does. Some examples for constraints might be: the token supply can't be increased over 1M tokens, the organization won't use more than 60% of its funds at once, etc. Arc utilizes the concept of \"Universal\" contracts : contracts which are deployed once, and then can be used by any number of DAOs simultaneously, saving gas and deployment costs. Schemes and constraints can both be used in this way. To use the already deployed contracts, you can either use Client, which maintains easy access to all universal Arc contracts, or you can use Migration.json to view the addresses of the universal contracts of the latest arc version on the mainnet, Kovan, Rinkeby and Ganache* All contracts listed in the file are universal, meaning that users should use them when needed and not redeploy them. * Please note that the Ganache addresses are based on the DAOstack commands for running and deploying Arc to a local Ganache network, which means those addresses might change if you are using a different method to run Ganache or deploy Arc. Should I work at this level? Using Arc is not necessary to deploy a DAO (you can do this with Migrations currently and in the future as an end user of Dapps), but you might want to work on this layer if you need your DAO to have a unique action, constraint, or voting process that is not yet implemented on Arc. You can find the complete Arc docs here: https://daostack.github.io/arc","title":"Arc"},{"location":"stack/arc/arcIntro/#should-i-work-at-this-level","text":"Using Arc is not necessary to deploy a DAO (you can do this with Migrations currently and in the future as an end user of Dapps), but you might want to work on this layer if you need your DAO to have a unique action, constraint, or voting process that is not yet implemented on Arc. You can find the complete Arc docs here: https://daostack.github.io/arc","title":"Should I work at this level?"},{"location":"stack/client/GettingStarted/","text":"Installation Install the package with npm or yarn 1 2 3 4 5 npm install @daostack/client # Or yarn add @daostack/client Import Once installed, import the module in your project 1 2 3 4 5 import { Arc } from @daostack/client //Or const { Arc } = require ( @daostack/client ) General Structure The client library provides a number of Classes that represent the DAOstack entities and configuration. Configuration Arc : holds the basic configuration i.e. which services to connect to. Any use of the library will start with instantiating a new Arc instance Entities represents information of DAOstack basic blocks. DAO : the DAOstack DAO and all its information. Reputation : native reputation contract of the DAO. Token : token contracts, including the native token of the DAO. Member : holders of reputation i.e. who have voting power in the DAO. Proposal : Proposal made in the DAO. Proposals belong to Schemes registered in the DAO. Vote : votes made on the proposal. Stake : stake made on the outcome of a proposal. Reward : rewards awarded by the DAO for a given proposal. Scheme : the various schemes (ContributionReward, SchemeRegistrar, GenericScheme etc) registered to the DAO and to which a proposal can be made. Scheme determines the conditions and effects of executing the proposal. Queue : queues for each scheme registered to the DAO. The proposal is ordered in queue upon submission. Follow the How to use guide for working details of client library.","title":"Getting Started"},{"location":"stack/client/GettingStarted/#installation","text":"Install the package with npm or yarn 1 2 3 4 5 npm install @daostack/client # Or yarn add @daostack/client","title":"Installation"},{"location":"stack/client/GettingStarted/#import","text":"Once installed, import the module in your project 1 2 3 4 5 import { Arc } from @daostack/client //Or const { Arc } = require ( @daostack/client )","title":"Import"},{"location":"stack/client/GettingStarted/#general-structure","text":"The client library provides a number of Classes that represent the DAOstack entities and configuration. Configuration Arc : holds the basic configuration i.e. which services to connect to. Any use of the library will start with instantiating a new Arc instance Entities represents information of DAOstack basic blocks. DAO : the DAOstack DAO and all its information. Reputation : native reputation contract of the DAO. Token : token contracts, including the native token of the DAO. Member : holders of reputation i.e. who have voting power in the DAO. Proposal : Proposal made in the DAO. Proposals belong to Schemes registered in the DAO. Vote : votes made on the proposal. Stake : stake made on the outcome of a proposal. Reward : rewards awarded by the DAO for a given proposal. Scheme : the various schemes (ContributionReward, SchemeRegistrar, GenericScheme etc) registered to the DAO and to which a proposal can be made. Scheme determines the conditions and effects of executing the proposal. Queue : queues for each scheme registered to the DAO. The proposal is ordered in queue upon submission. Follow the How to use guide for working details of client library.","title":"General Structure"},{"location":"stack/client/clientIntro/","text":"Client is a nodejs library that provides a helpful set of tools to interact with the DAOstack ecosystem. In particular, the library provides an interface to DAOstack contracts and DAOstack subgraph (an index of on-chain data). Should I work at this level? You should import client package as a dependency, if you are developing a dApp in DAOstack platform (we are using it to build our React App - Alchemy ) writing nodejs scripts that interact with the Arc Contracts and query data from the subgraph You should extend the client package, if you are interacting with Arc contracts that are not yet supported by Client.js modifying/extending DAOstack subgraph","title":"Intro"},{"location":"stack/client/clientIntro/#should-i-work-at-this-level","text":"You should import client package as a dependency, if you are developing a dApp in DAOstack platform (we are using it to build our React App - Alchemy ) writing nodejs scripts that interact with the Arc Contracts and query data from the subgraph You should extend the client package, if you are interacting with Arc contracts that are not yet supported by Client.js modifying/extending DAOstack subgraph","title":"Should I work at this level?"},{"location":"stack/client/example/","text":"In the following code we use the client library to interact with Arc contracts and then query the subgraph to fetch DAOstack data. Setup You can use development setup from Alchemy Starter or Starter-template Example Import Client 1 2 3 4 5 6 7 8 const client = require ( @daostack/client ) const Arc = client . Arc const DAO = client . DAO const Proposal = client . Proposal const utils = client . utils let arc ; Initialize Arc 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 const initialize = async () = { // Arc is the main class that handles configuration and connections // to various services. Create an Arc instance with settings to connect // to the local docker images arc = new Arc ({ graphqlHttpProvider : http://127.0.0.1:8000/subgraphs/name/daostack , graphqlWsProvider : http://127.0.0.1:8001/subgraphs/name/daostack , web3Provider : ws://127.0.0.1:8545 , ipfsProvider : /ip4/127.0.0.1/tcp/5001 , }) // we must provice Arc with some contract information. // We can use setContractInfos to set them manually, or // get this information from the subgraph await arc . fetchContractInfos () } Add your private key While using Ganache, by default it will be set to account[0] 1 2 3 // Add your private key or you can use metamask web3Provider above const account = arc . web3 . eth . accounts . privateKeyToAccount ( PRIVATE_KEY ) arc . web3 . eth . accounts . wallet . add ( account ) Query All DAOs 1 2 3 4 5 6 7 8 9 const showAllDAOs = () = { // we subscribe to the data needed to create resultant set i.e. DAO id in this case arc . daos (). subscribe ( ( daos ) = { console . log ( Here are all the DAOS: ) daos . map ( dao = console . log ( ` ${ dao . name } at address ${ dao . id } ` )) } ) } Create Proposal 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 const createProposal = async () = { // we get the first returned item from the obervable that returns a list of DAOs const daos = await arc . daos (). first () // given the id of a DAO, we can also create a fresh DAO instance const dao = new DAO ( 0xdao-id , arc ) // or can get the dao from the dao list // const dao = daos[0] // or fetch the dao from arc by its ID // const dao = await arc.dao( 0xdao-id ) // to create a proposal, we must first find the address of the Scheme in which to create the proposal const schemes = await dao . schemes ({ where : { name : ContributionReward }}). first () if ( schemes . length === 0 ) { throw Error ( Something went wrong - no ContributionReward scheme was registered with this DAO ) } console . log ( `Creating new proposal in DAO: ${ dao . id } for Scheme: ${ schemes [ 0 ]. staticState . address } ` ) // Send Transaction to create new proposal let minedTx = await dao . createProposal ({ description : This is a Sample proposal , title : Sample Proposal , url : http://localhost:3000 , scheme : schemeState . address , beneficiary : 0x90F8bf6A479f320ead074411a4B0e7944Ea8c9C1 , nativeTokenReward : , reputationReward : utils . toWei ( 100 ), ethReward : utils . toWei ( 1 ), externalTokenReward : , externalTokenAddress : , periodLength : , periods : }). send () console . log ( `Tx Hash: ${ minedTx . receipt . transactionHash } ` ) } Query Proposals Query the subgraph to get Details of all the proposals 1 2 3 4 5 6 7 8 9 10 11 12 const showProposalDetails = async () = { const daos = await arc . daos (). first () const dao = daos [ 0 ] // or the index of whichever DAO you are interested in const proposals = dao . proposals (). subscribe ( async ( proposals ) = { for ( let proposal of proposals ) { proposal . state (). subscribe ( ( p ) = console . log ( p ) ) } }) } Vote on Proposal This will only succeed if the proposal is still open for voting and the account has reputation in the respective DAO. 1 2 3 4 5 6 7 8 9 10 const voteOnProposal = async () = { const proposal = new Proposal ( 0x123abc.... , arc ) try { await proposal . vote ( IProposalOutcome . Pass ) . send () } catch ( err ) { // an error occurred , perhaps the proposal voting period ended , or the sender s account does no thave any reputation console . log ( err . message ) } } Query Votes We will query all the voters for the given proposal 1 2 3 4 5 6 7 8 9 10 11 const showAllVotes = async () = { const proposal = new client . Proposal ( 0xfa06e538a0ecb32c1cd1eaad2102a8104180b56b6f088fab298c1ce86f582b8e , arc ) proposal . votes ({}, { fetchAllData : true }). subscribe ( async ( votes ) = { for ( let vote of votes ) { vote . state (). subscribe ( ( vote ) = { console . log ( vote ) console . log ( `Vote id: ${ vote . id } , voter: ${ vote . voter } , proposal: ${ proposal . id } ` ) })}}) }","title":"Quick Example"},{"location":"stack/client/example/#setup","text":"You can use development setup from Alchemy Starter or Starter-template","title":"Setup"},{"location":"stack/client/example/#example","text":"","title":"Example"},{"location":"stack/client/example/#import-client","text":"1 2 3 4 5 6 7 8 const client = require ( @daostack/client ) const Arc = client . Arc const DAO = client . DAO const Proposal = client . Proposal const utils = client . utils let arc ;","title":"Import Client"},{"location":"stack/client/example/#initialize-arc","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 const initialize = async () = { // Arc is the main class that handles configuration and connections // to various services. Create an Arc instance with settings to connect // to the local docker images arc = new Arc ({ graphqlHttpProvider : http://127.0.0.1:8000/subgraphs/name/daostack , graphqlWsProvider : http://127.0.0.1:8001/subgraphs/name/daostack , web3Provider : ws://127.0.0.1:8545 , ipfsProvider : /ip4/127.0.0.1/tcp/5001 , }) // we must provice Arc with some contract information. // We can use setContractInfos to set them manually, or // get this information from the subgraph await arc . fetchContractInfos () }","title":"Initialize Arc"},{"location":"stack/client/example/#add-your-private-key","text":"While using Ganache, by default it will be set to account[0] 1 2 3 // Add your private key or you can use metamask web3Provider above const account = arc . web3 . eth . accounts . privateKeyToAccount ( PRIVATE_KEY ) arc . web3 . eth . accounts . wallet . add ( account )","title":"Add your private key"},{"location":"stack/client/example/#query-all-daos","text":"1 2 3 4 5 6 7 8 9 const showAllDAOs = () = { // we subscribe to the data needed to create resultant set i.e. DAO id in this case arc . daos (). subscribe ( ( daos ) = { console . log ( Here are all the DAOS: ) daos . map ( dao = console . log ( ` ${ dao . name } at address ${ dao . id } ` )) } ) }","title":"Query All DAOs"},{"location":"stack/client/example/#create-proposal","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 const createProposal = async () = { // we get the first returned item from the obervable that returns a list of DAOs const daos = await arc . daos (). first () // given the id of a DAO, we can also create a fresh DAO instance const dao = new DAO ( 0xdao-id , arc ) // or can get the dao from the dao list // const dao = daos[0] // or fetch the dao from arc by its ID // const dao = await arc.dao( 0xdao-id ) // to create a proposal, we must first find the address of the Scheme in which to create the proposal const schemes = await dao . schemes ({ where : { name : ContributionReward }}). first () if ( schemes . length === 0 ) { throw Error ( Something went wrong - no ContributionReward scheme was registered with this DAO ) } console . log ( `Creating new proposal in DAO: ${ dao . id } for Scheme: ${ schemes [ 0 ]. staticState . address } ` ) // Send Transaction to create new proposal let minedTx = await dao . createProposal ({ description : This is a Sample proposal , title : Sample Proposal , url : http://localhost:3000 , scheme : schemeState . address , beneficiary : 0x90F8bf6A479f320ead074411a4B0e7944Ea8c9C1 , nativeTokenReward : , reputationReward : utils . toWei ( 100 ), ethReward : utils . toWei ( 1 ), externalTokenReward : , externalTokenAddress : , periodLength : , periods : }). send () console . log ( `Tx Hash: ${ minedTx . receipt . transactionHash } ` ) }","title":"Create Proposal"},{"location":"stack/client/example/#query-proposals","text":"Query the subgraph to get Details of all the proposals 1 2 3 4 5 6 7 8 9 10 11 12 const showProposalDetails = async () = { const daos = await arc . daos (). first () const dao = daos [ 0 ] // or the index of whichever DAO you are interested in const proposals = dao . proposals (). subscribe ( async ( proposals ) = { for ( let proposal of proposals ) { proposal . state (). subscribe ( ( p ) = console . log ( p ) ) } }) }","title":"Query Proposals"},{"location":"stack/client/example/#vote-on-proposal","text":"This will only succeed if the proposal is still open for voting and the account has reputation in the respective DAO. 1 2 3 4 5 6 7 8 9 10 const voteOnProposal = async () = { const proposal = new Proposal ( 0x123abc.... , arc ) try { await proposal . vote ( IProposalOutcome . Pass ) . send () } catch ( err ) { // an error occurred , perhaps the proposal voting period ended , or the sender s account does no thave any reputation console . log ( err . message ) } }","title":"Vote on Proposal"},{"location":"stack/client/example/#query-votes","text":"We will query all the voters for the given proposal 1 2 3 4 5 6 7 8 9 10 11 const showAllVotes = async () = { const proposal = new client . Proposal ( 0xfa06e538a0ecb32c1cd1eaad2102a8104180b56b6f088fab298c1ce86f582b8e , arc ) proposal . votes ({}, { fetchAllData : true }). subscribe ( async ( votes ) = { for ( let vote of votes ) { vote . state (). subscribe ( ( vote ) = { console . log ( vote ) console . log ( `Vote id: ${ vote . id } , voter: ${ vote . voter } , proposal: ${ proposal . id } ` ) })}}) }","title":"Query Votes"},{"location":"stack/client/howToUseClient/","text":"How To Use In the following guide we describe how to instantiate classes and discuss the common methods shared by all Entities. Please refer to complete API reference for detailed list of properties and methods Configuration: Arc The Arc class holds the basic configuration and serves as the main entrypoint when using the library. The user of the library must provide some basic configuration options. Configuration Options Please see the API Reference for details of Configuration Options and their types. contractInfos[] : contracts details. Can be set/fetch using subgraph by setContractInfos / fetchContractInfos . graphqlHttpProvider : http connection to the subgraph of TheGraph protocol. Needed for graphQL queries. graphqlPrefetchHook() : function executed before sending graphQL query. graphqlSubscribeToQueries : determines if query should subscribe to updates from the graphProvider. Default True. graphqlWsProvider : web socket connection to subgraph of TheGraph protocol. Needed for subscriptions. ipfsProvider : connection to ipfs provider which is used as the data storage layer by DAOstack. The configuration is either a string or an object as used here web3Provider : connection to ethereum node which it is presumed has a default account enabling transactions to be sent. Required to create and send transactions to the blockchain. web3ProviderRead : connection to ethereum node to read Arc data. If provided arc will read all data from this provider, else if null/not provided it is set same as web3Provider . This is readonly and won't enable the user to submit transactions. Example 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 import { Arc } from @daostack/client const arc = new Arc ({ graphqlHttpProvider : https://subgraph.daostack.io/subgraphs/name/v23 , graphqlWsProvider : wss://ws.subgraph.daostack.io/subgraphs/name/v23 , web3Provider : `wss://mainnet.infura.io/ws/v3/e0cdf3bfda9b468fa908aa6ab03d5ba2` , ipfsProvider : { host : subgraph.daostack.io , port : 443 , protocol : https , api-path : /ipfs/api/v0/ } }) // before we can use the Arc instance to send transactions , we need to provide it // with information on where the contracts can be found // query the subgraph for the contract addresses , and use those await arc . fetchContractInfos () Note: If you instantiate arc with ipfs configuration, then arc.ipfs will have all the methods of the ipfslcient api available. Refer to ipfs client api Some of these configuration settings are optional while using @daostack/client . For example: For using client to only create and send transactions to the blockchain, it is sufficient to provide the web3Provider . For using client to only read blockchain data, it is sufficient to provide the web3ProviderRead . When using client only to interact with subgraph, it is sufficient to provide graphqlHttpProvider and/or graphqlWsProvider . Entities Entities are the basic building blocks of DAOstack ecosystem. The entity instance holds the static and dynamic state of the entity it represents and encapsulates graphql queries to retrieve data from subgraph. The client library caches entity data. Please refer to Common properties and methods section for more information about what is cached and how to retrieve it. While the entity classes provide nice helper methods that encapsulate graphql queries, you can also submit your own customized graphql queries using the static method arc.apolloClient . The client library uses Apollo for data management which is discussed in Query and Cache section . Please refer to the Queries section about all the ways to query subgraph. Instantiate All Entity classes can be created by providing an instance of Arc and either of the following: id : in this case a query to the subgraph is used to hydrate the entity. staticState : here entity's desired \"static state\" is provided at initialization and the subgraph query is bypassed. By providing entity id When using the client library with an arc instance which has subgraph configuration, it is sufficient to provide just an id . In this case, to vote or stake, the proposal object will need additional information (stored by the staticState of Entity) such as the address of the voting machine contract to which votes will be sent. The client will query the subgraph for this minimal set of information. Example 1 2 3 const proposal = new Proposal ( 0x1234.... , arc ) await proposal . vote ( ... ) . send () By providing static entity state To make the client usable without having subgraph service available, all Entities can also be created by providing the 'static state'. This will provide the instance with enough information to send transactions without having to query the subgraph for additional information. Example 1 2 3 4 5 6 7 8 const arc = new Arc ( { web3Provider : ` wss : // mainnet . infura . io / ws / v3 / e0cdf3bfda9b468fa908aa6ab03d5ba2 ` , } ) const proposal = new Proposal ( { id : 0x12455.. , votingMachine : 0x1111.. , scheme : 0x12345... } , arc ) Common methods and properties All entities have: context : arc configuration described above id : unique identifier of the entity instance. Various Entity class Id represents the information as described below: address : DAO, Reputation, Token hash(ReputationAddress, RepHolderAddress) : Members proposalId as on blockchain: Proposal hash(proposalId, beneficiaryAddress) : Reward hash(daoAddress, schemeAddress) : Scheme eventId : Stake, Vote staticState [1] : object representing properties of the entity that does not change over time. e.g. In case of entity DAO, address of Avatar or Native reputation of DAO fetchStaticState() [1] : method that returns an observable of object that represent the staticState of the entity. If the staticState is not set ( as here ), then at first use it queries the subgraph and setStaticState . setStaticState() [1] : method that sets the static state to the state provided as parameter. state() : method that returns an observable of objects that represent the current dynamic state of the entity. The dynamic state extends the static state to include properties that may change over time. e.g. IDAOState is dynamic state that would contain numberOfBoostedProposals or reputationTotalSupply along with the base static state of the DAO entity. e.g. Subscribe [2] to current state of the Proposal or DAO 1 2 3 4 5 6 7 proposal . state (). subscribe ( ( newState ) = console . log (` This proposal has ${ newState . votesFor } upvotes `) ) dao . state (). subscribe ( ( newState ) = console . log (` This DAO has ${ newState . memberCount } members `) ) search() [3] : static method which can be called from the Entity class and is used to search for the entities on the subgraph. Parameters: context : must be provided with an Arc instance with subgraph details, so it knows which service to send the queries. options (optional): query filter options apolloQueryOptions (optional): apollo query options By default it will return an observable of id(s) of the subgraph Entity for the given filter query, but can be modified to fetch the state() using apolloQueryOptions . eg. To get all DAOs that are called Foo , you can do: 1 2 3 4 DAO . search ( arc , { where : { name : Foo }} ) eg. To get current state of all DAOs that are called Foo ordered by createdAt , you can do: 1 2 3 4 5 6 7 8 DAO . search ( arc , // context { where : { name : Foo } , orderBy : createdAt } , // options { fetchAllData : true } // apolloQueryOptions ) Note: staticState , setStaticState and fetchStaticState is not available for all Entities consistantly and might be discontinued or restructured in future versions. There is a difference between state().subscribe and state({subscribe: true}) . Refer Types of Subscriptions All queries return rxjs.Observable . See below for further explanation. Search filters and Observables The search functions are wrappers around graphql queries and standard graphql syntax can be used to filter and sort the queries, and for pagination: 1 Proposal . search ( arc , { where : { dao : 0x1234.. }} ) 1 2 dao . proposals ( { where : { scheme : 0xffcf8fdee72ac11b5c542428b35eef5769c409f0 }} ) dao . proposals ( { where : { scheme_in : [ 0xffcf8fdee72ac11b5c542428b35eef5769c409f0 ] }} ) Paging 1 dao . proposals ( { skip : 100 , first : 100 } ) Sorting: 1 dao . proposals ( { orderBy : createdAt , orderDirection : desc } ) All these queries return an rxjs Observable object. This observables return a stream of results. Every time the data in the query gets updated, the observable will emit a new result. Observables are very flexible. Typically, an observable will be used by creating a subscription as described below. Please refer to Subscriptions section for details on when and how to use it and the types of subscription. 1 2 3 4 5 6 7 const observable = dao . proposals () // all proposals in this dao // a subscription const subscription = observable . subscribe ( ( next ) = console . log ( ` Now there are ${ next . length } proposals ` ) // will be called each time the data from the qeury changes ) subscription . unsubscribe () // do not forget to unsubscribe If you are only interested in the first result, but do not want to get further updates when the data is changed, there is a helper function that returns a Promise with the first result 1 2 const observable = dao . proposals () // all proposals in this dao const proposals = await observable . first () // returns a list of Proposal instances Sending transactions One of the purposes of the client library is to make help with interactions with the DAOstack Ethereum contracts. Here is how you create a proposal in a DAO for a contribution reward 1 2 3 4 5 6 7 8 9 10 const DAO = new DAO ( 0x123DAOADDRESS ) const tx = dao . createProposal ( { beneficiary : 0xffcf8fdee72ac11b5c542428b35eef5769c409f0 , ethReward : toWei ( 300 ), nativeTokenReward : toWei ( 1 ), periodLength : 0 , periods : 1 , reputationReward : toWei ( 10 ), scheme : 0xContributionRewardAddress // address of a contribution reward scheme that is registered with this DAO } ) All functions that send a transaction to the blockchain (like DAO.createProposal , Proposal.vote , Token.mint , etc, etc) return an rxjs Observable. This observable returns a stream of updates about the state of the transaction: first when it is sent, then when it is mined and confirmed. You can subscribe to the transaction: 1 2 3 4 5 6 7 8 tx . subscribe ( ( next ) = { console . log ( next . state ) // sending , sent , or mined if ( next . stage === ITransactionStage . Mined ) { console . log (` This transaction has ${ next . confirmations } confirmations `) console . log ( next . result ) } }) All operations also provide a convenience function send() that returns a promise that resolves when the transaction is mined 1 2 const voteTransaction = await proposal . vote ( ... ) . send () const vote = voteTransaction . result // an instance of Vote For details, checkout complete API reference","title":"How To Use"},{"location":"stack/client/howToUseClient/#how-to-use","text":"In the following guide we describe how to instantiate classes and discuss the common methods shared by all Entities. Please refer to complete API reference for detailed list of properties and methods","title":"How To Use"},{"location":"stack/client/howToUseClient/#configuration-arc","text":"The Arc class holds the basic configuration and serves as the main entrypoint when using the library. The user of the library must provide some basic configuration options.","title":"Configuration: Arc"},{"location":"stack/client/howToUseClient/#configuration-options","text":"Please see the API Reference for details of Configuration Options and their types. contractInfos[] : contracts details. Can be set/fetch using subgraph by setContractInfos / fetchContractInfos . graphqlHttpProvider : http connection to the subgraph of TheGraph protocol. Needed for graphQL queries. graphqlPrefetchHook() : function executed before sending graphQL query. graphqlSubscribeToQueries : determines if query should subscribe to updates from the graphProvider. Default True. graphqlWsProvider : web socket connection to subgraph of TheGraph protocol. Needed for subscriptions. ipfsProvider : connection to ipfs provider which is used as the data storage layer by DAOstack. The configuration is either a string or an object as used here web3Provider : connection to ethereum node which it is presumed has a default account enabling transactions to be sent. Required to create and send transactions to the blockchain. web3ProviderRead : connection to ethereum node to read Arc data. If provided arc will read all data from this provider, else if null/not provided it is set same as web3Provider . This is readonly and won't enable the user to submit transactions. Example 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 import { Arc } from @daostack/client const arc = new Arc ({ graphqlHttpProvider : https://subgraph.daostack.io/subgraphs/name/v23 , graphqlWsProvider : wss://ws.subgraph.daostack.io/subgraphs/name/v23 , web3Provider : `wss://mainnet.infura.io/ws/v3/e0cdf3bfda9b468fa908aa6ab03d5ba2` , ipfsProvider : { host : subgraph.daostack.io , port : 443 , protocol : https , api-path : /ipfs/api/v0/ } }) // before we can use the Arc instance to send transactions , we need to provide it // with information on where the contracts can be found // query the subgraph for the contract addresses , and use those await arc . fetchContractInfos () Note: If you instantiate arc with ipfs configuration, then arc.ipfs will have all the methods of the ipfslcient api available. Refer to ipfs client api Some of these configuration settings are optional while using @daostack/client . For example: For using client to only create and send transactions to the blockchain, it is sufficient to provide the web3Provider . For using client to only read blockchain data, it is sufficient to provide the web3ProviderRead . When using client only to interact with subgraph, it is sufficient to provide graphqlHttpProvider and/or graphqlWsProvider .","title":"Configuration Options"},{"location":"stack/client/howToUseClient/#entities","text":"Entities are the basic building blocks of DAOstack ecosystem. The entity instance holds the static and dynamic state of the entity it represents and encapsulates graphql queries to retrieve data from subgraph. The client library caches entity data. Please refer to Common properties and methods section for more information about what is cached and how to retrieve it. While the entity classes provide nice helper methods that encapsulate graphql queries, you can also submit your own customized graphql queries using the static method arc.apolloClient . The client library uses Apollo for data management which is discussed in Query and Cache section . Please refer to the Queries section about all the ways to query subgraph.","title":"Entities"},{"location":"stack/client/howToUseClient/#instantiate","text":"All Entity classes can be created by providing an instance of Arc and either of the following: id : in this case a query to the subgraph is used to hydrate the entity. staticState : here entity's desired \"static state\" is provided at initialization and the subgraph query is bypassed.","title":"Instantiate"},{"location":"stack/client/howToUseClient/#by-providing-entity-id","text":"When using the client library with an arc instance which has subgraph configuration, it is sufficient to provide just an id . In this case, to vote or stake, the proposal object will need additional information (stored by the staticState of Entity) such as the address of the voting machine contract to which votes will be sent. The client will query the subgraph for this minimal set of information. Example 1 2 3 const proposal = new Proposal ( 0x1234.... , arc ) await proposal . vote ( ... ) . send ()","title":"By providing entity id"},{"location":"stack/client/howToUseClient/#by-providing-static-entity-state","text":"To make the client usable without having subgraph service available, all Entities can also be created by providing the 'static state'. This will provide the instance with enough information to send transactions without having to query the subgraph for additional information. Example 1 2 3 4 5 6 7 8 const arc = new Arc ( { web3Provider : ` wss : // mainnet . infura . io / ws / v3 / e0cdf3bfda9b468fa908aa6ab03d5ba2 ` , } ) const proposal = new Proposal ( { id : 0x12455.. , votingMachine : 0x1111.. , scheme : 0x12345... } , arc )","title":"By providing static entity state"},{"location":"stack/client/howToUseClient/#common-methods-and-properties","text":"All entities have: context : arc configuration described above id : unique identifier of the entity instance. Various Entity class Id represents the information as described below: address : DAO, Reputation, Token hash(ReputationAddress, RepHolderAddress) : Members proposalId as on blockchain: Proposal hash(proposalId, beneficiaryAddress) : Reward hash(daoAddress, schemeAddress) : Scheme eventId : Stake, Vote staticState [1] : object representing properties of the entity that does not change over time. e.g. In case of entity DAO, address of Avatar or Native reputation of DAO fetchStaticState() [1] : method that returns an observable of object that represent the staticState of the entity. If the staticState is not set ( as here ), then at first use it queries the subgraph and setStaticState . setStaticState() [1] : method that sets the static state to the state provided as parameter. state() : method that returns an observable of objects that represent the current dynamic state of the entity. The dynamic state extends the static state to include properties that may change over time. e.g. IDAOState is dynamic state that would contain numberOfBoostedProposals or reputationTotalSupply along with the base static state of the DAO entity. e.g. Subscribe [2] to current state of the Proposal or DAO 1 2 3 4 5 6 7 proposal . state (). subscribe ( ( newState ) = console . log (` This proposal has ${ newState . votesFor } upvotes `) ) dao . state (). subscribe ( ( newState ) = console . log (` This DAO has ${ newState . memberCount } members `) ) search() [3] : static method which can be called from the Entity class and is used to search for the entities on the subgraph. Parameters: context : must be provided with an Arc instance with subgraph details, so it knows which service to send the queries. options (optional): query filter options apolloQueryOptions (optional): apollo query options By default it will return an observable of id(s) of the subgraph Entity for the given filter query, but can be modified to fetch the state() using apolloQueryOptions . eg. To get all DAOs that are called Foo , you can do: 1 2 3 4 DAO . search ( arc , { where : { name : Foo }} ) eg. To get current state of all DAOs that are called Foo ordered by createdAt , you can do: 1 2 3 4 5 6 7 8 DAO . search ( arc , // context { where : { name : Foo } , orderBy : createdAt } , // options { fetchAllData : true } // apolloQueryOptions ) Note: staticState , setStaticState and fetchStaticState is not available for all Entities consistantly and might be discontinued or restructured in future versions. There is a difference between state().subscribe and state({subscribe: true}) . Refer Types of Subscriptions All queries return rxjs.Observable . See below for further explanation.","title":"Common methods and properties"},{"location":"stack/client/howToUseClient/#search-filters-and-observables","text":"The search functions are wrappers around graphql queries and standard graphql syntax can be used to filter and sort the queries, and for pagination: 1 Proposal . search ( arc , { where : { dao : 0x1234.. }} ) 1 2 dao . proposals ( { where : { scheme : 0xffcf8fdee72ac11b5c542428b35eef5769c409f0 }} ) dao . proposals ( { where : { scheme_in : [ 0xffcf8fdee72ac11b5c542428b35eef5769c409f0 ] }} ) Paging 1 dao . proposals ( { skip : 100 , first : 100 } ) Sorting: 1 dao . proposals ( { orderBy : createdAt , orderDirection : desc } ) All these queries return an rxjs Observable object. This observables return a stream of results. Every time the data in the query gets updated, the observable will emit a new result. Observables are very flexible. Typically, an observable will be used by creating a subscription as described below. Please refer to Subscriptions section for details on when and how to use it and the types of subscription. 1 2 3 4 5 6 7 const observable = dao . proposals () // all proposals in this dao // a subscription const subscription = observable . subscribe ( ( next ) = console . log ( ` Now there are ${ next . length } proposals ` ) // will be called each time the data from the qeury changes ) subscription . unsubscribe () // do not forget to unsubscribe If you are only interested in the first result, but do not want to get further updates when the data is changed, there is a helper function that returns a Promise with the first result 1 2 const observable = dao . proposals () // all proposals in this dao const proposals = await observable . first () // returns a list of Proposal instances","title":"Search filters and Observables"},{"location":"stack/client/howToUseClient/#sending-transactions","text":"One of the purposes of the client library is to make help with interactions with the DAOstack Ethereum contracts. Here is how you create a proposal in a DAO for a contribution reward 1 2 3 4 5 6 7 8 9 10 const DAO = new DAO ( 0x123DAOADDRESS ) const tx = dao . createProposal ( { beneficiary : 0xffcf8fdee72ac11b5c542428b35eef5769c409f0 , ethReward : toWei ( 300 ), nativeTokenReward : toWei ( 1 ), periodLength : 0 , periods : 1 , reputationReward : toWei ( 10 ), scheme : 0xContributionRewardAddress // address of a contribution reward scheme that is registered with this DAO } ) All functions that send a transaction to the blockchain (like DAO.createProposal , Proposal.vote , Token.mint , etc, etc) return an rxjs Observable. This observable returns a stream of updates about the state of the transaction: first when it is sent, then when it is mined and confirmed. You can subscribe to the transaction: 1 2 3 4 5 6 7 8 tx . subscribe ( ( next ) = { console . log ( next . state ) // sending , sent , or mined if ( next . stage === ITransactionStage . Mined ) { console . log (` This transaction has ${ next . confirmations } confirmations `) console . log ( next . result ) } }) All operations also provide a convenience function send() that returns a promise that resolves when the transaction is mined 1 2 const voteTransaction = await proposal . vote ( ... ) . send () const vote = voteTransaction . result // an instance of Vote For details, checkout complete API reference","title":"Sending transactions"},{"location":"stack/client/querying/","text":"Query, Observables Subscription Your interactions with the DAOstack subgraph will involve working with the following: Query : the graphQL queries sent to graphnode to fetch DAOstack data from the subgraph. Observable : object representing the stream of data to which one can subscribe. Subscription : invokes a given function every time a new value is emitted for the observable. The entity methods provided by @daostack/client for querying the subgraph, by themselves do not actually send the query to the server. Instead, each methods returns an Observable to which we can subscribe , which is what actually initiates the query. Take a look at the following methods that return observable: 1 2 arc . daos () proposal . state () Now, in order to query the server we must subscribe 1 2 3 4 5 6 7 8 9 10 11 12 const observable = arc . daos () const subscription = observable . subscribe ( ( daos ) = console . log ( `we found ${ daos . length } results` ) ) const proposal = new Propsal ( 0x123abc.... , arc ) let stateObservable = proposal . state () stateObservable . subscribe ( ( proposal ) = console . log ( proposal ) ) In this guide we will describe how to create send query and subscribe to the data requested by the query. Why Subscription Subscriptions will cause the server to send you an update each time the data changes and are useful for composing asynchronous and event-based programs. By default, subscribing to an observable will do two things: send a query to the server to fetch the data send a subscription query to the server for update events How to Query and Subscribe Creating Queries As described in the following sections, you can query the subgraph using either entity methods or raw GraphQL queries. Entity Methods The entity methods return an Observables which encapsulate some predefined qraphQL queries to fetch Entity data from the subgraph. 1 2 3 4 5 // proposals of the DAO const proposalsObservable = Proposal . search ( arc , { where : { dao : 0x123 } } ) // members of the given dao const membersObservable = dao . members () Raw GraphQL queries To have more control over what gets fetched from the subgraph you can also customize the query. These queries will follow the standard graphQL syntax which is used to query graph explorer directly. Though the query must be wrapped inside the gql tag 1 2 3 4 5 6 const gql = require ( graphql-tag ) // titles of all proposals of the DAO let query = gql ` query { proposals ( where : { dao : 0x294f999356ed03347c7a23bcbcf8d33fa41dc830 } ) { title } } ` Executing a Query After creating a query, as we did in the previous section, we need to cause the query to be executed, that is, be sent to the graphnode server. Entity Methods We can subscribe to an observable with {subscribe: false} parameter (introduced in the subscribing to a query section ) for sending a one-time query without subscribing to further updates from the server for result of the query. 1 2 3 4 5 6 7 8 // Get all proposals Id of the DAO without subscribing to server const proposalsObs = dao . proposals ( {}, { subscribe : false } ) // send query and subscribe to the cache updates proposalsObs . subscribe (() = {} ) // Unsubscribe to cache once done proposalsObs . unsubscribe () Note : Refer to the Subscribe to Apollo Cache changes section to understand difference between cache and server update. Raw GraphQL queries You can submit raw GraphQL queries using the static method arc.sendQuery . Pass the query designed above as the parameter to sendQuery . 1 2 3 4 5 // Get votes id and outcome of the given Proposal arc . sendQuery ( gql ` query { proposal ( id : 0x1245 ) { votes { id outcome } }} ` ) Subscribing to a Query Use Subscriptions to invoke the handler that you supply to run every time a new value is emitted by an observable stream. This is useful to keep the app data updated as the value changes. Entity methods As we saw the Entity methods do not send the query to the server but return an observable. We must subscribe as follows to send the query as well as subscribe for server updates. 1 2 arc . daos (). subscribe (() = {} ) dao . state (). subscribe ( () = {} ) Note : Refer to the Subscribe to Apollo Cache changes section to understand difference between cache and server updates. Raw graphQL queries For even more control over what data is being fetched and subscribed to, you can write explicit queries: 1 2 3 4 5 6 arc . subscribe ( gql ` subscribe { proposal ( id : 0x1245 ) { votes { id outcome }} ) ` ) new Proposal ( 0x1245 ) . votes () . subscribe ( ( next ) = { } ) Optimizing How Subscriptions Use the Cache Since, subscriptions can be expensive, this behavior can be controlled/optimized in several ways. The client library uses Apollo for data management which offers an intelligent caching and declarative approach to data fetching. Controlling fetchPolicy : controlling cache interaction. Subscribing to Apollo Cache : getting updates from Apollo cache instead of graphnode server. FetchAllData and Nested subscription : by querying larger set at top level and subscribing to Apollo cache for nested queries. Controlling Apollo fetchPolicy We can pass Apollo's fetchPolicy argument to control how the query interacts with the cache: cache-first : default value. Read data from cache first, fetch from network if data is not available in cache. cache-and-network : return data from cache first and then always fetch from network to update the cache. It optimizes quick response while also keep cached data updated. network-only : will always make a request using network and write data to cache. It optimizes for data consistency with the server. cache-only : will never execute a query using your network interface and throw error if data not available in cache. no-cache : like network-only it will always make a request using your network interface. But, it will not write any data to the cache 1 2 arc . daos ( {} , { fetch - policy : cache-first } ) // the default value arc . daos ( { where : { stage : Boosted }} , { fetch - policy : network-only } ) // bypass the cache Subscribe to Apollo Cache changes As we have seen the client library offers two types of subscription that can be controlled by the subscribe parameter. server and cache { subscribe: true } : explicitly ask for the updates from the graph-node server. Update the cache with the results of the query. only cache { subscribe: false } : do not subscribe to the updates from the server but still subscribe to the Apollo cache changes. NOTE: By default subscribe is set to true. Apollo cache could change as a result of another query which does subscribe to server changes. e.g. In q1 we will not subscribe to the updates from network but will still watch changes in the Apollo cache and return updated results if the cache changes. 1 arc . daos ({}, { fetchAllData : true , subscribe : false }). subscribe (() = {}) // q1 In q2 we subscribe to server updates. The results of these updates are added to the Apollo cache and the observable in q1 will also get the updates if cache changes. 1 dao . state (). subscribe ( () = {}) // q2 Use fetchAllData with Nested subscription Most of the Entity methods are implemented in such a way that the queries will fetch (and subscribe to) just as much data as is needed to create the result set. For example, dao.proposals() will only fetch the proposal IDs. This can be controlled (in a limited way) by setting the parameter fetchAllData to true 1 dao . proposals ( { orderBy : creationDate } , { fetchAllData : true } ) This is useful for cache handling, where it may be useful to have more complete control over what data is being fetched. Consider the following example, which will get the list of proposals from the dao, and then get the state for each of the proposals. 1 2 3 4 5 6 7 dao . proposals () . subscribe ( ( proposals ) = { for ( let proposal of proposals ) { proposal . state () . subscribe ( ..... ) } } ) The problem with this pattern is that it is very expensive. The (subscription to) dao.proposals(..) will send a query and create a subscription and then each of the calls to proposal.state() will create a new query and a separate subscription. Consider now the following pattern: 1 2 3 4 5 6 7 dao . proposals ( {}, { fetchAllData : true } ) . subscribe ( ( proposals ) = { for ( let proposal of proposals ) { proposal . state ( {}, { subscribe : false } ) . subscribe ( ..... ) } } ) This will resolve two inefficiencies. First of all, the fetchAllData in the proposals query will make it so that the dao.proposals query will fetch (and subscribe to) a much larger query - in particular, it will get all state data for each of the proposals. This means that when prop.state() is called, it will find all the needed information in the cache (and so it will not send a new query to the server), and we can safely pass it the subscribe: false flag, because dao.proposals() already subscribes to updates for all the cached data.","title":"Query, Observables & Subscriptions"},{"location":"stack/client/querying/#query-observables-subscription","text":"Your interactions with the DAOstack subgraph will involve working with the following: Query : the graphQL queries sent to graphnode to fetch DAOstack data from the subgraph. Observable : object representing the stream of data to which one can subscribe. Subscription : invokes a given function every time a new value is emitted for the observable. The entity methods provided by @daostack/client for querying the subgraph, by themselves do not actually send the query to the server. Instead, each methods returns an Observable to which we can subscribe , which is what actually initiates the query. Take a look at the following methods that return observable: 1 2 arc . daos () proposal . state () Now, in order to query the server we must subscribe 1 2 3 4 5 6 7 8 9 10 11 12 const observable = arc . daos () const subscription = observable . subscribe ( ( daos ) = console . log ( `we found ${ daos . length } results` ) ) const proposal = new Propsal ( 0x123abc.... , arc ) let stateObservable = proposal . state () stateObservable . subscribe ( ( proposal ) = console . log ( proposal ) ) In this guide we will describe how to create send query and subscribe to the data requested by the query.","title":"Query, Observables &amp; Subscription"},{"location":"stack/client/querying/#why-subscription","text":"Subscriptions will cause the server to send you an update each time the data changes and are useful for composing asynchronous and event-based programs. By default, subscribing to an observable will do two things: send a query to the server to fetch the data send a subscription query to the server for update events","title":"Why Subscription"},{"location":"stack/client/querying/#how-to-query-and-subscribe","text":"","title":"How to Query and Subscribe"},{"location":"stack/client/querying/#creating-queries","text":"As described in the following sections, you can query the subgraph using either entity methods or raw GraphQL queries.","title":"Creating Queries"},{"location":"stack/client/querying/#entity-methods","text":"The entity methods return an Observables which encapsulate some predefined qraphQL queries to fetch Entity data from the subgraph. 1 2 3 4 5 // proposals of the DAO const proposalsObservable = Proposal . search ( arc , { where : { dao : 0x123 } } ) // members of the given dao const membersObservable = dao . members ()","title":"Entity Methods"},{"location":"stack/client/querying/#raw-graphql-queries","text":"To have more control over what gets fetched from the subgraph you can also customize the query. These queries will follow the standard graphQL syntax which is used to query graph explorer directly. Though the query must be wrapped inside the gql tag 1 2 3 4 5 6 const gql = require ( graphql-tag ) // titles of all proposals of the DAO let query = gql ` query { proposals ( where : { dao : 0x294f999356ed03347c7a23bcbcf8d33fa41dc830 } ) { title } } `","title":"Raw GraphQL queries"},{"location":"stack/client/querying/#executing-a-query","text":"After creating a query, as we did in the previous section, we need to cause the query to be executed, that is, be sent to the graphnode server.","title":"Executing a Query"},{"location":"stack/client/querying/#entity-methods_1","text":"We can subscribe to an observable with {subscribe: false} parameter (introduced in the subscribing to a query section ) for sending a one-time query without subscribing to further updates from the server for result of the query. 1 2 3 4 5 6 7 8 // Get all proposals Id of the DAO without subscribing to server const proposalsObs = dao . proposals ( {}, { subscribe : false } ) // send query and subscribe to the cache updates proposalsObs . subscribe (() = {} ) // Unsubscribe to cache once done proposalsObs . unsubscribe () Note : Refer to the Subscribe to Apollo Cache changes section to understand difference between cache and server update.","title":"Entity Methods"},{"location":"stack/client/querying/#raw-graphql-queries_1","text":"You can submit raw GraphQL queries using the static method arc.sendQuery . Pass the query designed above as the parameter to sendQuery . 1 2 3 4 5 // Get votes id and outcome of the given Proposal arc . sendQuery ( gql ` query { proposal ( id : 0x1245 ) { votes { id outcome } }} ` )","title":"Raw GraphQL queries"},{"location":"stack/client/querying/#subscribing-to-a-query","text":"Use Subscriptions to invoke the handler that you supply to run every time a new value is emitted by an observable stream. This is useful to keep the app data updated as the value changes.","title":"Subscribing to a Query"},{"location":"stack/client/querying/#entity-methods_2","text":"As we saw the Entity methods do not send the query to the server but return an observable. We must subscribe as follows to send the query as well as subscribe for server updates. 1 2 arc . daos (). subscribe (() = {} ) dao . state (). subscribe ( () = {} ) Note : Refer to the Subscribe to Apollo Cache changes section to understand difference between cache and server updates.","title":"Entity methods"},{"location":"stack/client/querying/#raw-graphql-queries_2","text":"For even more control over what data is being fetched and subscribed to, you can write explicit queries: 1 2 3 4 5 6 arc . subscribe ( gql ` subscribe { proposal ( id : 0x1245 ) { votes { id outcome }} ) ` ) new Proposal ( 0x1245 ) . votes () . subscribe ( ( next ) = { } )","title":"Raw graphQL queries"},{"location":"stack/client/querying/#optimizing-how-subscriptions-use-the-cache","text":"Since, subscriptions can be expensive, this behavior can be controlled/optimized in several ways. The client library uses Apollo for data management which offers an intelligent caching and declarative approach to data fetching. Controlling fetchPolicy : controlling cache interaction. Subscribing to Apollo Cache : getting updates from Apollo cache instead of graphnode server. FetchAllData and Nested subscription : by querying larger set at top level and subscribing to Apollo cache for nested queries.","title":"Optimizing How Subscriptions Use the Cache"},{"location":"stack/client/querying/#controlling-apollo-fetchpolicy","text":"We can pass Apollo's fetchPolicy argument to control how the query interacts with the cache: cache-first : default value. Read data from cache first, fetch from network if data is not available in cache. cache-and-network : return data from cache first and then always fetch from network to update the cache. It optimizes quick response while also keep cached data updated. network-only : will always make a request using network and write data to cache. It optimizes for data consistency with the server. cache-only : will never execute a query using your network interface and throw error if data not available in cache. no-cache : like network-only it will always make a request using your network interface. But, it will not write any data to the cache 1 2 arc . daos ( {} , { fetch - policy : cache-first } ) // the default value arc . daos ( { where : { stage : Boosted }} , { fetch - policy : network-only } ) // bypass the cache","title":"Controlling Apollo fetchPolicy"},{"location":"stack/client/querying/#subscribe-to-apollo-cache-changes","text":"As we have seen the client library offers two types of subscription that can be controlled by the subscribe parameter. server and cache { subscribe: true } : explicitly ask for the updates from the graph-node server. Update the cache with the results of the query. only cache { subscribe: false } : do not subscribe to the updates from the server but still subscribe to the Apollo cache changes. NOTE: By default subscribe is set to true. Apollo cache could change as a result of another query which does subscribe to server changes. e.g. In q1 we will not subscribe to the updates from network but will still watch changes in the Apollo cache and return updated results if the cache changes. 1 arc . daos ({}, { fetchAllData : true , subscribe : false }). subscribe (() = {}) // q1 In q2 we subscribe to server updates. The results of these updates are added to the Apollo cache and the observable in q1 will also get the updates if cache changes. 1 dao . state (). subscribe ( () = {}) // q2","title":"Subscribe to Apollo Cache changes"},{"location":"stack/client/querying/#use-fetchalldata-with-nested-subscription","text":"Most of the Entity methods are implemented in such a way that the queries will fetch (and subscribe to) just as much data as is needed to create the result set. For example, dao.proposals() will only fetch the proposal IDs. This can be controlled (in a limited way) by setting the parameter fetchAllData to true 1 dao . proposals ( { orderBy : creationDate } , { fetchAllData : true } ) This is useful for cache handling, where it may be useful to have more complete control over what data is being fetched. Consider the following example, which will get the list of proposals from the dao, and then get the state for each of the proposals. 1 2 3 4 5 6 7 dao . proposals () . subscribe ( ( proposals ) = { for ( let proposal of proposals ) { proposal . state () . subscribe ( ..... ) } } ) The problem with this pattern is that it is very expensive. The (subscription to) dao.proposals(..) will send a query and create a subscription and then each of the calls to proposal.state() will create a new query and a separate subscription. Consider now the following pattern: 1 2 3 4 5 6 7 dao . proposals ( {}, { fetchAllData : true } ) . subscribe ( ( proposals ) = { for ( let proposal of proposals ) { proposal . state ( {}, { subscribe : false } ) . subscribe ( ..... ) } } ) This will resolve two inefficiencies. First of all, the fetchAllData in the proposals query will make it so that the dao.proposals query will fetch (and subscribe to) a much larger query - in particular, it will get all state data for each of the proposals. This means that when prop.state() is called, it will find all the needed information in the cache (and so it will not send a new query to the server), and we can safely pass it the subscribe: false flag, because dao.proposals() already subscribes to updates for all the cached data.","title":"Use fetchAllData with Nested subscription"},{"location":"stack/infra/infraIntro/","text":"Infra is a Solidity smart contract library containing the core building blocks of decentralized governance. Infra contracts can be integrated into any application regardless of its architecture. Infra has two main components: Voting Machines - A voting machine is a universal contract which can operate the voting process for any organization. Each voting machine follows its own predifined rules for the decision making and execution process. Rules for voting machines can be implemented for any voting process, from a simple protocol like an \"Absolute Vote\" (where 51% of the voting power should approve it in order for the decision to pass), or more sophisticated protocols like the Holographic Consensus voting protocol. Voting Rights Management - A voting rights management system determines how voting rights are distributed. Any voting rights management system must have \"balances\" which represents the voting power each participant holds. There are 2 main approaches for managing voting rights: token-based voting and reputation-based voting. The main technical difference between the two is that tokens are transferable (i.e. tradable) while reputation is non-transferable. Another big difference which may appear (depending on implementation) is that a token is a property which cannot be taken while reputation may be redistributed by the organization itself. For most cases, we reccomend using the reputation-based voting model, however, Infra allows any voting right management system to be built. Should I work at this level? Build on Infra if you need new or modified decentralized governance primitives, such as voting machines and voting rights management systems.","title":"Infra"},{"location":"stack/infra/infraIntro/#should-i-work-at-this-level","text":"Build on Infra if you need new or modified decentralized governance primitives, such as voting machines and voting rights management systems.","title":"Should I work at this level?"},{"location":"stack/subgraph/entities/","text":"There are two types of Entities tracked by DAOstack subgraph Base Entity : Entity composed be indexing individual events emitted by multiple DAOstack core contracts Domain Entity : High level complex Entity that infer information and consolidates Base Entities . Domain Entity Following is the list of all top level Domain Entities DAO - id: ID! - name: String! - nativeToken: Token! - nativeReputation: Rep! - proposals: [Proposal!] - reputationHolders: [ReputationHolder!] - reputationHoldersCount: BigInt! - rewards: [GPReward!] - register: String! - schemes: [ControllerScheme!] - gpQueues: [GPQueue!] - numberOfQueuedProposals: BigInt! - numberOfPreBoostedProposals: BigInt! - numberOfBoostedProposals: BigInt! - numberOfExpiredInQueueProposals: BigInt! GPQueue - id: ID! - threshold: BigInt! - scheme: ControllerScheme - dao: DAO! - votingMachine: Bytes! Rep - id: ID! - dao: DAO - totalSupply: BigInt! Token - id: ID! - dao: DAO - name: String! - symbol: String! - totalSupply: BigInt! Proposal - id: ID! - dao: DAO! - proposer: Bytes! - stage: String! - createdAt: BigInt! - preBoostedAt: BigInt - boostedAt: BigInt - quietEndingPeriodBeganAt: BigInt - closingAt: BigInt - executedAt: BigInt - totalRepWhenExecuted: BigInt - totalRepWhenCreated: BigInt - votingMachine: Bytes! - executionState: String! - paramsHash: Bytes! - organizationId: Bytes! - confidenceThreshold: BigInt! - descriptionHash: String! - title: String - description: String - url: String - fulltext: [String!] - gpRewards: [GPReward!] @derivedFrom(field: \"proposal\") - accountsWithUnclaimedRewards: [Bytes!] - expiresInQueueAt: BigInt! - votes: [ProposalVote!] @derivedFrom(field: \"proposal\") - votesFor: BigInt! - votesAgainst: BigInt! - winningOutcome: Outcome! - stakes: [ProposalStake!] @derivedFrom(field: \"proposal\") - stakesFor: BigInt! - stakesAgainst: BigInt! - confidence: BigDecimal! - gpQueue: GPQueue! - scheme: ControllerScheme - contributionReward: ContributionRewardProposal - genericScheme : GenericSchemeProposal - schemeRegistrar : SchemeRegistrarProposal - genesisProtocolParams : GenesisProtocolParam! Tag ProposalStake - id: ID! - createdAt: BigInt! - staker: Bytes! - proposal: Proposal! - dao: DAO! - outcome: Outcome! - amount: BigInt! ProposalVote - id: ID! - createdAt: BigInt! - voter: Bytes! - proposal: Proposal! - dao: DAO! - outcome: Outcome! - reputation: BigInt! GPRewardsHelper - id: ID! - gpRewards: [PreGPReward!] PreGPReward - id: ID! - beneficiary: Bytes! GPReward - id: ID! - createdAt: BigInt! - dao: DAO! - beneficiary: Bytes! - proposal: Proposal! - reputationForVoter: BigInt - tokensForStaker: BigInt - daoBountyForStaker: BigInt - reputationForProposer: BigInt - tokenAddress: Bytes - # timestamps of the redeem events - reputationForVoterRedeemedAt: BigInt! - tokensForStakerRedeemedAt: BigInt! - reputationForProposerRedeemedAt: BigInt! - daoBountyForStakerRedeemedAt: BigInt! FirstRegisterSchemeFlag - id: ID! ContractInfo - id: ID! - name: String! - alias: String! - version: String! - address: Bytes! Base Entity Following is the list of base entities Avatar AvatarContract - id: ID! - address: Bytes! - name: String! - nativeToken: Bytes! - nativeReputation: Bytes! - balance: BigInt! - owner: Bytes! ContributionReward ContributionRewardRedeemReputation - id: ID! - txHash: Bytes! - contract: Bytes! - avatar: Bytes! - beneficiary: Bytes! - proposalId: Bytes! - amount: BigInt! ContributionRewardRedeemNativeToken - id: ID! - txHash: Bytes! - contract: Bytes! - avatar: Bytes! - beneficiary: Bytes! - proposalId: Bytes! - amount: BigInt! ContributionRewardRedeemExternalToken - id: ID! - txHash: Bytes! - contract: Bytes! - avatar: Bytes! - beneficiary: Bytes! - proposalId: Bytes! - amount: BigInt! ContributionRewardRedeemEther - id: ID! - txHash: Bytes! - contract: Bytes! - avatar: Bytes! - beneficiary: Bytes! - proposalId: Bytes! - amount: BigInt! ContributionRewardProposalResolved - id: ID! - txHash: Bytes! - contract: Bytes! - avatar: Bytes! - proposalId: Bytes! - passed: Boolean ContributionRewardNewContributionProposal - id: ID! - txHash: Bytes! - contract: Bytes! - avatar: Bytes! - beneficiary: Bytes! - descriptionHash: String! - externalToken: Bytes! - votingMachine: Bytes! - proposalId: Bytes! - reputationReward: BigInt! - nativeTokenReward: BigInt! - ethReward: BigInt! - externalTokenReward: BigInt! - periods: BigInt! - periodLength: BigInt! ContributionRewardProposal - id: ID! - proposalId: Bytes! - contract: Bytes! - avatar: Bytes! - beneficiary: Bytes! - descriptionHash: String! - externalToken: Bytes! - votingMachine: Bytes! - reputationReward: BigInt! - nativeTokenReward: BigInt! - ethReward: BigInt! - externalTokenReward: BigInt! - periods: BigInt! - periodLength: BigInt! - executedAt: BigInt - alreadyRedeemedReputationPeriods: BigInt - alreadyRedeemedNativeTokenPeriods: BigInt - alreadyRedeemedEthPeriods: BigInt - alreadyRedeemedExternalTokenPeriods: BigInt Controller ControllerOrganization - id: ID! - avatarAddress: Bytes! - nativeToken: TokenContract! - nativeReputation: ReputationContract! - controller: Bytes! ControllerScheme - id: ID! - dao: DAO! - paramsHash: Bytes! - canRegisterSchemes: Boolean - canManageGlobalConstraints: Boolean - canUpgradeController: Boolean - canDelegateCall: Boolean - gpQueue: GPQueue - address: Bytes! - name: String - version: String - alias: String - contributionRewardParams: ContributionRewardParam - schemeRegistrarParams: SchemeRegistrarParam - uGenericSchemeParams: UGenericSchemeParam - genericSchemeParams: GenericSchemeParam - numberOfQueuedProposals: BigInt! - numberOfPreBoostedProposals: BigInt! - numberOfBoostedProposals: BigInt! - numberOfExpiredInQueueProposals: BigInt! ControllerGlobalConstraint - id: ID! - address: Bytes! - paramsHash: Bytes! - type: String! ControllerRegisterScheme - id: ID! - txHash: Bytes! - controller: Bytes! - contract: Bytes! - scheme: Bytes! ControllerUnregisterScheme - id: ID! - txHash: Bytes! - controller: Bytes! - contract: Bytes! - scheme: Bytes! ControllerUpgradeController - id: ID! - txHash: Bytes! - controller: Bytes! - newController: Bytes! ControllerAddGlobalConstraint - id: ID! - txHash: Bytes! - controller: Bytes! - globalConstraint: Bytes! - paramsHash: Bytes! - type: String! ControllerRemoveGlobalConstraint - id: ID! - txHash: Bytes! - controller: Bytes! - globalConstraint: Bytes! - isPre: Boolean ContributionRewardParam - id: ID! - votingMachine : Bytes! - voteParams: GenesisProtocolParam! SchemeRegistrarParam - id: ID! - votingMachine : Bytes! - voteRegisterParams : GenesisProtocolParam! - voteRemoveParams : GenesisProtocolParam! UGenericSchemeParam - id: ID! - votingMachine : Bytes! - voteParams: GenesisProtocolParam! - contractToCall: Bytes! GenericSchemeParam - id: ID! - votingMachine : Bytes! - voteParams: GenesisProtocolParam! - contractToCall: Bytes! GenesisProtocolParam - id: ID! - queuedVoteRequiredPercentage: BigInt! - queuedVotePeriodLimit: BigInt! - boostedVotePeriodLimit: BigInt! - preBoostedVotePeriodLimit: BigInt! - thresholdConst: BigInt! - limitExponentValue: BigInt! - quietEndingPeriod: BigInt! - proposingRepReward: BigInt! - votersReputationLossRatio: BigInt! - minimumDaoBounty: BigInt! - daoBountyConst: BigInt! - activationTime: BigInt! - voteOnBehalf: Bytes! FirstRegisterScheme - id: ID! DAORegistry DAORegistryContract - id: ID! - address: Bytes! - owner: Bytes! DAOToken TokenContract - id: ID! - address: Bytes! - totalSupply: BigInt! - owner: Bytes! - tokenHolders: [String!] TokenHolder - id: ID! - contract: Bytes! - address: Bytes! - balance: BigInt! Allowance - id: ID! - token: Bytes! - owner: Bytes! - spender: Bytes! - amount: BigInt! TokenTransfer - id: ID! - txHash: Bytes! - contract: Bytes! - from: Bytes! - to: Bytes! - value: BigInt! TokenApproval - id: ID! - txHash: Bytes! - contract: Bytes! - owner: Bytes! - spender: Bytes! - value: BigInt! GenesisProtocol GenesisProtocolProposal - id: ID! - proposalId: Bytes! - submittedTime: BigInt! - proposer: Bytes! - daoAvatarAddress: Bytes! - numOfChoices: BigInt - executionState: Int - state: Int - decision: BigInt - executionTime: BigInt - totalReputation: BigInt - paramsHash: Bytes! - address: Bytes! GenesisProtocolVote - id: ID! - avatarAddress: Bytes! - voterAddress: Bytes! - reputation: BigInt! - voteOption: BigInt! - proposalId: GenesisProtocolProposal! GenesisProtocolStake - id: ID! - avatarAddress: Bytes! - stakerAddress: Bytes! - prediction: BigInt! - stakeAmount: BigInt! - proposalId: GenesisProtocolProposal! GenesisProtocolRedemption - id: ID! - rewardId: GenesisProtocolReward! - proposalId: ID! - redeemer: Bytes! GenesisProtocolReward - id: ID! - type: GenesisProtocolRewardType - amount: BigInt! GenesisProtocolExecuteProposal - id: ID! - txHash: Bytes! - contract: Bytes! - proposalId: Bytes! - organization: Bytes! - decision: BigInt! - totalReputation: BigInt! GenesisProtocolGPExecuteProposal - id: ID! - txHash: Bytes! - contract: Bytes! - proposalId: Bytes! - executionState: Int Reputation ReputationContract - id: ID! - address: Bytes! - totalSupply: BigInt! - reputationHolders: [String!] ReputationHolder - id: ID! - contract: Bytes! - address: Bytes! - balance: BigInt! - dao: DAO - createdAt: BigInt! ReputationMint - id: ID! - txHash: Bytes! - contract: Bytes! - address: Bytes! - amount: BigInt! ReputationBurn - id: ID! - txHash: Bytes! - contract: Bytes! - address: Bytes! - amount: BigInt! SchemeRegistrar SchemeRegistrarNewSchemeProposal - id: ID! - txHash: Bytes! - contract: Bytes! - avatar: Bytes! - proposalId: Bytes! - votingMachine: Bytes! - scheme: Bytes! - paramsHash: Bytes! - permission: Bytes! - descriptionHash: String! SchemeRegistrarRemoveSchemeProposal - id: ID! - txHash: Bytes! - contract: Bytes! - avatar: Bytes! - proposalId: Bytes! - votingMachine: Bytes! - scheme: Bytes! - descriptionHash: String! SchemeRegistrarProposalExecuted - id: ID! - txHash: Bytes! - contract: Bytes! - avatar: Bytes! - proposalId: Bytes! - decision : BigInt! SchemeRegistrarProposal - id: ID! - dao: DAO! - schemeToRegister: Bytes - schemeToRegisterParamsHash: Bytes - schemeToRegisterPermission: Bytes - schemeToRemove: Bytes - decision: BigInt - schemeRegistered: Boolean - schemeRemoved: Boolean UController UControllerOrganization - id: ID! - avatarAddress: Bytes! - nativeToken: TokenContract! - nativeReputation: ReputationContract! - controller: Bytes! UControllerGlobalConstraint - id: ID! - avatarAddress: Bytes! - address: Bytes! - paramsHash: Bytes! - type: String! UControllerRegisterScheme - id: ID! - txHash: Bytes! - controller: Bytes! - contract: Bytes! - avatarAddress: Bytes! - scheme: Bytes! UControllerUnregisterScheme - id: ID! - txHash: Bytes! - controller: Bytes! - contract: Bytes! - avatarAddress: Bytes! - scheme: Bytes! UControllerUpgradeController - id: ID! - txHash: Bytes! - controller: Bytes! - avatarAddress: Bytes! - newController: Bytes! UControllerAddGlobalConstraint - id: ID! - txHash: Bytes! - controller: Bytes! - avatarAddress: Bytes! - globalConstraint: Bytes! - paramsHash: Bytes! - type: String! UControllerRemoveGlobalConstraint - id: ID! - txHash: Bytes! - controller: Bytes! - avatarAddress: Bytes! - globalConstraint: Bytes! - isPre: Boolean UGenericScheme GenericSchemeProposal - id: ID! - dao: DAO! - contractToCall: Bytes! - callData: Bytes! - value: BigInt! - executed: Boolean! - returnValue: Bytes","title":"Entities"},{"location":"stack/subgraph/entities/#domain-entity","text":"Following is the list of all top level Domain Entities DAO - id: ID! - name: String! - nativeToken: Token! - nativeReputation: Rep! - proposals: [Proposal!] - reputationHolders: [ReputationHolder!] - reputationHoldersCount: BigInt! - rewards: [GPReward!] - register: String! - schemes: [ControllerScheme!] - gpQueues: [GPQueue!] - numberOfQueuedProposals: BigInt! - numberOfPreBoostedProposals: BigInt! - numberOfBoostedProposals: BigInt! - numberOfExpiredInQueueProposals: BigInt! GPQueue - id: ID! - threshold: BigInt! - scheme: ControllerScheme - dao: DAO! - votingMachine: Bytes! Rep - id: ID! - dao: DAO - totalSupply: BigInt! Token - id: ID! - dao: DAO - name: String! - symbol: String! - totalSupply: BigInt! Proposal - id: ID! - dao: DAO! - proposer: Bytes! - stage: String! - createdAt: BigInt! - preBoostedAt: BigInt - boostedAt: BigInt - quietEndingPeriodBeganAt: BigInt - closingAt: BigInt - executedAt: BigInt - totalRepWhenExecuted: BigInt - totalRepWhenCreated: BigInt - votingMachine: Bytes! - executionState: String! - paramsHash: Bytes! - organizationId: Bytes! - confidenceThreshold: BigInt! - descriptionHash: String! - title: String - description: String - url: String - fulltext: [String!] - gpRewards: [GPReward!] @derivedFrom(field: \"proposal\") - accountsWithUnclaimedRewards: [Bytes!] - expiresInQueueAt: BigInt! - votes: [ProposalVote!] @derivedFrom(field: \"proposal\") - votesFor: BigInt! - votesAgainst: BigInt! - winningOutcome: Outcome! - stakes: [ProposalStake!] @derivedFrom(field: \"proposal\") - stakesFor: BigInt! - stakesAgainst: BigInt! - confidence: BigDecimal! - gpQueue: GPQueue! - scheme: ControllerScheme - contributionReward: ContributionRewardProposal - genericScheme : GenericSchemeProposal - schemeRegistrar : SchemeRegistrarProposal - genesisProtocolParams : GenesisProtocolParam! Tag ProposalStake - id: ID! - createdAt: BigInt! - staker: Bytes! - proposal: Proposal! - dao: DAO! - outcome: Outcome! - amount: BigInt! ProposalVote - id: ID! - createdAt: BigInt! - voter: Bytes! - proposal: Proposal! - dao: DAO! - outcome: Outcome! - reputation: BigInt! GPRewardsHelper - id: ID! - gpRewards: [PreGPReward!] PreGPReward - id: ID! - beneficiary: Bytes! GPReward - id: ID! - createdAt: BigInt! - dao: DAO! - beneficiary: Bytes! - proposal: Proposal! - reputationForVoter: BigInt - tokensForStaker: BigInt - daoBountyForStaker: BigInt - reputationForProposer: BigInt - tokenAddress: Bytes - # timestamps of the redeem events - reputationForVoterRedeemedAt: BigInt! - tokensForStakerRedeemedAt: BigInt! - reputationForProposerRedeemedAt: BigInt! - daoBountyForStakerRedeemedAt: BigInt! FirstRegisterSchemeFlag - id: ID! ContractInfo - id: ID! - name: String! - alias: String! - version: String! - address: Bytes!","title":"Domain Entity"},{"location":"stack/subgraph/entities/#base-entity","text":"Following is the list of base entities","title":"Base Entity"},{"location":"stack/subgraph/entities/#avatar","text":"AvatarContract - id: ID! - address: Bytes! - name: String! - nativeToken: Bytes! - nativeReputation: Bytes! - balance: BigInt! - owner: Bytes!","title":"Avatar"},{"location":"stack/subgraph/entities/#contributionreward","text":"ContributionRewardRedeemReputation - id: ID! - txHash: Bytes! - contract: Bytes! - avatar: Bytes! - beneficiary: Bytes! - proposalId: Bytes! - amount: BigInt! ContributionRewardRedeemNativeToken - id: ID! - txHash: Bytes! - contract: Bytes! - avatar: Bytes! - beneficiary: Bytes! - proposalId: Bytes! - amount: BigInt! ContributionRewardRedeemExternalToken - id: ID! - txHash: Bytes! - contract: Bytes! - avatar: Bytes! - beneficiary: Bytes! - proposalId: Bytes! - amount: BigInt! ContributionRewardRedeemEther - id: ID! - txHash: Bytes! - contract: Bytes! - avatar: Bytes! - beneficiary: Bytes! - proposalId: Bytes! - amount: BigInt! ContributionRewardProposalResolved - id: ID! - txHash: Bytes! - contract: Bytes! - avatar: Bytes! - proposalId: Bytes! - passed: Boolean ContributionRewardNewContributionProposal - id: ID! - txHash: Bytes! - contract: Bytes! - avatar: Bytes! - beneficiary: Bytes! - descriptionHash: String! - externalToken: Bytes! - votingMachine: Bytes! - proposalId: Bytes! - reputationReward: BigInt! - nativeTokenReward: BigInt! - ethReward: BigInt! - externalTokenReward: BigInt! - periods: BigInt! - periodLength: BigInt! ContributionRewardProposal - id: ID! - proposalId: Bytes! - contract: Bytes! - avatar: Bytes! - beneficiary: Bytes! - descriptionHash: String! - externalToken: Bytes! - votingMachine: Bytes! - reputationReward: BigInt! - nativeTokenReward: BigInt! - ethReward: BigInt! - externalTokenReward: BigInt! - periods: BigInt! - periodLength: BigInt! - executedAt: BigInt - alreadyRedeemedReputationPeriods: BigInt - alreadyRedeemedNativeTokenPeriods: BigInt - alreadyRedeemedEthPeriods: BigInt - alreadyRedeemedExternalTokenPeriods: BigInt","title":"ContributionReward"},{"location":"stack/subgraph/entities/#controller","text":"ControllerOrganization - id: ID! - avatarAddress: Bytes! - nativeToken: TokenContract! - nativeReputation: ReputationContract! - controller: Bytes! ControllerScheme - id: ID! - dao: DAO! - paramsHash: Bytes! - canRegisterSchemes: Boolean - canManageGlobalConstraints: Boolean - canUpgradeController: Boolean - canDelegateCall: Boolean - gpQueue: GPQueue - address: Bytes! - name: String - version: String - alias: String - contributionRewardParams: ContributionRewardParam - schemeRegistrarParams: SchemeRegistrarParam - uGenericSchemeParams: UGenericSchemeParam - genericSchemeParams: GenericSchemeParam - numberOfQueuedProposals: BigInt! - numberOfPreBoostedProposals: BigInt! - numberOfBoostedProposals: BigInt! - numberOfExpiredInQueueProposals: BigInt! ControllerGlobalConstraint - id: ID! - address: Bytes! - paramsHash: Bytes! - type: String! ControllerRegisterScheme - id: ID! - txHash: Bytes! - controller: Bytes! - contract: Bytes! - scheme: Bytes! ControllerUnregisterScheme - id: ID! - txHash: Bytes! - controller: Bytes! - contract: Bytes! - scheme: Bytes! ControllerUpgradeController - id: ID! - txHash: Bytes! - controller: Bytes! - newController: Bytes! ControllerAddGlobalConstraint - id: ID! - txHash: Bytes! - controller: Bytes! - globalConstraint: Bytes! - paramsHash: Bytes! - type: String! ControllerRemoveGlobalConstraint - id: ID! - txHash: Bytes! - controller: Bytes! - globalConstraint: Bytes! - isPre: Boolean ContributionRewardParam - id: ID! - votingMachine : Bytes! - voteParams: GenesisProtocolParam! SchemeRegistrarParam - id: ID! - votingMachine : Bytes! - voteRegisterParams : GenesisProtocolParam! - voteRemoveParams : GenesisProtocolParam! UGenericSchemeParam - id: ID! - votingMachine : Bytes! - voteParams: GenesisProtocolParam! - contractToCall: Bytes! GenericSchemeParam - id: ID! - votingMachine : Bytes! - voteParams: GenesisProtocolParam! - contractToCall: Bytes! GenesisProtocolParam - id: ID! - queuedVoteRequiredPercentage: BigInt! - queuedVotePeriodLimit: BigInt! - boostedVotePeriodLimit: BigInt! - preBoostedVotePeriodLimit: BigInt! - thresholdConst: BigInt! - limitExponentValue: BigInt! - quietEndingPeriod: BigInt! - proposingRepReward: BigInt! - votersReputationLossRatio: BigInt! - minimumDaoBounty: BigInt! - daoBountyConst: BigInt! - activationTime: BigInt! - voteOnBehalf: Bytes! FirstRegisterScheme - id: ID!","title":"Controller"},{"location":"stack/subgraph/entities/#daoregistry","text":"DAORegistryContract - id: ID! - address: Bytes! - owner: Bytes!","title":"DAORegistry"},{"location":"stack/subgraph/entities/#daotoken","text":"TokenContract - id: ID! - address: Bytes! - totalSupply: BigInt! - owner: Bytes! - tokenHolders: [String!] TokenHolder - id: ID! - contract: Bytes! - address: Bytes! - balance: BigInt! Allowance - id: ID! - token: Bytes! - owner: Bytes! - spender: Bytes! - amount: BigInt! TokenTransfer - id: ID! - txHash: Bytes! - contract: Bytes! - from: Bytes! - to: Bytes! - value: BigInt! TokenApproval - id: ID! - txHash: Bytes! - contract: Bytes! - owner: Bytes! - spender: Bytes! - value: BigInt!","title":"DAOToken"},{"location":"stack/subgraph/entities/#genesisprotocol","text":"GenesisProtocolProposal - id: ID! - proposalId: Bytes! - submittedTime: BigInt! - proposer: Bytes! - daoAvatarAddress: Bytes! - numOfChoices: BigInt - executionState: Int - state: Int - decision: BigInt - executionTime: BigInt - totalReputation: BigInt - paramsHash: Bytes! - address: Bytes! GenesisProtocolVote - id: ID! - avatarAddress: Bytes! - voterAddress: Bytes! - reputation: BigInt! - voteOption: BigInt! - proposalId: GenesisProtocolProposal! GenesisProtocolStake - id: ID! - avatarAddress: Bytes! - stakerAddress: Bytes! - prediction: BigInt! - stakeAmount: BigInt! - proposalId: GenesisProtocolProposal! GenesisProtocolRedemption - id: ID! - rewardId: GenesisProtocolReward! - proposalId: ID! - redeemer: Bytes! GenesisProtocolReward - id: ID! - type: GenesisProtocolRewardType - amount: BigInt! GenesisProtocolExecuteProposal - id: ID! - txHash: Bytes! - contract: Bytes! - proposalId: Bytes! - organization: Bytes! - decision: BigInt! - totalReputation: BigInt! GenesisProtocolGPExecuteProposal - id: ID! - txHash: Bytes! - contract: Bytes! - proposalId: Bytes! - executionState: Int","title":"GenesisProtocol"},{"location":"stack/subgraph/entities/#reputation","text":"ReputationContract - id: ID! - address: Bytes! - totalSupply: BigInt! - reputationHolders: [String!] ReputationHolder - id: ID! - contract: Bytes! - address: Bytes! - balance: BigInt! - dao: DAO - createdAt: BigInt! ReputationMint - id: ID! - txHash: Bytes! - contract: Bytes! - address: Bytes! - amount: BigInt! ReputationBurn - id: ID! - txHash: Bytes! - contract: Bytes! - address: Bytes! - amount: BigInt!","title":"Reputation"},{"location":"stack/subgraph/entities/#schemeregistrar","text":"SchemeRegistrarNewSchemeProposal - id: ID! - txHash: Bytes! - contract: Bytes! - avatar: Bytes! - proposalId: Bytes! - votingMachine: Bytes! - scheme: Bytes! - paramsHash: Bytes! - permission: Bytes! - descriptionHash: String! SchemeRegistrarRemoveSchemeProposal - id: ID! - txHash: Bytes! - contract: Bytes! - avatar: Bytes! - proposalId: Bytes! - votingMachine: Bytes! - scheme: Bytes! - descriptionHash: String! SchemeRegistrarProposalExecuted - id: ID! - txHash: Bytes! - contract: Bytes! - avatar: Bytes! - proposalId: Bytes! - decision : BigInt! SchemeRegistrarProposal - id: ID! - dao: DAO! - schemeToRegister: Bytes - schemeToRegisterParamsHash: Bytes - schemeToRegisterPermission: Bytes - schemeToRemove: Bytes - decision: BigInt - schemeRegistered: Boolean - schemeRemoved: Boolean","title":"SchemeRegistrar"},{"location":"stack/subgraph/entities/#ucontroller","text":"UControllerOrganization - id: ID! - avatarAddress: Bytes! - nativeToken: TokenContract! - nativeReputation: ReputationContract! - controller: Bytes! UControllerGlobalConstraint - id: ID! - avatarAddress: Bytes! - address: Bytes! - paramsHash: Bytes! - type: String! UControllerRegisterScheme - id: ID! - txHash: Bytes! - controller: Bytes! - contract: Bytes! - avatarAddress: Bytes! - scheme: Bytes! UControllerUnregisterScheme - id: ID! - txHash: Bytes! - controller: Bytes! - contract: Bytes! - avatarAddress: Bytes! - scheme: Bytes! UControllerUpgradeController - id: ID! - txHash: Bytes! - controller: Bytes! - avatarAddress: Bytes! - newController: Bytes! UControllerAddGlobalConstraint - id: ID! - txHash: Bytes! - controller: Bytes! - avatarAddress: Bytes! - globalConstraint: Bytes! - paramsHash: Bytes! - type: String! UControllerRemoveGlobalConstraint - id: ID! - txHash: Bytes! - controller: Bytes! - avatarAddress: Bytes! - globalConstraint: Bytes! - isPre: Boolean","title":"UController"},{"location":"stack/subgraph/entities/#ugenericscheme","text":"GenericSchemeProposal - id: ID! - dao: DAO! - contractToCall: Bytes! - callData: Bytes! - value: BigInt! - executed: Boolean! - returnValue: Bytes","title":"UGenericScheme"},{"location":"stack/subgraph/queries/","text":"You can use GraphQL queries to get quick info from DAOstack Subgraph hosted on GraphExplorer. This guide explains how to use GraphQL queries to get single or multiple Entities and sort, filter and paginate them. The full list of Subgraph Entities cached by DAOstack subgraph can be found here General Guidelines All queries must be wrapped inside query {} object. While querying, the Entity name is same as provided in Entity list but starts with lowerCase . You can query for single entity by providing Entity id . You can query for multiple Entities by changing entity to plural. i.e. proposal - proposals The complex-field i.e. fields that are themselves an Entity such as dao and proposals in below example , need to be proceeded with {} and provided with the subfield needed to be queried While you can Filter/Sort/Paginate complex subfield (Entity) array, the Top level Entity itself cannot be Filtered/Sorted/Paginated by complex fields. If no pagination limit is provided, by default a limit of 100 entities is used. Maximum pagination limit is 1000 Query for single Entity When you query for single Entity with all/some fields, you need to provide the Entity id. Examples Details of Genesis DAO 0x294f999356ed03347c7a23bcbcf8d33fa41dc830 1 2 3 4 5 6 7 8 9 10 11 12 query { dao ( id : 0x294f999356ed03347c7a23bcbcf8d33fa41dc830 ) { name numberOfQueuedProposals numberOfBoostedProposals numberOfPreBoostedProposals proposals { title } reputationHoldersCount } } Details of Proposal `0x0025c38d987acba1f1d446d3690384327ebe06d15f1fa4171a4dc3467f8bd416` 1 2 3 4 5 6 7 8 9 10 11 12 13 14 query { proposal ( id : 0x0025c38d987acba1f1d446d3690384327ebe06d15f1fa4171a4dc3467f8bd416 ) { proposer createdAt expiresInQueueAt title votesFor votesAgainst dao { id name } } } Query for Multiple Entities Query all Just change the entity name to plural to query for all the entities of that type Examples Details of all daos indexed by the DAOstack subgraph 1 2 3 4 5 6 7 8 9 10 11 query { daos { name id reputationHoldersCount proposals { id title } } } Details of all `Reputation Holders` in DAOstack DAOs 1 2 3 4 5 6 7 8 9 10 query { reputationHolders { id address balance dao { name } } } Filter by fields To query for a subset of Entities you can add where: {} parameter to filter for different properties. You can filter for single or multiple properties. Filter top level entity Examples To get all proposals submitted on 2019 Halloween, we can filter for the time interval on `createdAt` property 1 2 3 4 5 6 7 8 9 10 11 12 13 14 query { proposals ( where : { createdAt_gt : 1572480000 , createdAt_lt : 1572566400 } ) { id title dao { name } } } Get all `daos` with more than 200 reputation holders 1 2 3 4 5 6 7 8 9 query { daos ( where : { reputationHoldersCount_gt : 200 } ) { name reputationHoldersCount } } Genesis DAO proposals that contains word 'Reputation' in title 1 2 3 4 5 6 7 8 9 10 11 12 13 query { proposals ( where : { dao : 0x294f999356ed03347c7a23bcbcf8d33fa41dc830 title_contains : Reputation } ) { title dao { name } } } Filter complex subfield array Examples Get rewards detail for all DAO where 250 GEN or more were awarded in DAO bounty 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 query { daos { name rewards ( where : { daoBountyForStaker_gte : 250000000000000000000 } ) { proposal { id } daoBountyForStaker } } } NOTE: The suffix _contains in the above example is used for the comparison Some suffixes are only supported for specific types. For example, Boolean only supports _not , _in , and _not_in . Complete list of suffix is _not _gt _lt _gte _lte _in _not_in _contains _not_contains _starts_with _ends_with _not_starts_with _not_ends_with Sort by field values Sort top level entity Examples To query for a sorted list you can add orderBy parameter to sort by a specific property. Also, you can specify the direction of sort asc for ascending and desc for descending. Sort Reputation Holders by their reputation balance 1 2 3 4 5 6 7 8 9 query { reputationHolders ( orderBy : balance , orderDirection : desc ) { address balance } } Sort DAOs by number of boosted proposals it has 1 2 3 4 5 6 7 8 9 query { daos ( orderBy : numberOfBoostedProposals , orderDirection : asc ) { name numberOfBoostedProposals } } Sort complex subfield array Examples Get all proposals from all the daos ordered by the date of submission 1 2 3 4 5 6 7 8 9 10 query { daos { proposals ( orderBy : createdAt , orderDirection : desc ) { title } } } Paginate You can also decrease the size of set queried by specifying the pagination limit Examples From the beginning Get first 3 DAOs based on highest number of reputation holders 1 2 3 4 5 6 7 8 9 10 query { daos ( first : 3 orderBy : reputationHoldersCount orderDirection : desc ) { name numberOfBoostedProposals } } From the middle Get all DAOs except the first 5 1 2 3 4 5 6 7 8 9 10 query { daos ( skip : 5 orderBy : reputationHoldersCount orderDirection : desc ) { name numberOfBoostedProposals } } Get the next 3 DAOs after the top 3 1 2 3 4 5 6 7 8 9 10 11 12 13 query { daos ( skip : 3 first : 3 orderBy : reputationHoldersCount orderDirection : desc ) { You name reputationHoldersCount } } NOTE: There is a limit of 1000 entities per query. Combine them all ... You can combine the above parameters to create a more complex query Examples Get top 6 boosted proposals that belong to either Genesis Alpha or DutchX 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 query { proposals ( where : { dao_in : [ 0x294f999356ed03347c7a23bcbcf8d33fa41dc830 , 0x519b70055af55a007110b4ff99b0ea33071c720a ] stage : Boosted } orderBy : createdAt orderDirection : asc first : 6 ) { title dao { name } } } Get top 3 reputation holders from all DAOstack 1 2 3 4 5 6 7 8 9 10 11 12 13 14 query { daos { name reputationHolders ( orderBy : balance orderDirection : desc first : 3 ) { address balance } } }","title":"GraphQL queries"},{"location":"stack/subgraph/queries/#general-guidelines","text":"All queries must be wrapped inside query {} object. While querying, the Entity name is same as provided in Entity list but starts with lowerCase . You can query for single entity by providing Entity id . You can query for multiple Entities by changing entity to plural. i.e. proposal - proposals The complex-field i.e. fields that are themselves an Entity such as dao and proposals in below example , need to be proceeded with {} and provided with the subfield needed to be queried While you can Filter/Sort/Paginate complex subfield (Entity) array, the Top level Entity itself cannot be Filtered/Sorted/Paginated by complex fields. If no pagination limit is provided, by default a limit of 100 entities is used. Maximum pagination limit is 1000","title":"General Guidelines"},{"location":"stack/subgraph/queries/#query-for-single-entity","text":"When you query for single Entity with all/some fields, you need to provide the Entity id. Examples Details of Genesis DAO 0x294f999356ed03347c7a23bcbcf8d33fa41dc830 1 2 3 4 5 6 7 8 9 10 11 12 query { dao ( id : 0x294f999356ed03347c7a23bcbcf8d33fa41dc830 ) { name numberOfQueuedProposals numberOfBoostedProposals numberOfPreBoostedProposals proposals { title } reputationHoldersCount } } Details of Proposal `0x0025c38d987acba1f1d446d3690384327ebe06d15f1fa4171a4dc3467f8bd416` 1 2 3 4 5 6 7 8 9 10 11 12 13 14 query { proposal ( id : 0x0025c38d987acba1f1d446d3690384327ebe06d15f1fa4171a4dc3467f8bd416 ) { proposer createdAt expiresInQueueAt title votesFor votesAgainst dao { id name } } }","title":"Query for single Entity"},{"location":"stack/subgraph/queries/#query-for-multiple-entities","text":"","title":"Query for Multiple Entities"},{"location":"stack/subgraph/queries/#query-all","text":"Just change the entity name to plural to query for all the entities of that type Examples Details of all daos indexed by the DAOstack subgraph 1 2 3 4 5 6 7 8 9 10 11 query { daos { name id reputationHoldersCount proposals { id title } } } Details of all `Reputation Holders` in DAOstack DAOs 1 2 3 4 5 6 7 8 9 10 query { reputationHolders { id address balance dao { name } } }","title":"Query all"},{"location":"stack/subgraph/queries/#filter-by-fields","text":"To query for a subset of Entities you can add where: {} parameter to filter for different properties. You can filter for single or multiple properties.","title":"Filter by fields"},{"location":"stack/subgraph/queries/#filter-top-level-entity","text":"Examples To get all proposals submitted on 2019 Halloween, we can filter for the time interval on `createdAt` property 1 2 3 4 5 6 7 8 9 10 11 12 13 14 query { proposals ( where : { createdAt_gt : 1572480000 , createdAt_lt : 1572566400 } ) { id title dao { name } } } Get all `daos` with more than 200 reputation holders 1 2 3 4 5 6 7 8 9 query { daos ( where : { reputationHoldersCount_gt : 200 } ) { name reputationHoldersCount } } Genesis DAO proposals that contains word 'Reputation' in title 1 2 3 4 5 6 7 8 9 10 11 12 13 query { proposals ( where : { dao : 0x294f999356ed03347c7a23bcbcf8d33fa41dc830 title_contains : Reputation } ) { title dao { name } } }","title":"Filter top level entity"},{"location":"stack/subgraph/queries/#filter-complex-subfield-array","text":"Examples Get rewards detail for all DAO where 250 GEN or more were awarded in DAO bounty 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 query { daos { name rewards ( where : { daoBountyForStaker_gte : 250000000000000000000 } ) { proposal { id } daoBountyForStaker } } } NOTE: The suffix _contains in the above example is used for the comparison Some suffixes are only supported for specific types. For example, Boolean only supports _not , _in , and _not_in . Complete list of suffix is _not _gt _lt _gte _lte _in _not_in _contains _not_contains _starts_with _ends_with _not_starts_with _not_ends_with","title":"Filter complex subfield array"},{"location":"stack/subgraph/queries/#sort-by-field-values","text":"","title":"Sort by field values"},{"location":"stack/subgraph/queries/#sort-top-level-entity","text":"Examples To query for a sorted list you can add orderBy parameter to sort by a specific property. Also, you can specify the direction of sort asc for ascending and desc for descending. Sort Reputation Holders by their reputation balance 1 2 3 4 5 6 7 8 9 query { reputationHolders ( orderBy : balance , orderDirection : desc ) { address balance } } Sort DAOs by number of boosted proposals it has 1 2 3 4 5 6 7 8 9 query { daos ( orderBy : numberOfBoostedProposals , orderDirection : asc ) { name numberOfBoostedProposals } }","title":"Sort top level entity"},{"location":"stack/subgraph/queries/#sort-complex-subfield-array","text":"Examples Get all proposals from all the daos ordered by the date of submission 1 2 3 4 5 6 7 8 9 10 query { daos { proposals ( orderBy : createdAt , orderDirection : desc ) { title } } }","title":"Sort complex subfield array"},{"location":"stack/subgraph/queries/#paginate","text":"You can also decrease the size of set queried by specifying the pagination limit Examples","title":"Paginate"},{"location":"stack/subgraph/queries/#from-the-beginning","text":"Get first 3 DAOs based on highest number of reputation holders 1 2 3 4 5 6 7 8 9 10 query { daos ( first : 3 orderBy : reputationHoldersCount orderDirection : desc ) { name numberOfBoostedProposals } }","title":"From the beginning"},{"location":"stack/subgraph/queries/#from-the-middle","text":"Get all DAOs except the first 5 1 2 3 4 5 6 7 8 9 10 query { daos ( skip : 5 orderBy : reputationHoldersCount orderDirection : desc ) { name numberOfBoostedProposals } } Get the next 3 DAOs after the top 3 1 2 3 4 5 6 7 8 9 10 11 12 13 query { daos ( skip : 3 first : 3 orderBy : reputationHoldersCount orderDirection : desc ) { You name reputationHoldersCount } } NOTE: There is a limit of 1000 entities per query.","title":"From the middle"},{"location":"stack/subgraph/queries/#combine-them-all","text":"You can combine the above parameters to create a more complex query Examples Get top 6 boosted proposals that belong to either Genesis Alpha or DutchX 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 query { proposals ( where : { dao_in : [ 0x294f999356ed03347c7a23bcbcf8d33fa41dc830 , 0x519b70055af55a007110b4ff99b0ea33071c720a ] stage : Boosted } orderBy : createdAt orderDirection : asc first : 6 ) { title dao { name } } } Get top 3 reputation holders from all DAOstack 1 2 3 4 5 6 7 8 9 10 11 12 13 14 query { daos { name reputationHolders ( orderBy : balance orderDirection : desc first : 3 ) { address balance } } }","title":"Combine them all ..."},{"location":"stack/subgraph/subgraphIntro/","text":"Subgraph indexes the blockchain data and stores it in postgres database for easy and quick access. The subgraph runs on a Graph Node which is a server that developers can run local or remote. The data store can be queried by GraphQL endpoints. DAOstack subgraph is based on graphprotocol, checkout TheGraph for more details. TheGraph opens their server to others and you can find daostack subgraph at Graph Explorer. Should I work at this level? If you are writing new Arc contracts which are not indexed by DAOstack subgraph or want to fetch data of existing Arc contracts in a way other than that specified in DAOstack subgraph's schema.graphql , then you should write your own subgraph schema and mappings","title":"Intro"},{"location":"stack/subgraph/subgraphIntro/#should-i-work-at-this-level","text":"If you are writing new Arc contracts which are not indexed by DAOstack subgraph or want to fetch data of existing Arc contracts in a way other than that specified in DAOstack subgraph's schema.graphql , then you should write your own subgraph schema and mappings","title":"Should I work at this level?"}]}