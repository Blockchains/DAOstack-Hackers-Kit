{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"How to DAO with DAOstack Introduction DAOstack provides everything you need to start managing your community without a centralized authority. Launch your DAO - Decentralized Autonomous Organization using Adaptive, Modular and Upgradable governance structures powered by, DAOstack , a software stack for building Dapps (decentralized apps), DAOs (Decentralized Autonomous Organizations), and DAO tools. The Stack A DApp build with DAOstack DAOs consists of public blockchain layer ( Infra, Arc, Arc-Hive) which is the source of data caching layers (Subgraph) which allows fast access to the blockchain layer javascript library (Client) for application layer integration.","title":"Home"},{"location":"#how-to-dao-with-daostack","text":"","title":"How to DAO with DAOstack"},{"location":"#introduction","text":"DAOstack provides everything you need to start managing your community without a centralized authority. Launch your DAO - Decentralized Autonomous Organization using Adaptive, Modular and Upgradable governance structures powered by, DAOstack , a software stack for building Dapps (decentralized apps), DAOs (Decentralized Autonomous Organizations), and DAO tools.","title":"Introduction"},{"location":"#the-stack","text":"A DApp build with DAOstack DAOs consists of public blockchain layer ( Infra, Arc, Arc-Hive) which is the source of data caching layers (Subgraph) which allows fast access to the blockchain layer javascript library (Client) for application layer integration.","title":"The Stack"},{"location":"hackerkit/","text":"Table of contents DAOs Examples Contact and Help DAOs DAOs can be created for any conceivable collaborative purpose, from local political action to distributed manufacturing and sales. The goal of DAOstack is to make it as easy as possible to create and manage DAOs, and to use them to drive a new decentralized global economy (specifically, an economy that uses GEN, our collective attention token ). DAOstack Technologies has created an initial DAO called \"Genesis\" with the purpose of promoting the GEN/DAO ecosystem. Genesis is currently live on the Ethereum mainnet, has over 200 Reputation-holders who have executed over 170 proposals since August 2018, and can be accessed through \"Alchemy\" . Examples The hackers kit is equipped with several examples and sample projects, which we are working to maintain and expand. The goal for these examples is to help developers easily kickstart a new project, as well as to demonstrate some of the features included in each layer of the DAO stack. Starter Template This is a basic template you can use for kickstarting your project using the DAOstack platform. Here you can find the basic structure for using Arc, Client and Subgraph to build your project. Peep DAO This project is a Dapp for interacting with a DAO which has its own DAO social media account on Peepeth , a decentralized microblogging app. The Dapp allows a DAO post Peeps via a decentralized voting mechanism. DutchX DAO Bootstrap This project contains a minimal UI for participating in the bootstrap of the DutchX DAO. The bootstrapping process for a DAO is the process of distributing its initial reputation and tokens. The DutchX bootstrap process is a 3 months period during which users can do several actions, like locking tokens, in order to receive Reputation in the DutchX DAO. You can view the DutchX DAO bootstrapping contracts here . Firestarter DAO Example Firestarter is a community driven crowdsourcing platform, which utilizes DaoStack for governance of the projects. This is a striped down version of the project, which only showcases the DaoStack integration. Contact and Help DAOstack team members and open-source community members always make an effort to assist new projects. For any technical questions, please reach out to us via Discord at this link . If you have any questions or comments about this repository, please open an issue, and we'll do our best to help.","title":"Hacker-kit"},{"location":"hackerkit/#table-of-contents","text":"DAOs Examples Contact and Help","title":"Table of contents"},{"location":"hackerkit/#daos","text":"DAOs can be created for any conceivable collaborative purpose, from local political action to distributed manufacturing and sales. The goal of DAOstack is to make it as easy as possible to create and manage DAOs, and to use them to drive a new decentralized global economy (specifically, an economy that uses GEN, our collective attention token ). DAOstack Technologies has created an initial DAO called \"Genesis\" with the purpose of promoting the GEN/DAO ecosystem. Genesis is currently live on the Ethereum mainnet, has over 200 Reputation-holders who have executed over 170 proposals since August 2018, and can be accessed through \"Alchemy\" .","title":"DAOs"},{"location":"hackerkit/#examples","text":"The hackers kit is equipped with several examples and sample projects, which we are working to maintain and expand. The goal for these examples is to help developers easily kickstart a new project, as well as to demonstrate some of the features included in each layer of the DAO stack.","title":"Examples"},{"location":"hackerkit/#starter-template","text":"This is a basic template you can use for kickstarting your project using the DAOstack platform. Here you can find the basic structure for using Arc, Client and Subgraph to build your project.","title":"Starter Template"},{"location":"hackerkit/#peep-dao","text":"This project is a Dapp for interacting with a DAO which has its own DAO social media account on Peepeth , a decentralized microblogging app. The Dapp allows a DAO post Peeps via a decentralized voting mechanism.","title":"Peep DAO"},{"location":"hackerkit/#dutchx-dao-bootstrap","text":"This project contains a minimal UI for participating in the bootstrap of the DutchX DAO. The bootstrapping process for a DAO is the process of distributing its initial reputation and tokens. The DutchX bootstrap process is a 3 months period during which users can do several actions, like locking tokens, in order to receive Reputation in the DutchX DAO. You can view the DutchX DAO bootstrapping contracts here .","title":"DutchX DAO Bootstrap"},{"location":"hackerkit/#firestarter-dao-example","text":"Firestarter is a community driven crowdsourcing platform, which utilizes DaoStack for governance of the projects. This is a striped down version of the project, which only showcases the DaoStack integration.","title":"Firestarter DAO Example"},{"location":"hackerkit/#contact-and-help","text":"DAOstack team members and open-source community members always make an effort to assist new projects. For any technical questions, please reach out to us via Discord at this link . If you have any questions or comments about this repository, please open an issue, and we'll do our best to help.","title":"Contact and Help"},{"location":"migration/","text":"Migration package is useful for handling the migrations of DAOstack contracts and DAOs. You can use this tool to migrate DAOstack base contracts and DAOstack DAOs in production, test or developer mode","title":"Migration"},{"location":"notes/","text":"Alchmey updates","title":"Notes"},{"location":"gettingStarted/createNewInterface/","text":"Coming Soon","title":"Create your own interface for DAOstack DAOs"},{"location":"gettingStarted/deployDAO/","text":"How to launch a new DAO? The core contracts required by a daostack DAO are already deployed by the DAOstack team on mainnet as well as testnet and the addresses are available in Migration.json . Though you need to deploy an Avatar, custom schemes (optional), native reputation and native token contract. Checkout Structure of DAO for details on Avatar, scheme, rep and token DAO can be deployed using Migration package either from CLI or using javascript. Example deployment setup and scripts are available in Starter-template Choose a name for your DAO and the native token and its symbol Do you want to use DAOcreator contract? Deploying a DAO with DAOcreator contract saves number of transactions to be signed by bundling up founder rep and token distribution (upto 100 members) in single tx and initial scheme registration in single tx Which schemes to include in the DAO? Schemes are the actions a DAOstack DAO can take when a proposal passes/fails. Currently supported schemes in Migrations package are: ContributionReward: Enables fund management proposals that distribute funds to beneficiary once the proposal passes GenericScheme: Enables Avatar to make arbitrary function calls to a specific contract. For eg use Avatar to submit a proposal to Genesis Alpha on behalf of your DAO SchemeRegistrar: Lets you submit a proposal to register more schemes (apart from initial schemes set at time of deployment) to the DAO GlobalConstraintRegistrar: Lets you submit a proposal to register more GlobalConstraints UpgradeScheme: Lets you upgrade the controller. Since Controller is not a Scheme it cannot be changed via SchemeRegistrar Find detailed documentation re Schemes in Arc Repo Ucontroller vs Controller? Refer to documentation on Controllers Decide on which Voting Machine to use and the parameters Set the voting machine parameters according to the needs of the organization. Currently you can deploy a DAO using migrations with only GenesisProtocol voting machine, which allows decision at timeout according to higher relative vote. You can find details about different voting machines supported by arc at https://github.com/daostack/arc/tree/master/docs/contracts/VotingMachines Who gets the initial rep and token in DAO? Edit the list of founder members\u2019 address along with the rep and/or token to be distributed initially. You may choose to give equal rep to all or have differentiated rep. Once you have decided on dao-params follow the instruction in Migrations or one of the examples to deploy your dao","title":"Deploy a DAO"},{"location":"gettingStarted/deployDAO/#how-to-launch-a-new-dao","text":"The core contracts required by a daostack DAO are already deployed by the DAOstack team on mainnet as well as testnet and the addresses are available in Migration.json . Though you need to deploy an Avatar, custom schemes (optional), native reputation and native token contract. Checkout Structure of DAO for details on Avatar, scheme, rep and token DAO can be deployed using Migration package either from CLI or using javascript. Example deployment setup and scripts are available in Starter-template Choose a name for your DAO and the native token and its symbol Do you want to use DAOcreator contract? Deploying a DAO with DAOcreator contract saves number of transactions to be signed by bundling up founder rep and token distribution (upto 100 members) in single tx and initial scheme registration in single tx Which schemes to include in the DAO? Schemes are the actions a DAOstack DAO can take when a proposal passes/fails. Currently supported schemes in Migrations package are: ContributionReward: Enables fund management proposals that distribute funds to beneficiary once the proposal passes GenericScheme: Enables Avatar to make arbitrary function calls to a specific contract. For eg use Avatar to submit a proposal to Genesis Alpha on behalf of your DAO SchemeRegistrar: Lets you submit a proposal to register more schemes (apart from initial schemes set at time of deployment) to the DAO GlobalConstraintRegistrar: Lets you submit a proposal to register more GlobalConstraints UpgradeScheme: Lets you upgrade the controller. Since Controller is not a Scheme it cannot be changed via SchemeRegistrar Find detailed documentation re Schemes in Arc Repo Ucontroller vs Controller? Refer to documentation on Controllers Decide on which Voting Machine to use and the parameters Set the voting machine parameters according to the needs of the organization. Currently you can deploy a DAO using migrations with only GenesisProtocol voting machine, which allows decision at timeout according to higher relative vote. You can find details about different voting machines supported by arc at https://github.com/daostack/arc/tree/master/docs/contracts/VotingMachines Who gets the initial rep and token in DAO? Edit the list of founder members\u2019 address along with the rep and/or token to be distributed initially. You may choose to give equal rep to all or have differentiated rep. Once you have decided on dao-params follow the instruction in Migrations or one of the examples to deploy your dao","title":"How to launch a new DAO?"},{"location":"gettingStarted/setupAlchemyDevMode/","text":"Following is the guide to start developing with Alchemy if you are using already supported schemes by client.js and subgraph . If you have created your own scheme contracts for your DAO, please refer to Add Custom Scheme support tutorial Prerequisites docker = 18.06.1-c docker-compose = 1.22.0 node = 10.16.0 npm = 6.9.0 Overview Alchemy uses Client.js for reading/inferencing blockchain data via DAOstack Subgraph writing/modifying state of Arc contracts Interaction of Alchemy with rest of the stack Boilerplate 1 2 3 git clone https : // github . com / daostack / alchemy . git cd alchemy npm ci Setup Alchemy with Ganache (mode: development) 1 2 3 docker - compose build docker - compose up - d graph - node alchemy - server npm run start The above commands will build docker images and start the following services locally: alchemy-server = for storing proposal information for quick access graph-node = for handling events from blockchain as described in subgraph ganache = dev blockchain with some test DAOs deployed and loaded with GEN and Eth subgraph-ipfs = subgraph mappings on ipfs node subgraph-postgres = db for caching events based on subgraph and later fetched via GraphQL redis = used by alchemy-server for sessions alchemy-postgres Import test accounts that are setup with GEN and ETH to your metamask. You can get the account details by: 1 docker logs alchemy_ganache_1 | head - 35 Now your playground is ready for developing. TODO: Currently webpack does not detect changes in all components and rebuilds only if top-level src/file is changed. For now you can touch the any file in top-level and this should trigger rebuild NOTE: If the feature integration requires you to interact with outside contracts (e.g. uniswap widget integration might require uniswap contracts), then you can simply deploy those contracts to same ganache container using truffle or your own deployment script. See Client.js documentation for more integration details Setup Alchemy with Testnet (mode: staging) Often Ganache does not behave same as production. If you want to setup Alchemy for interacting with testnet and check before you submit PR, then after the boilerplate steps - Choose from one of the following setup for testnet to start playing/integrating features to Alchemy: Use DAOstack rinkeby subgraph Run graph-node locally NOTE: Alchemy only shows daos that are registered via DAOregistry and tracked by DAOstack subgraph for the respective network. You can send the .json of your DAO details to us (contact Nave Rachman, telegram: @NaveRachman) and we will help you. Since above process of registering DAO takes up to 24hrs in following section we provide way to hack it during development and start your own graph-node Use DAOstack rinkeby subgraph Choose this when, using rinkeby testnet working with existing whitelisted DAOs on DAOstack subgraph Run alchemy-server 1 docker - compose up - d alchemy - server Start alchemy in staging mode 1 npm run start - staging Run graph-node locally Choose this when, working with any of the already supported Arc schemes by client Alchemy playing with the DAO that is not yet tracked by DAOstack subgraph Make following changes: Clone subgraph repo and start-graph node locally 1 2 3 git clone git @github . com : daostack / subgraph . git cd subgraph npm i Setup .env file and run rinkeby graph node 1 2 3 4 5 6 7 8 // Following are example values please change for customization network = rinkeby subgraph = daostack postgres_password = letmein ethereum_node = https://rinkeby.infura.io/v3/e0cdf3bfda9b468fa908aa6ab03d5ba2 npm run docker : run - rinkeby Update your DAO details in daos/rinkeby/ DAO-Name .json and deploy subgraph 1 npm run deploy { migrationFile : ../migration.json } Go back to alchemy and Update webpack.dev.config.js , add following process variables 1 2 3 ARC_GRAPHQLHTTPPROVIDER : http://127.0.0.1:8000/subgraphs/name/daostack , ARC_GRAPHQLWSPROVIDER : ws://127.0.0.1:8001/subgraphs/name/daostack , ARC_IPFSPROVIDER : localhost NOTE: If you changed name of subgraph while setting up .env in step 1 then change it in this step accordingly Run alchemy-server 1 docker - compose up - d alchemy - server Start alchemy in staging mode 1 npm run start - staging","title":"Add features to Alchemy interface"},{"location":"gettingStarted/setupAlchemyDevMode/#prerequisites","text":"docker = 18.06.1-c docker-compose = 1.22.0 node = 10.16.0 npm = 6.9.0","title":"Prerequisites"},{"location":"gettingStarted/setupAlchemyDevMode/#overview","text":"Alchemy uses Client.js for reading/inferencing blockchain data via DAOstack Subgraph writing/modifying state of Arc contracts Interaction of Alchemy with rest of the stack","title":"Overview"},{"location":"gettingStarted/setupAlchemyDevMode/#boilerplate","text":"1 2 3 git clone https : // github . com / daostack / alchemy . git cd alchemy npm ci","title":"Boilerplate"},{"location":"gettingStarted/setupAlchemyDevMode/#setup-alchemy-with-ganache-mode-development","text":"1 2 3 docker - compose build docker - compose up - d graph - node alchemy - server npm run start The above commands will build docker images and start the following services locally: alchemy-server = for storing proposal information for quick access graph-node = for handling events from blockchain as described in subgraph ganache = dev blockchain with some test DAOs deployed and loaded with GEN and Eth subgraph-ipfs = subgraph mappings on ipfs node subgraph-postgres = db for caching events based on subgraph and later fetched via GraphQL redis = used by alchemy-server for sessions alchemy-postgres Import test accounts that are setup with GEN and ETH to your metamask. You can get the account details by: 1 docker logs alchemy_ganache_1 | head - 35 Now your playground is ready for developing. TODO: Currently webpack does not detect changes in all components and rebuilds only if top-level src/file is changed. For now you can touch the any file in top-level and this should trigger rebuild NOTE: If the feature integration requires you to interact with outside contracts (e.g. uniswap widget integration might require uniswap contracts), then you can simply deploy those contracts to same ganache container using truffle or your own deployment script. See Client.js documentation for more integration details","title":"Setup Alchemy with Ganache (mode: development)"},{"location":"gettingStarted/setupAlchemyDevMode/#setup-alchemy-with-testnet-mode-staging","text":"Often Ganache does not behave same as production. If you want to setup Alchemy for interacting with testnet and check before you submit PR, then after the boilerplate steps - Choose from one of the following setup for testnet to start playing/integrating features to Alchemy: Use DAOstack rinkeby subgraph Run graph-node locally NOTE: Alchemy only shows daos that are registered via DAOregistry and tracked by DAOstack subgraph for the respective network. You can send the .json of your DAO details to us (contact Nave Rachman, telegram: @NaveRachman) and we will help you. Since above process of registering DAO takes up to 24hrs in following section we provide way to hack it during development and start your own graph-node","title":"Setup Alchemy with Testnet (mode: staging)"},{"location":"gettingStarted/setupAlchemyDevMode/#use-daostack-rinkeby-subgraph","text":"Choose this when, using rinkeby testnet working with existing whitelisted DAOs on DAOstack subgraph Run alchemy-server 1 docker - compose up - d alchemy - server Start alchemy in staging mode 1 npm run start - staging","title":"Use DAOstack rinkeby subgraph"},{"location":"gettingStarted/setupAlchemyDevMode/#run-graph-node-locally","text":"Choose this when, working with any of the already supported Arc schemes by client Alchemy playing with the DAO that is not yet tracked by DAOstack subgraph Make following changes: Clone subgraph repo and start-graph node locally 1 2 3 git clone git @github . com : daostack / subgraph . git cd subgraph npm i Setup .env file and run rinkeby graph node 1 2 3 4 5 6 7 8 // Following are example values please change for customization network = rinkeby subgraph = daostack postgres_password = letmein ethereum_node = https://rinkeby.infura.io/v3/e0cdf3bfda9b468fa908aa6ab03d5ba2 npm run docker : run - rinkeby Update your DAO details in daos/rinkeby/ DAO-Name .json and deploy subgraph 1 npm run deploy { migrationFile : ../migration.json } Go back to alchemy and Update webpack.dev.config.js , add following process variables 1 2 3 ARC_GRAPHQLHTTPPROVIDER : http://127.0.0.1:8000/subgraphs/name/daostack , ARC_GRAPHQLWSPROVIDER : ws://127.0.0.1:8001/subgraphs/name/daostack , ARC_IPFSPROVIDER : localhost NOTE: If you changed name of subgraph while setting up .env in step 1 then change it in this step accordingly Run alchemy-server 1 docker - compose up - d alchemy - server Start alchemy in staging mode 1 npm run start - staging","title":"Run graph-node locally"},{"location":"gettingStarted/setupGenericScheme/","text":"Generic Schemes In DAOstack, \"schemes\" are smart contracts that enable various DAO actions, and \"generic schemes\" are schemes that enable nearly any kind of action possible for an Ethereum address. GenericScheme and UGenericScheme are both types of generic scheme. DAOs can use these schemes: to enable truly generic DAO actions (letting proposers choose which contracts to interact with and how), or to create specific, custom integrations for their DAO (actions that make particular calls to particular smart contracts that serve a particular purpose for the DAO). When to use GenericScheme and when to use UGenericScheme UGenericScheme : If a DAO only needs a single generic scheme and/or doesn't need to change the scheme's on-chain code at all, then the UGenericScheme is a good choice, since it is already deployed and can be used by any number of DAOs (the \"U\" stands for \"universal\"). GenericScheme : If a DAO wants to make multiple smart contracts available, with different labels and proposal types in the UI, then each contract should use its own GenericScheme, customized if required for the DAO's purpose. NOTE: While at the contract level, both generic schemes only need encoded call data to function, asking users to provide this data is not good UX. If you're using a generic scheme for anything except a truly generic action, which is only accessible to Ethereum experts, we ask that you add Alchemy support for the specific actions you intend. Please do not register your scheme on mainnet without adding alchemy support for it. Here is an example of a customized generic scheme on mainnet. How to register a generic scheme to a DAO A DAO can only use schemes that are registered with its controller. There are two ways to register a scheme to a DAO's controller: During the DAO's creation, while deploying the DAO's contracts Through a proposal that uses a scheme with permission to register schemes to the DAO. NOTE: In case of the Genesis DAO, you can propose new schemes to be registered using the aptly named Scheme Registrar scheme. Register a generic scheme while deploying a DAO While deploying DAO, \" UGenericScheme \" can be used to register the universal generic scheme. If are using the regular GenericScheme, then you can register multiple \" GenericScheme \" instances and mention each in the customSchemes section of your migration-dao-params.json . Refer to the instructions for how to deploy DAO . Set UGenericScheme to interact with your contract NOTE: Follow this if UGenericScheme is not already registered in your DAO or you need to update UGenericScheme with new parameters. You can use UGenericScheme's setParameters method to setup the contractToCall , the votingMachine to use, and the voteParameters used for voting on proposals for the generic scheme action. The following is a short script that shows how to do this: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 const ugenericScheme = new web3 . eth . Contract ( require ( @daostack/arc/build/contracts/UGenericScheme.json ). abi , UGenericSchemeAddress , // address from https://github.com/daostack/migration/blob/master/migration.json { from , gas , gasPrice } ) // These are example values: please change appropriately. // Refer to https://daostack.zendesk.com/hc/en-us/sections/360000535638-Genesis-Protocol const voteParams = { boostedVotePeriodLimit : 345600 , daoBountyConst : 10 , minimumDaoBountyGWei : 150000000000 , queuedVotePeriodLimit : 2592000 , queuedVoteRequiredPercentage : 50 , preBoostedVotePeriodLimit : 86400 , proposingRepRewardGwei : 50000000000 , quietEndingPeriod : 172800 , thresholdConst : 1200 , voteOnBehalf : 0x0000000000000000000000000000000000000000 , votersReputationLossRatio : 4 , activationTime : 0 } // Get address from https://github.com/daostack/migration/blob/master/migration.json const votingMachineAddress = 0xaddress-of-VotingMachine-of-DAO-on-given-network // If you want this Generic Scheme to enable DAO to interact with Bounties Network // then targetContract would be the address of Bounties Network s respective contract const targetContractAddress = 0xaddress-of-contract-this-will-interact-with // paramHash will be useful in later step so lets log it const paramHash = ugenericScheme . methods . setParameters ( voteParams , votingMachineAddress , targetContractAddress ). call () console . log ( paramHash ) ugenericScheme . methods . setParameters ( voteParams , votingMachineAddress , targetContractAddress ). send () OR Set GenericScheme to interact with your contract First, you will have to deploy a new instance of GenericScheme and use its initialize method to setup its params: the DAO Avatar it connects to, the contractToCall , the votingMachine to use, and the voteParameters for voting on proposals that use the scheme. The following is a short script that shows how to do this: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 const genericSchemeJson = require ( @daostack/arc/build/contracts/GenericScheme.json ) const genericSchemeContract = new web3 . eth . Contract ( genericSchemeJson . abi , undefined , { from , gas , gasPrice } ) // Deploy New GenericScheme Instance const genericSchemeDeployedContract = genericSchemeContract . deploy ({ data : genericSchemeJson . bytecode , arguments : null }). send () let genericScheme = await genericSchemeDeployedContract // Log Address of new instance to use in next step while registering the scheme to DAO console . log ( `Deployed new GenericScheme instance at ${ genericScheme . options . address } ` ) // Following are example values, Please change appropriately // Refer https://daostack.zendesk.com/hc/en-us/sections/360000535638-Genesis-Protocol const voteParams = { boostedVotePeriodLimit : 345600 , daoBountyConst : 10 , minimumDaoBountyGWei : 150000000000 , queuedVotePeriodLimit : 2592000 , queuedVoteRequiredPercentage : 50 , preBoostedVotePeriodLimit : 86400 , proposingRepRewardGwei : 50000000000 , quietEndingPeriod : 172800 , thresholdConst : 1200 , voteOnBehalf : 0x0000000000000000000000000000000000000000 , votersReputationLossRatio : 4 , activationTime : 0 } // Get address from https://github.com/daostack/migration/blob/master/migration.json const votingMachineAddress = 0xaddress-of-VotingMachine-of-DAO-on-given-network // For eg if you want this Generic Scheme to enable DAO to interact with Bounties Network // then targetContract would be the address of Bounties Network s respective contract const targetContractAddress = 0xaddress-of-contract-this-will-interact-with const avatar = 0xaddres-of-DAO // paramHash will be useful in later step so lets log it const paramHash = genericScheme . methods . initialize ( avatar , voteParams , votingMachineAddress , targetContractAddress ). call () console . log ( paramHash ) genericScheme . methods . initialize ( avatar , voteParams , votingMachineAddress , targetContractAddress ). send () Submit a new proposal to the Scheme Registrar via Alchemy UI On Alchemy's landing page, choose the DAO to which you wish to register the scheme. Visit the DAO's Home page and choose Scheme Registrar . Click New Proposal \u2013 this will open a popup. Select Add Scheme on the popup sidebar (on the left). Give the proposal an appropriate title, description, and url linking to a description of the proposal. For Scheme , put the address of your Generic Scheme contract (universal or not). Enter the paramHash you got here . In the permissions section, check Call genericCall on behalf of (this will allow your scheme to make generic calls, which is the whole point here). Submit the proposal and sign the transaction as normal. If the DAO passes your proposal, then your Generic Scheme with the ability to interact with the targetContract will be registered to the DAO, and people will be able to submit proposals for the DAO to take your custom generic action. How to get Generic Scheme indexed by DAOstack subgraph The DAOstack subgraph enables Alchemy's quick loading of cached blockchain data and is a huge part of creating a positive user experience in Alchemy. If you are using: UGenericScheme: the subgraph is already indexing the scheme, and you do not have to worry about it \ud83d\ude05 GenericScheme: You will have to submit a PR here Make sure to choose the correct Ethereum network for your DAO If the scheme is for a new DAO, then add YourDAO.json in that network folder. eg. 1 2 3 4 5 6 7 8 9 10 11 { name : New DAO , Avatar : 0xaddress-of-avatar-on-this-network , DAOToken : 0xaddress-of-daotoken-on-this-network , Reputation : 0xaddress-of-nativereputation-on-this-network , Controller : 0xaddress-of-controller-on-this-network , Schemes : { GenesisScheme : 0xaddress-of-genericScheme-on-this-network } , arcVersion : 0.0.1-rc.22 # choose the correct arc version } If the scheme is for an already existing DAO, then edit existing-DAO .json for the correct network. Add to the schemes section, eg. 1 2 3 4 Schemes : { GenesisScheme : 0xaddress-of-genericScheme-on-this-network } , arcVersion : 0.0.1-rc.22 # choose the correct arc version How to get your Generic Scheme showing up in Alchemy To help you get a user-friendly interface for your generic scheme, we have created a way to customize Alchemy's UI for specific generic schemes. The customization has a few pieces, and you will have to submit a PR to the Alchemy repo once you're finished with it. Proposal Creation Interface Customize the \"create proposal\" popup to present the different functions the scheme can call on the contract. This requires adding the contracts\u2019 ABI and customizing things like the titles of the labels and placeholders. If this was a generic scheme for interacting with the Bounties Network, you would create a file named something like Bounties.json and add it here . Use the following example or refer to an example using the DutchX integration. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 // Bounties.json { name : Bounties , address : { main : [ 0xtarget-contract-address-on-mainnet ], rinkeby : [], private : [] }, actions : [ { id : createBountyMethod-from-contract , label : Create Bounty , description : This method will create a bounty with the DAO as the issuer , notes : , fields : [ { label : bounty title , name : name-of-field-in-abi , placeholder : Osam Bin-Laden - dead or alive }, { // more feilds if any }, ], abi : {}, }, { // more methods of contract if any } ], } Update Known Schemes Once you have customised the proposal create interface update the genericSchemeRegistry For eg. In case of StandardBounty scheme we will add: 1 2 3 4 5 6 const standardBountiesInfo = require ( ./schemes/StandardBounties.json ) const KNOWNSCHEMES = [ ..., standardBountiesInfo ]; Proposal Display Interface You will also have to customise the description summary for your scheme to explain what it does. Refer to the ProposalSummaryDutchX and add your own proposal summary file, say ProposalSummaryBountiesNetwork.tsx , here . Update Proposal Summary render Once you have created the proposal summary make sure that it gets rendered by updating ProposalSummaryKnownGenericScheme.tsx For eg. In case of StandardBounty scheme we will add: 1 2 3 4 import ProposalSummaryStandardBounties from ./ProposalSummaryStandardBounties ; if ( genericSchemeInfo . specs . name === StandardBounties ) { return ProposalSummaryStandardBounties { ... this . props } / ; Integration tests Please add the relevant integration test for your scheme. You can refer to genericSchemeDutchx tests. (Optional) Change the Scheme UI Right now, Alchemy\u2019s UI is only focused on currently open proposals (it does not show past proposals). But based on the scheme you are adding, there might be some different UI features/tabs that are required. For a bounties scheme, for example, it would be helpful to have a new tab that shows open bounties (from proposals that have already been passed).","title":"Setup Generic Scheme for a DAO"},{"location":"gettingStarted/setupGenericScheme/#generic-schemes","text":"In DAOstack, \"schemes\" are smart contracts that enable various DAO actions, and \"generic schemes\" are schemes that enable nearly any kind of action possible for an Ethereum address. GenericScheme and UGenericScheme are both types of generic scheme. DAOs can use these schemes: to enable truly generic DAO actions (letting proposers choose which contracts to interact with and how), or to create specific, custom integrations for their DAO (actions that make particular calls to particular smart contracts that serve a particular purpose for the DAO).","title":"Generic Schemes"},{"location":"gettingStarted/setupGenericScheme/#when-to-use-genericscheme-and-when-to-use-ugenericscheme","text":"UGenericScheme : If a DAO only needs a single generic scheme and/or doesn't need to change the scheme's on-chain code at all, then the UGenericScheme is a good choice, since it is already deployed and can be used by any number of DAOs (the \"U\" stands for \"universal\"). GenericScheme : If a DAO wants to make multiple smart contracts available, with different labels and proposal types in the UI, then each contract should use its own GenericScheme, customized if required for the DAO's purpose. NOTE: While at the contract level, both generic schemes only need encoded call data to function, asking users to provide this data is not good UX. If you're using a generic scheme for anything except a truly generic action, which is only accessible to Ethereum experts, we ask that you add Alchemy support for the specific actions you intend. Please do not register your scheme on mainnet without adding alchemy support for it. Here is an example of a customized generic scheme on mainnet.","title":"When to use GenericScheme and when to use UGenericScheme"},{"location":"gettingStarted/setupGenericScheme/#how-to-register-a-generic-scheme-to-a-dao","text":"A DAO can only use schemes that are registered with its controller. There are two ways to register a scheme to a DAO's controller: During the DAO's creation, while deploying the DAO's contracts Through a proposal that uses a scheme with permission to register schemes to the DAO. NOTE: In case of the Genesis DAO, you can propose new schemes to be registered using the aptly named Scheme Registrar scheme.","title":"How to register a generic scheme to a DAO"},{"location":"gettingStarted/setupGenericScheme/#register-a-generic-scheme-while-deploying-a-dao","text":"While deploying DAO, \" UGenericScheme \" can be used to register the universal generic scheme. If are using the regular GenericScheme, then you can register multiple \" GenericScheme \" instances and mention each in the customSchemes section of your migration-dao-params.json . Refer to the instructions for how to deploy DAO .","title":"Register a generic scheme while deploying a DAO"},{"location":"gettingStarted/setupGenericScheme/#set-ugenericscheme-to-interact-with-your-contract","text":"NOTE: Follow this if UGenericScheme is not already registered in your DAO or you need to update UGenericScheme with new parameters. You can use UGenericScheme's setParameters method to setup the contractToCall , the votingMachine to use, and the voteParameters used for voting on proposals for the generic scheme action. The following is a short script that shows how to do this: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 const ugenericScheme = new web3 . eth . Contract ( require ( @daostack/arc/build/contracts/UGenericScheme.json ). abi , UGenericSchemeAddress , // address from https://github.com/daostack/migration/blob/master/migration.json { from , gas , gasPrice } ) // These are example values: please change appropriately. // Refer to https://daostack.zendesk.com/hc/en-us/sections/360000535638-Genesis-Protocol const voteParams = { boostedVotePeriodLimit : 345600 , daoBountyConst : 10 , minimumDaoBountyGWei : 150000000000 , queuedVotePeriodLimit : 2592000 , queuedVoteRequiredPercentage : 50 , preBoostedVotePeriodLimit : 86400 , proposingRepRewardGwei : 50000000000 , quietEndingPeriod : 172800 , thresholdConst : 1200 , voteOnBehalf : 0x0000000000000000000000000000000000000000 , votersReputationLossRatio : 4 , activationTime : 0 } // Get address from https://github.com/daostack/migration/blob/master/migration.json const votingMachineAddress = 0xaddress-of-VotingMachine-of-DAO-on-given-network // If you want this Generic Scheme to enable DAO to interact with Bounties Network // then targetContract would be the address of Bounties Network s respective contract const targetContractAddress = 0xaddress-of-contract-this-will-interact-with // paramHash will be useful in later step so lets log it const paramHash = ugenericScheme . methods . setParameters ( voteParams , votingMachineAddress , targetContractAddress ). call () console . log ( paramHash ) ugenericScheme . methods . setParameters ( voteParams , votingMachineAddress , targetContractAddress ). send () OR","title":"Set UGenericScheme to interact with your contract"},{"location":"gettingStarted/setupGenericScheme/#set-genericscheme-to-interact-with-your-contract","text":"First, you will have to deploy a new instance of GenericScheme and use its initialize method to setup its params: the DAO Avatar it connects to, the contractToCall , the votingMachine to use, and the voteParameters for voting on proposals that use the scheme. The following is a short script that shows how to do this: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 const genericSchemeJson = require ( @daostack/arc/build/contracts/GenericScheme.json ) const genericSchemeContract = new web3 . eth . Contract ( genericSchemeJson . abi , undefined , { from , gas , gasPrice } ) // Deploy New GenericScheme Instance const genericSchemeDeployedContract = genericSchemeContract . deploy ({ data : genericSchemeJson . bytecode , arguments : null }). send () let genericScheme = await genericSchemeDeployedContract // Log Address of new instance to use in next step while registering the scheme to DAO console . log ( `Deployed new GenericScheme instance at ${ genericScheme . options . address } ` ) // Following are example values, Please change appropriately // Refer https://daostack.zendesk.com/hc/en-us/sections/360000535638-Genesis-Protocol const voteParams = { boostedVotePeriodLimit : 345600 , daoBountyConst : 10 , minimumDaoBountyGWei : 150000000000 , queuedVotePeriodLimit : 2592000 , queuedVoteRequiredPercentage : 50 , preBoostedVotePeriodLimit : 86400 , proposingRepRewardGwei : 50000000000 , quietEndingPeriod : 172800 , thresholdConst : 1200 , voteOnBehalf : 0x0000000000000000000000000000000000000000 , votersReputationLossRatio : 4 , activationTime : 0 } // Get address from https://github.com/daostack/migration/blob/master/migration.json const votingMachineAddress = 0xaddress-of-VotingMachine-of-DAO-on-given-network // For eg if you want this Generic Scheme to enable DAO to interact with Bounties Network // then targetContract would be the address of Bounties Network s respective contract const targetContractAddress = 0xaddress-of-contract-this-will-interact-with const avatar = 0xaddres-of-DAO // paramHash will be useful in later step so lets log it const paramHash = genericScheme . methods . initialize ( avatar , voteParams , votingMachineAddress , targetContractAddress ). call () console . log ( paramHash ) genericScheme . methods . initialize ( avatar , voteParams , votingMachineAddress , targetContractAddress ). send ()","title":"Set GenericScheme to interact with your contract"},{"location":"gettingStarted/setupGenericScheme/#submit-a-new-proposal-to-the-scheme-registrar-via-alchemy-ui","text":"On Alchemy's landing page, choose the DAO to which you wish to register the scheme. Visit the DAO's Home page and choose Scheme Registrar . Click New Proposal \u2013 this will open a popup. Select Add Scheme on the popup sidebar (on the left). Give the proposal an appropriate title, description, and url linking to a description of the proposal. For Scheme , put the address of your Generic Scheme contract (universal or not). Enter the paramHash you got here . In the permissions section, check Call genericCall on behalf of (this will allow your scheme to make generic calls, which is the whole point here). Submit the proposal and sign the transaction as normal. If the DAO passes your proposal, then your Generic Scheme with the ability to interact with the targetContract will be registered to the DAO, and people will be able to submit proposals for the DAO to take your custom generic action.","title":"Submit a new proposal to the Scheme Registrar via Alchemy UI"},{"location":"gettingStarted/setupGenericScheme/#how-to-get-generic-scheme-indexed-by-daostack-subgraph","text":"The DAOstack subgraph enables Alchemy's quick loading of cached blockchain data and is a huge part of creating a positive user experience in Alchemy. If you are using: UGenericScheme: the subgraph is already indexing the scheme, and you do not have to worry about it \ud83d\ude05 GenericScheme: You will have to submit a PR here Make sure to choose the correct Ethereum network for your DAO If the scheme is for a new DAO, then add YourDAO.json in that network folder. eg. 1 2 3 4 5 6 7 8 9 10 11 { name : New DAO , Avatar : 0xaddress-of-avatar-on-this-network , DAOToken : 0xaddress-of-daotoken-on-this-network , Reputation : 0xaddress-of-nativereputation-on-this-network , Controller : 0xaddress-of-controller-on-this-network , Schemes : { GenesisScheme : 0xaddress-of-genericScheme-on-this-network } , arcVersion : 0.0.1-rc.22 # choose the correct arc version } If the scheme is for an already existing DAO, then edit existing-DAO .json for the correct network. Add to the schemes section, eg. 1 2 3 4 Schemes : { GenesisScheme : 0xaddress-of-genericScheme-on-this-network } , arcVersion : 0.0.1-rc.22 # choose the correct arc version","title":"How to get Generic Scheme indexed by DAOstack subgraph"},{"location":"gettingStarted/setupGenericScheme/#how-to-get-your-generic-scheme-showing-up-in-alchemy","text":"To help you get a user-friendly interface for your generic scheme, we have created a way to customize Alchemy's UI for specific generic schemes. The customization has a few pieces, and you will have to submit a PR to the Alchemy repo once you're finished with it.","title":"How to get your Generic Scheme showing up in Alchemy"},{"location":"gettingStarted/setupGenericScheme/#proposal-creation-interface","text":"Customize the \"create proposal\" popup to present the different functions the scheme can call on the contract. This requires adding the contracts\u2019 ABI and customizing things like the titles of the labels and placeholders. If this was a generic scheme for interacting with the Bounties Network, you would create a file named something like Bounties.json and add it here . Use the following example or refer to an example using the DutchX integration. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 // Bounties.json { name : Bounties , address : { main : [ 0xtarget-contract-address-on-mainnet ], rinkeby : [], private : [] }, actions : [ { id : createBountyMethod-from-contract , label : Create Bounty , description : This method will create a bounty with the DAO as the issuer , notes : , fields : [ { label : bounty title , name : name-of-field-in-abi , placeholder : Osam Bin-Laden - dead or alive }, { // more feilds if any }, ], abi : {}, }, { // more methods of contract if any } ], }","title":"Proposal Creation Interface"},{"location":"gettingStarted/setupGenericScheme/#update-known-schemes","text":"Once you have customised the proposal create interface update the genericSchemeRegistry For eg. In case of StandardBounty scheme we will add: 1 2 3 4 5 6 const standardBountiesInfo = require ( ./schemes/StandardBounties.json ) const KNOWNSCHEMES = [ ..., standardBountiesInfo ];","title":"Update Known Schemes"},{"location":"gettingStarted/setupGenericScheme/#proposal-display-interface","text":"You will also have to customise the description summary for your scheme to explain what it does. Refer to the ProposalSummaryDutchX and add your own proposal summary file, say ProposalSummaryBountiesNetwork.tsx , here .","title":"Proposal Display Interface"},{"location":"gettingStarted/setupGenericScheme/#update-proposal-summary-render","text":"Once you have created the proposal summary make sure that it gets rendered by updating ProposalSummaryKnownGenericScheme.tsx For eg. In case of StandardBounty scheme we will add: 1 2 3 4 import ProposalSummaryStandardBounties from ./ProposalSummaryStandardBounties ; if ( genericSchemeInfo . specs . name === StandardBounties ) { return ProposalSummaryStandardBounties { ... this . props } / ;","title":"Update Proposal Summary render"},{"location":"gettingStarted/setupGenericScheme/#integration-tests","text":"Please add the relevant integration test for your scheme. You can refer to genericSchemeDutchx tests.","title":"Integration tests"},{"location":"gettingStarted/setupGenericScheme/#optional-change-the-scheme-ui","text":"Right now, Alchemy\u2019s UI is only focused on currently open proposals (it does not show past proposals). But based on the scheme you are adding, there might be some different UI features/tabs that are required. For a bounties scheme, for example, it would be helpful to have a new tab that shows open bounties (from proposals that have already been passed).","title":"(Optional) Change the Scheme UI"},{"location":"gettingStarted/customScheme/alchemyIntegrationForNewScheme/","text":"Coming Soon","title":"Alchemy: integrate with DAOstack interface"},{"location":"gettingStarted/customScheme/clientForNewScheme/","text":"You might want to update client library while working on Alchemy integration if you added new contract or updated subgraph In this client tutorial we will extend client library to interact with the previous non-universal example scheme BuyInWithRageQuitOpt Pre Work Make sure you have cloned client submodule, if you have not already 1 git submodule update --init Update Client In order to extend client support for the new scheme you will have to add the following: New Scheme Class New Entity Class Integration Test ( Merging code without testing is a risky business \ud83d\ude01) Some case dependent updates Add new scheme class Create file client/src/schemes/BuyInWithRageQuitOpt.ts that exports the new scheme class to enable client to interact with the scheme contract Please refer to Example Scheme Class NOTE: You will need to add abi of the contract in client/src , if it does not exist in @daostack/arc Client library use toIOperationObservable to create observables to get 3rd confirmation update Example Scheme class 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 import BN = require ( bn.js ) import { from } from rxjs import { concatMap } from rxjs/operators import buyInWithRageQuitOptScheme = require ( ./BuyInWithRageQuitOpt.json ) import { Operation , toIOperationObservable } from ../operation import { Scheme } from ../scheme import { Deposit } from ../deposit export class BuyInWithRageQuitOptScheme { constructor ( public scheme : Scheme ) { } err = ( error : Error ): Error = { return error } public deposit ( amount : BN ): Operation Deposit | null { const observable = from ( this . getContract ()) . pipe ( concatMap (( buyInWithRageQuitOpt ) = { const transaction = { value : amount , tx : buyInWithRageQuitOpt . methods . deposit () } const map = ( receipt : any ) = { const event = receipt . events . buyIn if ( ! event ) { return null } return new Deposit ({ amount : event . returnValues . _amount , member : event . returnValues . _member . toLowerCase (), dao : event . returnValues . _avatar . toLowerCase (), rep : event . returnValues . _rep }, this . scheme . context ) } return this . scheme . context . sendTransaction ( transaction , map , this . err ) }) ) return toIOperationObservable ( observable ) } public quit (): Operation Quit | null { const observable = from ( this . getContract ()) . pipe ( concatMap (( buyInWithRageQuitOpt ) = { const transaction = buyInWithRageQuitOpt . methods . quit () const map = ( receipt : any ) = { const event = receipt . events . buyIn if ( ! event ) { return null } return new Quit ({ amount : event . returnValues . _amount , memberAddress : event . returnValues . _memberAddress , dao : event . returnValues . _avatar , rep : event . returnValues . _rep }, this . scheme . context ) } return this . scheme . context . sendTransaction ( transaction , map , this . err ) }) ) return toIOperationObservable ( observable ) } private async getContract () { const state = await this . scheme . fetchStaticState () return this . scheme . context . getContract ( state . address , buyInWithRageQuitOptScheme . abi ) } } Add new Entity class Enable client library to interact with the Entities added to subgraph during previous step (Upgrade subgraph) Add relevant IEntityStaticState, IEntityState and IEntityQueryOptions interface Each Entity class must have following methods: state : that takes IEntityQueryOptions and returns Entity Observable from graphQL query setStaticState : that sets IEntityStaticState fetchStaticState : that returns IEntityStaticState observable state : that returns IEntityState observable Please refer to example Deposit Entity class Example Entity Class 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 import gql from graphql-tag import { Observable } from rxjs import { first } from rxjs/operators import { Arc , IApolloQueryOptions } from ./arc import { Address , ICommonQueryOptions , IStateful } from ./types import { BN , createGraphQlQuery , isAddress } from ./utils export interface IDepositStaticState { id ? : string member : Address amount : typeof BN rep : typeof BN dao : Address } export interface IDepositState extends IDepositStaticState { id : string } export interface IDepositQueryOptions extends ICommonQueryOptions { where ? : { id ? : string member ? : Address dao ? : Address [ key : string ]: any } } export class Deposit implements IStateful IDepositState { /** * Deposit . search ( context , options ) searches for deposit entities * @param context an Arc instance that provides connection information * @param options the query options , cf . IDepositQueryOptions * @return an observable of Deposit objects */ public static search ( context : Arc , options : IDepositQueryOptions = {}, apolloQueryOptions : IApolloQueryOptions = {} ): Observable Deposit [] { if ( ! options . where ) { options . where = {}} let where = let daoFilter : ( r : any ) = boolean daoFilter = () = true for ( const key of Object . keys ( options . where )) { if ( options . where [ key ] === undefined ) { continue } if ( key === member || key === dao ) { const option = options . where [ key ] as string isAddress ( option ) options . where [ key ] = option . toLowerCase () } else { where += `${key}: ${options.where[key] as string} \\n` } } const query = gql ` query DepositSearch { deposits $ { createGraphQlQuery ( options , where )} { id member amount avatar rep } } ` return context . getObservableListWithFilter ( query , ( r : any ) = { return new Deposit ({ id : r . id , member : r . member , amount : new BN ( r . amount || 0 ), dao : r . avatar , rep : new BN ( r . rep || 0 ) }, context ) }, daoFilter , apolloQueryOptions ) as Observable Deposit [] } public id : string | undefined public staticState : IDepositStaticState | undefined constructor ( idOrOpts : string | IDepositStaticState , public context : Arc ) { if ( typeof idOrOpts === string ) { this . id = idOrOpts } else { const opts = idOrOpts as IDepositStaticState this . id = opts . id this . setStaticState ( opts ) } } public setStaticState ( opts : IDepositStaticState ) { this . staticState = opts } public async fetchStaticState (): Promise IDepositStaticState { if ( !! this . staticState ) { return this . staticState } else { return await this . state () . pipe ( first ()) . toPromise () } } public state ( apolloQueryOptions : IApolloQueryOptions = {}): Observable IDepositState { const query = gql ` query DepositById { deposit ( id : ${this.id} ) { id memberAddress amount avatar rep } } ` const itemMap = ( item : any ): IDepositState = { if ( item === null ) { throw Error ( `Could not find a Vote with id ${this.id}` ) } return { amount : item . amount , dao : item . dao , id : item . id , member : item . member , rep : item . rep } } return this . context . getObservableObject ( query , itemMap , apolloQueryOptions ) } } Integration Tests Add relevant integration test for the new scheme, client/test/scheme-buyInWithRageQuitOpt.spec.ts Start test watcher while you test and update the client 1 npm run test : watch : client -- test/scheme-buyInWithRageQuitOpt.spec.ts Refer to example Test BuyInWithRageQuitOpt Scheme Example Test BuyInWithRageQuitOpt Scheme Following is an example integration test file to test the sample non-universal scheme we developed in this tutorial 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 import { Scheme } from ../src/scheme import { Arc } from ../src/arc import { DAO } from ../src/dao import { first } from rxjs/operators import { Reputation } from ../src/reputation import { Deposit } from ../src/deposit import { BN , getTestDAO , getTestAddresses , newArc , toWei , waitUntilTrue } from ./utils jest . setTimeout ( 60000 ) /** * Scheme test */ describe ( Deposit to buy reputaion , () = { let addresses : any let arc : Arc let dao : DAO let scheme : Scheme let daoBalanceBefore : undefined let reputationBefore : undefined let eventLengthBefore : number let reputation : any let amount = toWei ( 0.1 ) let response : any const getEventLength = async () = { let deposits = await Deposit . search ( arc , { where : { member : arc . web3 . eth . defaultAccount }}, { fetchPolicy : no-cache } ) . pipe ( first ()) . toPromise () return deposits . length } beforeAll ( async () = { arc = await newArc () addresses = getTestAddresses ( arc ) dao = await getTestDAO () scheme = new Scheme ({ address : 0x6d065a54f0a14cb03b949a146dbb58c14a0afc48 , dao : dao . id , id : 0x992c72e5e965d11a318839b554b0330dcb3ac81dc2ac0e4e57ba2c15660a3564 , name : BuyInWithRageQuitOpt , paramsHash : 0x0000000000000000000000000000000000000000000000000000000000000000 }, arc ) reputation = new Reputation ( addresses . dao . Reputation , arc ) daoBalanceBefore = await dao . ethBalance () . pipe ( first ()) . toPromise () reputationBefore = await reputation . reputationOf ( arc . web3 . eth . defaultAccount ) . pipe ( first ()) . toPromise () eventLengthBefore = await getEventLength () expect ( scheme . BuyInWithRageQuitOpt ) . not . toBeFalsy () if ( scheme . BuyInWithRageQuitOpt ) { response = await scheme . BuyInWithRageQuitOpt . deposit ( amount ) . send () expect ( response ) } }) it ( Should increase DAO balance by amount deposited , async () = { let daoBalanceAfter = await dao . ethBalance () . pipe ( first ()) . toPromise () expect ( Number ( daoBalanceAfter ) - Number ( daoBalanceBefore )) . toEqual ( Number ( amount )) }) it ( Should increase reputation of Member by amount deposited , async () = { let reputationAfter = new BN ( await reputation . contract () . methods . balanceOf ( arc . web3 . eth . defaultAccount ) . call ()) expect ( Number ( reputationAfter ) - Number ( reputationBefore )) . toEqual ( Number ( amount )) }) it ( Should index the deposit event , async () = { const state0 = await response . result . fetchStaticState () expect ( state0 ) . toMatchObject ({ amount : amount . toString (), member : arc . web3 . eth . defaultAccount . toLowerCase (), dao : dao . id . toLowerCase (), rep : amount . toString () }) let eventLengthAfter = eventLengthBefore const depositIsIndexed = async () = { eventLengthAfter = await getEventLength () return eventLengthAfter - eventLengthBefore 0 } await waitUntilTrue ( depositIsIndexed ) expect ( eventLengthAfter - 1 ) . toEqual ( eventLengthBefore ) }) }) describe ( Quit to refund funds , () = { // add more tests }) Extra Interoperability updates (may differ per use case) Apart from the above standard updates you might need to update some other files depending on the scheme you are adding. For eg. In case of BuyInWithRageQuitOpt Scheme , we added to following files: src/scheme.ts : To add BuyInWithRageQuitOpt to ISchemeState src/operation.ts : To enable passing custom value to this.scheme.context.sendTransaction test/utils.ts : To update LATEST_ARC_VERSION and to getTestAddresses of our newly created DAO instead of test DAO test/migration.json : To use the migration file we got in the migration step (which has details of our DAO and new scheme`","title":"Client: interact with new Scheme"},{"location":"gettingStarted/customScheme/clientForNewScheme/#pre-work","text":"Make sure you have cloned client submodule, if you have not already 1 git submodule update --init","title":"Pre Work"},{"location":"gettingStarted/customScheme/clientForNewScheme/#update-client","text":"In order to extend client support for the new scheme you will have to add the following: New Scheme Class New Entity Class Integration Test ( Merging code without testing is a risky business \ud83d\ude01) Some case dependent updates","title":"Update Client"},{"location":"gettingStarted/customScheme/clientForNewScheme/#add-new-scheme-class","text":"Create file client/src/schemes/BuyInWithRageQuitOpt.ts that exports the new scheme class to enable client to interact with the scheme contract Please refer to Example Scheme Class NOTE: You will need to add abi of the contract in client/src , if it does not exist in @daostack/arc Client library use toIOperationObservable to create observables to get 3rd confirmation update","title":"Add new scheme class"},{"location":"gettingStarted/customScheme/clientForNewScheme/#example-scheme-class","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 import BN = require ( bn.js ) import { from } from rxjs import { concatMap } from rxjs/operators import buyInWithRageQuitOptScheme = require ( ./BuyInWithRageQuitOpt.json ) import { Operation , toIOperationObservable } from ../operation import { Scheme } from ../scheme import { Deposit } from ../deposit export class BuyInWithRageQuitOptScheme { constructor ( public scheme : Scheme ) { } err = ( error : Error ): Error = { return error } public deposit ( amount : BN ): Operation Deposit | null { const observable = from ( this . getContract ()) . pipe ( concatMap (( buyInWithRageQuitOpt ) = { const transaction = { value : amount , tx : buyInWithRageQuitOpt . methods . deposit () } const map = ( receipt : any ) = { const event = receipt . events . buyIn if ( ! event ) { return null } return new Deposit ({ amount : event . returnValues . _amount , member : event . returnValues . _member . toLowerCase (), dao : event . returnValues . _avatar . toLowerCase (), rep : event . returnValues . _rep }, this . scheme . context ) } return this . scheme . context . sendTransaction ( transaction , map , this . err ) }) ) return toIOperationObservable ( observable ) } public quit (): Operation Quit | null { const observable = from ( this . getContract ()) . pipe ( concatMap (( buyInWithRageQuitOpt ) = { const transaction = buyInWithRageQuitOpt . methods . quit () const map = ( receipt : any ) = { const event = receipt . events . buyIn if ( ! event ) { return null } return new Quit ({ amount : event . returnValues . _amount , memberAddress : event . returnValues . _memberAddress , dao : event . returnValues . _avatar , rep : event . returnValues . _rep }, this . scheme . context ) } return this . scheme . context . sendTransaction ( transaction , map , this . err ) }) ) return toIOperationObservable ( observable ) } private async getContract () { const state = await this . scheme . fetchStaticState () return this . scheme . context . getContract ( state . address , buyInWithRageQuitOptScheme . abi ) } }","title":"Example Scheme class"},{"location":"gettingStarted/customScheme/clientForNewScheme/#add-new-entity-class","text":"Enable client library to interact with the Entities added to subgraph during previous step (Upgrade subgraph) Add relevant IEntityStaticState, IEntityState and IEntityQueryOptions interface Each Entity class must have following methods: state : that takes IEntityQueryOptions and returns Entity Observable from graphQL query setStaticState : that sets IEntityStaticState fetchStaticState : that returns IEntityStaticState observable state : that returns IEntityState observable Please refer to example Deposit Entity class","title":"Add new Entity class"},{"location":"gettingStarted/customScheme/clientForNewScheme/#example-entity-class","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 import gql from graphql-tag import { Observable } from rxjs import { first } from rxjs/operators import { Arc , IApolloQueryOptions } from ./arc import { Address , ICommonQueryOptions , IStateful } from ./types import { BN , createGraphQlQuery , isAddress } from ./utils export interface IDepositStaticState { id ? : string member : Address amount : typeof BN rep : typeof BN dao : Address } export interface IDepositState extends IDepositStaticState { id : string } export interface IDepositQueryOptions extends ICommonQueryOptions { where ? : { id ? : string member ? : Address dao ? : Address [ key : string ]: any } } export class Deposit implements IStateful IDepositState { /** * Deposit . search ( context , options ) searches for deposit entities * @param context an Arc instance that provides connection information * @param options the query options , cf . IDepositQueryOptions * @return an observable of Deposit objects */ public static search ( context : Arc , options : IDepositQueryOptions = {}, apolloQueryOptions : IApolloQueryOptions = {} ): Observable Deposit [] { if ( ! options . where ) { options . where = {}} let where = let daoFilter : ( r : any ) = boolean daoFilter = () = true for ( const key of Object . keys ( options . where )) { if ( options . where [ key ] === undefined ) { continue } if ( key === member || key === dao ) { const option = options . where [ key ] as string isAddress ( option ) options . where [ key ] = option . toLowerCase () } else { where += `${key}: ${options.where[key] as string} \\n` } } const query = gql ` query DepositSearch { deposits $ { createGraphQlQuery ( options , where )} { id member amount avatar rep } } ` return context . getObservableListWithFilter ( query , ( r : any ) = { return new Deposit ({ id : r . id , member : r . member , amount : new BN ( r . amount || 0 ), dao : r . avatar , rep : new BN ( r . rep || 0 ) }, context ) }, daoFilter , apolloQueryOptions ) as Observable Deposit [] } public id : string | undefined public staticState : IDepositStaticState | undefined constructor ( idOrOpts : string | IDepositStaticState , public context : Arc ) { if ( typeof idOrOpts === string ) { this . id = idOrOpts } else { const opts = idOrOpts as IDepositStaticState this . id = opts . id this . setStaticState ( opts ) } } public setStaticState ( opts : IDepositStaticState ) { this . staticState = opts } public async fetchStaticState (): Promise IDepositStaticState { if ( !! this . staticState ) { return this . staticState } else { return await this . state () . pipe ( first ()) . toPromise () } } public state ( apolloQueryOptions : IApolloQueryOptions = {}): Observable IDepositState { const query = gql ` query DepositById { deposit ( id : ${this.id} ) { id memberAddress amount avatar rep } } ` const itemMap = ( item : any ): IDepositState = { if ( item === null ) { throw Error ( `Could not find a Vote with id ${this.id}` ) } return { amount : item . amount , dao : item . dao , id : item . id , member : item . member , rep : item . rep } } return this . context . getObservableObject ( query , itemMap , apolloQueryOptions ) } }","title":"Example Entity Class"},{"location":"gettingStarted/customScheme/clientForNewScheme/#integration-tests","text":"Add relevant integration test for the new scheme, client/test/scheme-buyInWithRageQuitOpt.spec.ts Start test watcher while you test and update the client 1 npm run test : watch : client -- test/scheme-buyInWithRageQuitOpt.spec.ts Refer to example Test BuyInWithRageQuitOpt Scheme","title":"Integration Tests"},{"location":"gettingStarted/customScheme/clientForNewScheme/#example-test-buyinwithragequitopt-scheme","text":"Following is an example integration test file to test the sample non-universal scheme we developed in this tutorial 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 import { Scheme } from ../src/scheme import { Arc } from ../src/arc import { DAO } from ../src/dao import { first } from rxjs/operators import { Reputation } from ../src/reputation import { Deposit } from ../src/deposit import { BN , getTestDAO , getTestAddresses , newArc , toWei , waitUntilTrue } from ./utils jest . setTimeout ( 60000 ) /** * Scheme test */ describe ( Deposit to buy reputaion , () = { let addresses : any let arc : Arc let dao : DAO let scheme : Scheme let daoBalanceBefore : undefined let reputationBefore : undefined let eventLengthBefore : number let reputation : any let amount = toWei ( 0.1 ) let response : any const getEventLength = async () = { let deposits = await Deposit . search ( arc , { where : { member : arc . web3 . eth . defaultAccount }}, { fetchPolicy : no-cache } ) . pipe ( first ()) . toPromise () return deposits . length } beforeAll ( async () = { arc = await newArc () addresses = getTestAddresses ( arc ) dao = await getTestDAO () scheme = new Scheme ({ address : 0x6d065a54f0a14cb03b949a146dbb58c14a0afc48 , dao : dao . id , id : 0x992c72e5e965d11a318839b554b0330dcb3ac81dc2ac0e4e57ba2c15660a3564 , name : BuyInWithRageQuitOpt , paramsHash : 0x0000000000000000000000000000000000000000000000000000000000000000 }, arc ) reputation = new Reputation ( addresses . dao . Reputation , arc ) daoBalanceBefore = await dao . ethBalance () . pipe ( first ()) . toPromise () reputationBefore = await reputation . reputationOf ( arc . web3 . eth . defaultAccount ) . pipe ( first ()) . toPromise () eventLengthBefore = await getEventLength () expect ( scheme . BuyInWithRageQuitOpt ) . not . toBeFalsy () if ( scheme . BuyInWithRageQuitOpt ) { response = await scheme . BuyInWithRageQuitOpt . deposit ( amount ) . send () expect ( response ) } }) it ( Should increase DAO balance by amount deposited , async () = { let daoBalanceAfter = await dao . ethBalance () . pipe ( first ()) . toPromise () expect ( Number ( daoBalanceAfter ) - Number ( daoBalanceBefore )) . toEqual ( Number ( amount )) }) it ( Should increase reputation of Member by amount deposited , async () = { let reputationAfter = new BN ( await reputation . contract () . methods . balanceOf ( arc . web3 . eth . defaultAccount ) . call ()) expect ( Number ( reputationAfter ) - Number ( reputationBefore )) . toEqual ( Number ( amount )) }) it ( Should index the deposit event , async () = { const state0 = await response . result . fetchStaticState () expect ( state0 ) . toMatchObject ({ amount : amount . toString (), member : arc . web3 . eth . defaultAccount . toLowerCase (), dao : dao . id . toLowerCase (), rep : amount . toString () }) let eventLengthAfter = eventLengthBefore const depositIsIndexed = async () = { eventLengthAfter = await getEventLength () return eventLengthAfter - eventLengthBefore 0 } await waitUntilTrue ( depositIsIndexed ) expect ( eventLengthAfter - 1 ) . toEqual ( eventLengthBefore ) }) }) describe ( Quit to refund funds , () = { // add more tests })","title":"Example Test BuyInWithRageQuitOpt Scheme"},{"location":"gettingStarted/customScheme/clientForNewScheme/#extra-interoperability-updates-may-differ-per-use-case","text":"Apart from the above standard updates you might need to update some other files depending on the scheme you are adding. For eg. In case of BuyInWithRageQuitOpt Scheme , we added to following files: src/scheme.ts : To add BuyInWithRageQuitOpt to ISchemeState src/operation.ts : To enable passing custom value to this.scheme.context.sendTransaction test/utils.ts : To update LATEST_ARC_VERSION and to getTestAddresses of our newly created DAO instead of test DAO test/migration.json : To use the migration file we got in the migration step (which has details of our DAO and new scheme`","title":"Extra Interoperability updates (may differ per use case)"},{"location":"gettingStarted/customScheme/developCustomNonUniScheme/","text":"Tutorial for adding non-universal scheme skip Design Principle Non-Universal scheme is more simple than a universal one, since it serves a single DAO (avatar) It is possible to attach multiple instances of non-universal scheme to a single DAO (avatar), For eg. In case of GenericScheme we attach an instance per external contract that the DAO can interact to. Recommended design principle : should include a one time called public initialize function which gets the avatar as its first parameters (This will assist with the common migration process) Setup We will use Alchemy-starter for this tutorial, enter the directory and install starter-package 1 2 cd alchemy - starter / npm i Add your custom scheme contract to contracts folder. Refer to example BuyInWithRageQuitOpt.sol : A non-universal scheme to allow people to buy reputation by donating money to the DAO and if their goals no more align with the DAO, have the ability to quit reputation at some later time and receive propotional funds back. Compile your contracts 1 npm run compile","title":"Non-Universal Scheme"},{"location":"gettingStarted/customScheme/developCustomNonUniScheme/#design-principle","text":"Non-Universal scheme is more simple than a universal one, since it serves a single DAO (avatar) It is possible to attach multiple instances of non-universal scheme to a single DAO (avatar), For eg. In case of GenericScheme we attach an instance per external contract that the DAO can interact to. Recommended design principle : should include a one time called public initialize function which gets the avatar as its first parameters (This will assist with the common migration process)","title":"Design Principle"},{"location":"gettingStarted/customScheme/developCustomNonUniScheme/#setup","text":"We will use Alchemy-starter for this tutorial, enter the directory and install starter-package 1 2 cd alchemy - starter / npm i Add your custom scheme contract to contracts folder. Refer to example BuyInWithRageQuitOpt.sol : A non-universal scheme to allow people to buy reputation by donating money to the DAO and if their goals no more align with the DAO, have the ability to quit reputation at some later time and receive propotional funds back. Compile your contracts 1 npm run compile","title":"Setup"},{"location":"gettingStarted/customScheme/developCustomUniScheme/","text":"Coming Soon","title":"Universal Scheme"},{"location":"gettingStarted/customScheme/intro/","text":"Scheme is an action a DAO on DAOstack platform can be enabled to take. Schemes might be used to help a DAO: propose and make investments, give reputation to agents, upgrade the DAO's contracts, register new schemes and constraints, etc. Apart from the schemes already designed by DAOstack team - Arc , you can also deploy your own Custom Schemes and register them to the DAO. A scheme could be, Universal : inherit from UniversalSchemeInterface and are designed to be deployed once and any DAO can register to a universal scheme to enable the functionality offered by them. OR Non Universal : do not follow any standard and do not inherit from UniversalSchemeInterface. A non universal scheme has to be deployed for each DAO separately. Which layer to customize To Enable DAO with some custom actions, you will have to work on multiple layers of the stack Arc : Design and Deploy the scheme contract which has the action DAO will execute. Migration : deploy + register custom scheme to new DAO using migration script or deploy independently and register via another Scheme Subgraph : develop subgraph tracker for your scheme for faster/efficient read access Client : enable DAOstack client library to write to your scheme contract and read scheme data from subgraph using graphQL Alchemy : enable user friendly interface for your scheme in Alchemy Tutorial In following section we will see some sample code for adding a custom scheme to the DAO and enable Alchemy to interact with it. We will be using Alchemy-starter for this tutorial If you have not cloned the DAOstack Hacker kit repo , then clone it recursively to get the submodules 1 git clone --recursive git@github.com:daostack/DAOstack-Hackers-Kit.git If you have already cloned the DAOstack Hackers kit repo , then make sure you have the latest submodules too 1 git submodule update --init Depending on your requirements all or some parts of the tutorial might be useful for you. Pre Work 1 2 3 cd alchemy - starter npm i npm run launch : docker Add scheme contract and deploy Follow tutorial for Universal Scheme or Non-Universal Scheme Deploy with New DAO 1 npm run migrate OR Deploy and register to Existing DAO Update subgraph and deploy Make changes to subgraph refer Update subgraph tutorial and deploy graph 1 npm run deploy : graph Update client and build Update client to interact with your scheme, refer Update client tutorial 1 2 npm run build : client npm run link : client To develop on the client in tandem with alchemy, start watcher 1 npm run watch : client Update alchemy Add front-end support for you scheme, refer to Update alchemy tutorial for some basics Launch alchemy in dev mode 1 npm run start : alchemy","title":"Intro"},{"location":"gettingStarted/customScheme/intro/#which-layer-to-customize","text":"To Enable DAO with some custom actions, you will have to work on multiple layers of the stack Arc : Design and Deploy the scheme contract which has the action DAO will execute. Migration : deploy + register custom scheme to new DAO using migration script or deploy independently and register via another Scheme Subgraph : develop subgraph tracker for your scheme for faster/efficient read access Client : enable DAOstack client library to write to your scheme contract and read scheme data from subgraph using graphQL Alchemy : enable user friendly interface for your scheme in Alchemy","title":"Which layer to customize"},{"location":"gettingStarted/customScheme/intro/#tutorial","text":"In following section we will see some sample code for adding a custom scheme to the DAO and enable Alchemy to interact with it. We will be using Alchemy-starter for this tutorial If you have not cloned the DAOstack Hacker kit repo , then clone it recursively to get the submodules 1 git clone --recursive git@github.com:daostack/DAOstack-Hackers-Kit.git If you have already cloned the DAOstack Hackers kit repo , then make sure you have the latest submodules too 1 git submodule update --init Depending on your requirements all or some parts of the tutorial might be useful for you.","title":"Tutorial"},{"location":"gettingStarted/customScheme/intro/#pre-work","text":"1 2 3 cd alchemy - starter npm i npm run launch : docker","title":"Pre Work"},{"location":"gettingStarted/customScheme/intro/#add-scheme-contract-and-deploy","text":"Follow tutorial for Universal Scheme or Non-Universal Scheme Deploy with New DAO 1 npm run migrate OR Deploy and register to Existing DAO","title":"Add scheme contract and deploy"},{"location":"gettingStarted/customScheme/intro/#update-subgraph-and-deploy","text":"Make changes to subgraph refer Update subgraph tutorial and deploy graph 1 npm run deploy : graph","title":"Update subgraph and deploy"},{"location":"gettingStarted/customScheme/intro/#update-client-and-build","text":"Update client to interact with your scheme, refer Update client tutorial 1 2 npm run build : client npm run link : client To develop on the client in tandem with alchemy, start watcher 1 npm run watch : client","title":"Update client and build"},{"location":"gettingStarted/customScheme/intro/#update-alchemy","text":"Add front-end support for you scheme, refer to Update alchemy tutorial for some basics Launch alchemy in dev mode 1 npm run start : alchemy","title":"Update alchemy"},{"location":"gettingStarted/customScheme/registerToExistingDAO/","text":"Develop the Scheme and register it to your DAO as part of initial scheme set or via another scheme (SchemeRegistrar in case of GenesisAlpha DAO)","title":"Register scheme to existing DAO"},{"location":"gettingStarted/customScheme/registerToNewDAO/","text":"You can deploy your new custom scheme contract and register it to the New DAO as part of initial scheme set using @daostack/migration tool Create DAO-spec Add data/YourDaoSpec.json file that describes the specifics of the DAO such as Name of Organization, Token name and symbol, initial set of scheme registered and founder members etc. You can refer to Deploy a DAO section for base dao-spec file Add CustomSchemes section with the details of your scheme as follows. Refer Example DAO spec name : Name of the contract file schemeName : Name of the scheme isUniversal : true or false, depending on which scheme you are registering params : array of parameters to be passed to scheme contract's initialize (in-case of non-universal) or setParameters (in-case of universal) method. Please keep the order of parameters expected by the method in consideration Include { \"voteParams\": X } for voting machine parameters, where X is the index of param from VotingMachinesParams , that will be used to vote on proposals submitted to this scheme. \"GenesisProtocolAddress\" will be converted to actual GenesisProtocol address. Include this if scheme uses Genesis Protocol as the voting machine and expects its Address as one of the parameter Since each non-universal scheme is deployed per DAO and it is advisable to have the DAO address initialized the scheme, the migration tool expects first param to initialize method is DAO avatar address. permissions : Include a 4 byte hex describing the permissions required by your new scheme 2nd bit: Scheme can register other schemes 3rd bit: Scheme can add/remove global constraints 4th bit: Scheme can upgrade the controller 5th bit: Scheme can call genericCall on behalf of address (optional): If you have already deployed your scheme contract, then include its address here, else migration script will deploy this scheme alias (optional): include alias for what you will want your scheme to be referred as in subgraph Example DAO spec file Following is CommunityDaoSpec.json using custom scheme designed in previous step for new Community DAO where people can buy reputation by donating money 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 { orgName : CommunityDAO , tokenName : Commune , tokenSymbol : CDT , ContributionReward :[ { voteParams : 0 } ], SchemeRegistrar : [ { voteRegisterParams : 1 , voteRemoveParams : 1 } ], CustomSchemes : [ { name : BuyInWithRageQuitOpt , schemeName : BuyInWithRageQuitOpt , isUniversal : false , params : [ ], permissions : 0x00000000 } ], VotingMachinesParams :[ { activationTime : 0 , boostedVotePeriodLimit : 345600 , daoBountyConst : 10 , minimumDaoBounty : 150 , preBoostedVotePeriodLimit : 86400 , proposingRepReward : 0 , queuedVotePeriodLimit : 2592000 , queuedVoteRequiredPercentage : 50 , quietEndingPeriod : 172800 , thresholdConst : 1200 , voteOnBehalf : 0x0000000000000000000000000000000000000000 , votersReputationLossRatio : 0 } , { activationTime : 0 , boostedVotePeriodLimit : 691200 , daoBountyConst : 10 , minimumDaoBounty : 500 , preBoostedVotePeriodLimit : 172800 , proposingRepReward : 0 , queuedVotePeriodLimit : 5184000 , queuedVoteRequiredPercentage : 50 , quietEndingPeriod : 345600 , thresholdConst : 1500 , voteOnBehalf : 0x0000000000000000000000000000000000000000 , votersReputationLossRatio : 0 } ], schemes : { ContributionReward : true , SchemeRegistrar : true } , unregisterOwner : true , useUController : false , useDaoCreator : true , founders :[ ] } Create DAO-deploy file Create migration file to deploy your DAO. You will need node = 10.16.0 dotenv =8.1.0 @daostack/migration latest Update .env file with following environment variables CUSTOM_ABI_LOCATION : location of all your compiled contracts, eg. contracts/build DAO_SPEC : path to yourDaoSpec.json file DEFAULT_GAS : gas price for tx, eg. 3.0 OUTPUT_FILE : full path of file where to store migration output, eg. data/migration.json PRIVATE_KEY : key of the account you are using to deploy the DAO PROVIDER : url of the ethprovider, this could be infura or ganache Example 1 2 3 4 5 6 CUSTOM_ABI_LOCATION = build/contracts DAO_SPEC = ../data/testDaoSpec.json DEFAULT_GAS = 3 . 0 OUTPUT_FILE = data/migration.json PRIVATE_KEY = 0x4f3edf983ac636a65a842ce7c78d9aa706d3b113bce9c46f30d7d21715b23b1d PROVIDER = http://localhost:8545 Add/Update the ops/deployDAO.js , Refer Example deploy script Example deploy script 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 require ( dotenv ). config (); const DAOstackMigration = require ( @daostack/migration ); const migrationSpec = require ( process . env . DAO_SPEC ) async function migrate () { const options = { provider : process . env . PROVIDER , gasPrice : process . env . DEFAULT_GAS , quiet : false , force : true , output : process . env . OUTPUT_FILE , privateKey : process . env . PRIVATE_KEY , customabislocation : process . env . CUSTOM_ABI_LOCATION , params : { private : migrationSpec , rinkeby : migrationSpec } , } ; await DAOstackMigration . migrateDAO ( options ); } migrate ()","title":"Register scheme to new DAO"},{"location":"gettingStarted/customScheme/registerToNewDAO/#create-dao-spec","text":"Add data/YourDaoSpec.json file that describes the specifics of the DAO such as Name of Organization, Token name and symbol, initial set of scheme registered and founder members etc. You can refer to Deploy a DAO section for base dao-spec file Add CustomSchemes section with the details of your scheme as follows. Refer Example DAO spec name : Name of the contract file schemeName : Name of the scheme isUniversal : true or false, depending on which scheme you are registering params : array of parameters to be passed to scheme contract's initialize (in-case of non-universal) or setParameters (in-case of universal) method. Please keep the order of parameters expected by the method in consideration Include { \"voteParams\": X } for voting machine parameters, where X is the index of param from VotingMachinesParams , that will be used to vote on proposals submitted to this scheme. \"GenesisProtocolAddress\" will be converted to actual GenesisProtocol address. Include this if scheme uses Genesis Protocol as the voting machine and expects its Address as one of the parameter Since each non-universal scheme is deployed per DAO and it is advisable to have the DAO address initialized the scheme, the migration tool expects first param to initialize method is DAO avatar address. permissions : Include a 4 byte hex describing the permissions required by your new scheme 2nd bit: Scheme can register other schemes 3rd bit: Scheme can add/remove global constraints 4th bit: Scheme can upgrade the controller 5th bit: Scheme can call genericCall on behalf of address (optional): If you have already deployed your scheme contract, then include its address here, else migration script will deploy this scheme alias (optional): include alias for what you will want your scheme to be referred as in subgraph","title":"Create DAO-spec"},{"location":"gettingStarted/customScheme/registerToNewDAO/#example-dao-spec-file","text":"Following is CommunityDaoSpec.json using custom scheme designed in previous step for new Community DAO where people can buy reputation by donating money 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 { orgName : CommunityDAO , tokenName : Commune , tokenSymbol : CDT , ContributionReward :[ { voteParams : 0 } ], SchemeRegistrar : [ { voteRegisterParams : 1 , voteRemoveParams : 1 } ], CustomSchemes : [ { name : BuyInWithRageQuitOpt , schemeName : BuyInWithRageQuitOpt , isUniversal : false , params : [ ], permissions : 0x00000000 } ], VotingMachinesParams :[ { activationTime : 0 , boostedVotePeriodLimit : 345600 , daoBountyConst : 10 , minimumDaoBounty : 150 , preBoostedVotePeriodLimit : 86400 , proposingRepReward : 0 , queuedVotePeriodLimit : 2592000 , queuedVoteRequiredPercentage : 50 , quietEndingPeriod : 172800 , thresholdConst : 1200 , voteOnBehalf : 0x0000000000000000000000000000000000000000 , votersReputationLossRatio : 0 } , { activationTime : 0 , boostedVotePeriodLimit : 691200 , daoBountyConst : 10 , minimumDaoBounty : 500 , preBoostedVotePeriodLimit : 172800 , proposingRepReward : 0 , queuedVotePeriodLimit : 5184000 , queuedVoteRequiredPercentage : 50 , quietEndingPeriod : 345600 , thresholdConst : 1500 , voteOnBehalf : 0x0000000000000000000000000000000000000000 , votersReputationLossRatio : 0 } ], schemes : { ContributionReward : true , SchemeRegistrar : true } , unregisterOwner : true , useUController : false , useDaoCreator : true , founders :[ ] }","title":"Example DAO spec file"},{"location":"gettingStarted/customScheme/registerToNewDAO/#create-dao-deploy-file","text":"Create migration file to deploy your DAO. You will need node = 10.16.0 dotenv =8.1.0 @daostack/migration latest Update .env file with following environment variables CUSTOM_ABI_LOCATION : location of all your compiled contracts, eg. contracts/build DAO_SPEC : path to yourDaoSpec.json file DEFAULT_GAS : gas price for tx, eg. 3.0 OUTPUT_FILE : full path of file where to store migration output, eg. data/migration.json PRIVATE_KEY : key of the account you are using to deploy the DAO PROVIDER : url of the ethprovider, this could be infura or ganache Example 1 2 3 4 5 6 CUSTOM_ABI_LOCATION = build/contracts DAO_SPEC = ../data/testDaoSpec.json DEFAULT_GAS = 3 . 0 OUTPUT_FILE = data/migration.json PRIVATE_KEY = 0x4f3edf983ac636a65a842ce7c78d9aa706d3b113bce9c46f30d7d21715b23b1d PROVIDER = http://localhost:8545 Add/Update the ops/deployDAO.js , Refer Example deploy script","title":"Create DAO-deploy file"},{"location":"gettingStarted/customScheme/registerToNewDAO/#example-deploy-script","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 require ( dotenv ). config (); const DAOstackMigration = require ( @daostack/migration ); const migrationSpec = require ( process . env . DAO_SPEC ) async function migrate () { const options = { provider : process . env . PROVIDER , gasPrice : process . env . DEFAULT_GAS , quiet : false , force : true , output : process . env . OUTPUT_FILE , privateKey : process . env . PRIVATE_KEY , customabislocation : process . env . CUSTOM_ABI_LOCATION , params : { private : migrationSpec , rinkeby : migrationSpec } , } ; await DAOstackMigration . migrateDAO ( options ); } migrate ()","title":"Example deploy script"},{"location":"gettingStarted/customScheme/subgraphForNewScheme/","text":"If you created a custom scheme or used any of the new arc scheme that are not yet tracked by subgraph, then you will have to make changes to DAOstack caching layer. NOTE: You can skip this step if you do not wish to take advantage of caching layer for faster access and would rather read data directly from blockchain. But would recommend not to. Pre Work Make sure you have cloned subgraph submodule, if you have not already 1 git submodule update --init Create a new directory with your scheme-name in mappings 1 2 cd subgraph mkdir src / mappings / BuyInWithRageQuitOpt Add contract abi to abis/'version' folder e.g. abis/0.0.1-rc.27/BuyInWithRageQuitOpt.json If you have jq tool installed you can use this command to extract abi, make sure to use right version folder 1 cat .. / build / contracts / BuyInWithRageQuitOpt . json | jq . abi abis / 0 . 0 . 1 - rc . 27 / BuyInWithRageQuitOpt . json If you ran above command you should be able to see an Abi file for the non-universal scheme as follows 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 [ { constant : true , inputs : [], name : avatar , outputs : [ { internalType : contract Avatar , name : , type : address } ], payable : false , stateMutability : view , type : function } , { constant : true , inputs : [], name : reputation , outputs : [ { internalType : contract Reputation , name : , type : address } ], payable : false , stateMutability : view , type : function } , { anonymous : false , inputs : [ { indexed : true , internalType : address , name : _member , type : address } , { indexed : false , internalType : uint256 , name : _amount , type : uint256 } , { indexed : false , internalType : uint256 , name : _rep , type : uint256 } ], name : buyIn , type : event } , { anonymous : false , inputs : [ { indexed : true , internalType : address , name : _member , type : address } , { indexed : false , internalType : uint256 , name : _amount , type : uint256 } , { indexed : false , internalType : uint256 , name : _rep , type : uint256 } ], name : rageQuit , type : event } , { constant : false , inputs : [ { internalType : contract Avatar , name : _avatar , type : address } ], name : initialize , outputs : [], payable : false , stateMutability : nonpayable , type : function } , { constant : false , inputs : [], name : deposit , outputs : [], payable : true , stateMutability : payable , type : function } , { constant : false , inputs : [], name : quit , outputs : [ { internalType : uint256 , name : , type : uint256 } ], payable : false , stateMutability : nonpayable , type : function } ] Add contract mappings In order to cache the events from blockchain, we will create following files in src/mappings/BuyInWithRageQuitOpt : datasource.yaml File containing the subgraph manifest src/mappings/BuyInWithRageQuitOpt/datasource.yaml 1 2 3 4 5 6 7 8 9 10 abis : - BuyInWithRageQuitOpt entities : - Deposit - Quit eventHandlers : - event : buyIn ( indexed address , uint256 , uint256 ) handler : handleBuyIn - event : rageQuit ( indexed address , uint256 , uint256 ) handler : handleRageQuit schema.graphql Describe what data is stored for your subgraph and how to query it via GraphQL in src/mappings/BuyInWithRageQuitOpt/schema.graphql NOTE: These will be used for the generating types in src/types/ during build step and will need to be imported while writing handlers in mapping.ts 1 2 3 4 5 6 7 8 9 10 11 12 13 type Deposit @entity { id : ID ! memberAddress : Bytes ! amount : BigInt ! rep : BigInt ! } type Quit @entity { id : ID ! memberAddress : Bytes ! amount : BigInt ! rep : BigInt ! } mapping.ts Describe how blockchain events are processed and stored in entities defined in your schema src/mappings/BuyInWithRageQuitOpt/mapping.ts NOTE: src/types/BuyInWithRageQuitOpt/BuyInWithRageQuitOpt will be generated during the build step based on the entities described in schema.graphQL. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 import allocator/arena ; import { store , } from @graphprotocol/graph-ts ; import * as domain from ../../domain ; import { Deposit , Quit } from ../../types/schema ; import { concat , equalsBytes , eventId } from ../../utils ; import { buyIn , rageQuit , } from ../../types/BuyInWithRageQuitOpt/BuyInWithRageQuitOpt ; export function handleBuyIn ( event : buyIn ): void { let ent = new Deposit ( eventId ( event )); ent . memberAddress = event . params . _member ; ent . amount = event . params . _amount ; ent . rep = event . params . _rep ; store . set ( Deposit , ent . id , ent ); } export function handleRageQuit ( event : rageQuit ): void { let ent = new Quit ( eventId ( event )); ent . memberAddress = event . params . _member ; ent . amount = event . params . _amount ; ent . rep = event . params . _rep ; store . set ( Quit , ent . id , ent ); } Integration test (optional) Add integration test for the subgraph test/integration/MyContractName.spec.ts Update Ops Add tracker for your contract in ops/mappings.json . In the JSON object for the network your contract is located at, under the \"mappings\" JSON array, add the following. arcVersion : contract arc version dao : section label where contract is defined in migration.json file (base/ dao/ test/ organs) or address , mapping : contract name as in mappings, name : contract name as appears in abis/arcVersion folder, contractName : contract name as appears in migration.json file, If your contract information is in the migration.json file specified (default is the file under @daostack/migration folder, as defined in the ops/settings.js file) 1 2 3 4 5 6 7 { name : BuyInWithRageQuitOpt , contractName : BuyInWithRageQuitOpt , dao : dao , mapping : BuyInWithRageQuitOpt , arcVersion : 0.0.1-rc.27 } , OR address : the contract address on network If your contract does not appear in the migration file add following info: 1 2 3 4 5 6 7 { name : BuyInWithRageQuitOpt , address : 0x4a35d1434D34Ac7842381362924E6399ca63Da5A dao : address , mapping : BuyInWithRageQuitOpt , arcVersion : 0.0.1-rc.27 , } ,","title":"Subgraph: enable cache for new scheme"},{"location":"gettingStarted/customScheme/subgraphForNewScheme/#pre-work","text":"Make sure you have cloned subgraph submodule, if you have not already 1 git submodule update --init Create a new directory with your scheme-name in mappings 1 2 cd subgraph mkdir src / mappings / BuyInWithRageQuitOpt Add contract abi to abis/'version' folder e.g. abis/0.0.1-rc.27/BuyInWithRageQuitOpt.json If you have jq tool installed you can use this command to extract abi, make sure to use right version folder 1 cat .. / build / contracts / BuyInWithRageQuitOpt . json | jq . abi abis / 0 . 0 . 1 - rc . 27 / BuyInWithRageQuitOpt . json If you ran above command you should be able to see an Abi file for the non-universal scheme as follows 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 [ { constant : true , inputs : [], name : avatar , outputs : [ { internalType : contract Avatar , name : , type : address } ], payable : false , stateMutability : view , type : function } , { constant : true , inputs : [], name : reputation , outputs : [ { internalType : contract Reputation , name : , type : address } ], payable : false , stateMutability : view , type : function } , { anonymous : false , inputs : [ { indexed : true , internalType : address , name : _member , type : address } , { indexed : false , internalType : uint256 , name : _amount , type : uint256 } , { indexed : false , internalType : uint256 , name : _rep , type : uint256 } ], name : buyIn , type : event } , { anonymous : false , inputs : [ { indexed : true , internalType : address , name : _member , type : address } , { indexed : false , internalType : uint256 , name : _amount , type : uint256 } , { indexed : false , internalType : uint256 , name : _rep , type : uint256 } ], name : rageQuit , type : event } , { constant : false , inputs : [ { internalType : contract Avatar , name : _avatar , type : address } ], name : initialize , outputs : [], payable : false , stateMutability : nonpayable , type : function } , { constant : false , inputs : [], name : deposit , outputs : [], payable : true , stateMutability : payable , type : function } , { constant : false , inputs : [], name : quit , outputs : [ { internalType : uint256 , name : , type : uint256 } ], payable : false , stateMutability : nonpayable , type : function } ]","title":"Pre Work"},{"location":"gettingStarted/customScheme/subgraphForNewScheme/#add-contract-mappings","text":"In order to cache the events from blockchain, we will create following files in src/mappings/BuyInWithRageQuitOpt :","title":"Add contract mappings"},{"location":"gettingStarted/customScheme/subgraphForNewScheme/#datasourceyaml","text":"File containing the subgraph manifest src/mappings/BuyInWithRageQuitOpt/datasource.yaml 1 2 3 4 5 6 7 8 9 10 abis : - BuyInWithRageQuitOpt entities : - Deposit - Quit eventHandlers : - event : buyIn ( indexed address , uint256 , uint256 ) handler : handleBuyIn - event : rageQuit ( indexed address , uint256 , uint256 ) handler : handleRageQuit","title":"datasource.yaml"},{"location":"gettingStarted/customScheme/subgraphForNewScheme/#schemagraphql","text":"Describe what data is stored for your subgraph and how to query it via GraphQL in src/mappings/BuyInWithRageQuitOpt/schema.graphql NOTE: These will be used for the generating types in src/types/ during build step and will need to be imported while writing handlers in mapping.ts 1 2 3 4 5 6 7 8 9 10 11 12 13 type Deposit @entity { id : ID ! memberAddress : Bytes ! amount : BigInt ! rep : BigInt ! } type Quit @entity { id : ID ! memberAddress : Bytes ! amount : BigInt ! rep : BigInt ! }","title":"schema.graphql"},{"location":"gettingStarted/customScheme/subgraphForNewScheme/#mappingts","text":"Describe how blockchain events are processed and stored in entities defined in your schema src/mappings/BuyInWithRageQuitOpt/mapping.ts NOTE: src/types/BuyInWithRageQuitOpt/BuyInWithRageQuitOpt will be generated during the build step based on the entities described in schema.graphQL. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 import allocator/arena ; import { store , } from @graphprotocol/graph-ts ; import * as domain from ../../domain ; import { Deposit , Quit } from ../../types/schema ; import { concat , equalsBytes , eventId } from ../../utils ; import { buyIn , rageQuit , } from ../../types/BuyInWithRageQuitOpt/BuyInWithRageQuitOpt ; export function handleBuyIn ( event : buyIn ): void { let ent = new Deposit ( eventId ( event )); ent . memberAddress = event . params . _member ; ent . amount = event . params . _amount ; ent . rep = event . params . _rep ; store . set ( Deposit , ent . id , ent ); } export function handleRageQuit ( event : rageQuit ): void { let ent = new Quit ( eventId ( event )); ent . memberAddress = event . params . _member ; ent . amount = event . params . _amount ; ent . rep = event . params . _rep ; store . set ( Quit , ent . id , ent ); }","title":"mapping.ts"},{"location":"gettingStarted/customScheme/subgraphForNewScheme/#integration-test-optional","text":"Add integration test for the subgraph test/integration/MyContractName.spec.ts","title":"Integration test (optional)"},{"location":"gettingStarted/customScheme/subgraphForNewScheme/#update-ops","text":"Add tracker for your contract in ops/mappings.json . In the JSON object for the network your contract is located at, under the \"mappings\" JSON array, add the following. arcVersion : contract arc version dao : section label where contract is defined in migration.json file (base/ dao/ test/ organs) or address , mapping : contract name as in mappings, name : contract name as appears in abis/arcVersion folder, contractName : contract name as appears in migration.json file, If your contract information is in the migration.json file specified (default is the file under @daostack/migration folder, as defined in the ops/settings.js file) 1 2 3 4 5 6 7 { name : BuyInWithRageQuitOpt , contractName : BuyInWithRageQuitOpt , dao : dao , mapping : BuyInWithRageQuitOpt , arcVersion : 0.0.1-rc.27 } , OR address : the contract address on network If your contract does not appear in the migration file add following info: 1 2 3 4 5 6 7 { name : BuyInWithRageQuitOpt , address : 0x4a35d1434D34Ac7842381362924E6399ca63Da5A dao : address , mapping : BuyInWithRageQuitOpt , arcVersion : 0.0.1-rc.27 , } ,","title":"Update Ops"},{"location":"stack/alchemy/alchemyIntro/","text":"The Client library facilitates development of \"Dapps\" (Decentralized applications) for interacting with DAOs. DAOstack has built its own Dapp called Alchemy , a front-end interface for DAOs , or more specifically, for budget management in decentralized organizations. Alchemy allows end users to make collaborative budgeting decisions and allocations using the Holographic Consensus protocol . You can find the Alchemy repo at github.com/daostack/alchemy . A second Dapp built by DAOstack is Vanille (enable MetaMask). Vanille enables users to create and interact with DAOs before moving to a dedicated interface like Alchemy. You can find the Vanille repo here: https://github.com/daostack/vanille . Should I work at this level? Build at the Dapp level if you want to create new ways to interact with existing DAOs and DAOstack smart contracts, e.g. a multi-DAO explorer for GEN predictors or a new DAO creation app.","title":"DApps/Alchemy"},{"location":"stack/alchemy/alchemyIntro/#should-i-work-at-this-level","text":"Build at the Dapp level if you want to create new ways to interact with existing DAOs and DAOstack smart contracts, e.g. a multi-DAO explorer for GEN predictors or a new DAO creation app.","title":"Should I work at this level?"},{"location":"stack/arc/arcIntro/","text":"Arc is a Solidity smart contract library for building DAOs. To get a good understanding of how the Arc framework is built, you can go to this blog post . Arc uses Infra to provide decentralized organizations with voting machines and voting rights management systems. DAOs built with Arc have a few basic contract components: Avatar - The DAO's \"account.\" This contract represents the address of the DAO and holds its assets. Reputation - Voting in Arc is done mainly using Reputation. Reputation can be distributed and redistributed only by DAO decision, and it is generally given (via vote) to an agent according to their performance and contribution to a DAO. Token - Each DAO may have its own token, which can be used in any way the DAO would like. Controller - The controller is the \"Access Control\" of the DAO, managing who can interact with which DAO functions and enforcing the DAO's constraints. Schemes - Schemes are a DAO's \"actions\": anything a DAO should act upon needs to be written and authorized by the controller as a scheme. Schemes might be used to help a DAO: propose and make investments, give reputation to agents, upgrade the DAO's contracts, register new schemes and constraints, etc. Global Constraints - Global constraints are limitations on a DAO's actions. When executing a scheme, the controller checks the constraints to see if the action violates them, and blocks the execution if it does. Some examples for constraints might be: the token supply can't be increased over 1M tokens, the organization won't use more than 60% of its funds at once, etc. Arc utilizes the concept of \"Universal\" contracts : contracts which are deployed once, and then can be used by any number of DAOs simultaneously, saving gas and deployment costs. Schemes and constraints can both be used in this way. To use the already deployed contracts, you can either use Client, which maintains easy access to all universal Arc contracts, or you can use Migration.json to view the addresses of the universal contracts of the latest arc version on the mainnet, Kovan, Rinkeby and Ganache* All contracts listed in the file are universal, meaning that users should use them when needed and not redeploy them. * Please note that the Ganache addresses are based on the DAOstack commands for running and deploying Arc to a local Ganache network, which means those addresses might change if you are using a different method to run Ganache or deploy Arc. Should I work at this level? Using Arc is not necessary to deploy a DAO (you can do this with Migrations currently and in the future as an end user of Dapps), but you might want to work on this layer if you need your DAO to have a unique action, constraint, or voting process that is not yet implemented on Arc. You can find the complete Arc docs here: https://daostack.github.io/arc","title":"Arc"},{"location":"stack/arc/arcIntro/#should-i-work-at-this-level","text":"Using Arc is not necessary to deploy a DAO (you can do this with Migrations currently and in the future as an end user of Dapps), but you might want to work on this layer if you need your DAO to have a unique action, constraint, or voting process that is not yet implemented on Arc. You can find the complete Arc docs here: https://daostack.github.io/arc","title":"Should I work at this level?"},{"location":"stack/client/clientIntro/","text":"Client is a library that facilitates access to Arc contracts without having to directly interact with the Ethereum blockchain. It provides functions to interact with DAOstack contracts to vote, propose, stake and execute proposals. Client library is also a wrapper around DAOstack subgraph . It enable developers to interact with subgraph and execute various generic graph queries to access proposals, daos and other complex entities Using Client, JavaScript/TypeScript developers can easily write scripts or applications which can interact with existing DAOs, submit proposals to DAOs, vote and stake on proposals, execute the resulting decisions, manage agent reputations. This is particularly helpful for developers who want to get the advantages of decentralized governance on the blockchain without dealing directly with a smart contract language. Should I work at this level? You should use Client whenever you want to use JavaScript or TypeScript to interact with Arc contracts for voting, proposing etc or to execute generic GraphQL queries on subgraph for accessing blockchain data. If you are interacting with custom Arc contracts or custom subgraph, then you might have to write your own Web3 library to interact with contracts and/or query the subgraph.","title":"Client"},{"location":"stack/client/clientIntro/#should-i-work-at-this-level","text":"You should use Client whenever you want to use JavaScript or TypeScript to interact with Arc contracts for voting, proposing etc or to execute generic GraphQL queries on subgraph for accessing blockchain data. If you are interacting with custom Arc contracts or custom subgraph, then you might have to write your own Web3 library to interact with contracts and/or query the subgraph.","title":"Should I work at this level?"},{"location":"stack/infra/infraIntro/","text":"Infra is a Solidity smart contract library containing the core building blocks of decentralized governance. Infra contracts can be integrated into any application regardless of its architecture. Infra has two main components: Voting Machines - A voting machine is a universal contract which can operate the voting process for any organization. Each voting machine follows its own predifined rules for the decision making and execution process. Rules for voting machines can be implemented for any voting process, from a simple protocol like an \"Absolute Vote\" (where 51% of the voting power should approve it in order for the decision to pass), or more sophisticated protocols like the Holographic Consensus voting protocol. Voting Rights Management - A voting rights management system determines how voting rights are distributed. Any voting rights management system must have \"balances\" which represents the voting power each participant holds. There are 2 main approaches for managing voting rights: token-based voting and reputation-based voting. The main technical difference between the two is that tokens are transferable (i.e. tradable) while reputation is non-transferable. Another big difference which may appear (depending on implementation) is that a token is a property which cannot be taken while reputation may be redistributed by the organization itself. For most cases, we reccomend using the reputation-based voting model, however, Infra allows any voting right management system to be built. Should I work at this level? Build on Infra if you need new or modified decentralized governance primitives, such as voting machines and voting rights management systems.","title":"Infra"},{"location":"stack/infra/infraIntro/#should-i-work-at-this-level","text":"Build on Infra if you need new or modified decentralized governance primitives, such as voting machines and voting rights management systems.","title":"Should I work at this level?"},{"location":"stack/subgraph/subgraphIntro/","text":"Subgraph indexes the blockchain data and stores it in postgres database for easy and quick access. The subgraph runs on a Graph Node which is a server that developers can run local or remote. The data store can be queried by GraphQL endpoints. DAOstack subgraph is based on graphprotocol, checkout TheGraph for more details. TheGraph opens their server to others and you can find daostack subgraph and subgraphs from many other projects at Graph Explorer Should I work at this level? If you are writing new Arc contracts which are not indexed by DAOstack subgraph or want to fetch data of existing Arc contracts in a way other than that specified in DAOstack subgraph's schema.graphql , then you should write your own subgraph schema and mappings","title":"Subgraph"},{"location":"stack/subgraph/subgraphIntro/#should-i-work-at-this-level","text":"If you are writing new Arc contracts which are not indexed by DAOstack subgraph or want to fetch data of existing Arc contracts in a way other than that specified in DAOstack subgraph's schema.graphql , then you should write your own subgraph schema and mappings","title":"Should I work at this level?"}]}